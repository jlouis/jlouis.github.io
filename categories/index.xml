
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
 <channel>
   <title>Categories on jlouis&#39; Ramblings</title>
   <link>https://jlouis.github.io/categories/</link>
   <description>Recent content in Categories on jlouis&#39; Ramblings</description>
   <generator>Hugo -- gohugo.io</generator>
   
       <atom:link href="https://jlouis.github.io/categories/index.xml" rel="self" type="application/rss+xml" />
   
   
     <item>
       <title>On Observability</title>
       <link>https://jlouis.github.io/posts/observability/</link>
       <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/observability/</guid>
       <description>&lt;div class=&#34;quoteblock&#34;&gt;&lt;blockquote&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The hard part is not debugging the code. The hard part is figuring out where the bug is. This is what observability is.&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div class=&#34;attribution&#34;&gt;— Charity Majors&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I really like the notion of “observability”, which stems from Control Theory. The idea is that we have some system, with inputs, some internal state and some outputs. A system is observable if we can determine its internal state, solely from a finite set of outputs (in finite time).&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The contrast, a non-observable system, has some internal state we cannot infer just by looking at the outputs over some time frame.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Credit should be given to Charity Majors for transplanting this idea into tech (thank you!), and also creating a whole company around the idea (see &lt;a href=&#34;http://honeycomb.io&#34; class=&#34;bare&#34;&gt;http://honeycomb.io&lt;/a&gt; if you are interested).&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When we look at program output, we need to take a (w)holistic approach. There are the immediate replies to user requests; but there are also log lines, trace probes, metrics and so on. Everything can be considered an output, even if it is a side-effect of the primary computation. And that set is what we look at when we try to determine what is happening inside a running system.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Most computer systems are strictly non-observable. We don’t log the relevant information, we don’t have the relevant metrics, and we don’t have the ability to trace arbitrarily in most systems. As a result, we have no chance when a system misbehaves. In many cases we won’t even know that the system misbehaved in some way.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Logs, Metrics and Tracing are &lt;em&gt;necessary&lt;/em&gt; but certainly not &lt;em&gt;sufficient&lt;/em&gt; properties needed to achieve observability in a system. People will do all kinds of aggregations, filters, reductions and so on to their data in order to cut down on it.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Logs tend to have all kinds of problems associated with them. The good old syslog system has the problem it treats each line as a separate event. It also has no structure in the log lines. Asking questions in these are hell. A little better is if the log lines has structure, where the structure is flat. But the best situation is if you just log an Erlang term, and S-expression or the like, so you have all relevant information in the log line.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Metrics tend to aggregate. You know you had an error, but you don’t know any context. You also tend to have a temporal problem, in which you take 30 seconds of errors and store in one value. This makes spikes impossible to detect.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When people say tracing, they often mean “We added this static set of probe points to our code base, and we want to output all of those when we increase the log level.” People don’t enable this because it kills their production servers with on-disk log writes.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;How we transplant the notion from control theory is a bit vague:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;We could treat the notion as a continous axis where systems can converge toward being (fully) observable.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;We could treat the notion as a discrete property. Either you have a system which is, or you have a system which isn’t.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;We could accept a discrete notion, but with partiality. In some cases our system is observable, but not in others. Then define a fully observable system as one which is observable in all cases.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Personally, I lean toward the latter of these. Suppose you have a fault in your software. If the fault can be found and fixed by looking at your systems output only, then the system was observable in this case. If, on the other hand, you need to reproduce the error in a development environment, attach a debugger, step through the program and scratch your head for several hours, the system was not observable.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I stress this is on a case-by-case basis. A system is 80% fault-observable if 80% of all faults are observable according to the above notion.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_crash_logs&#34;&gt;Crash Logs&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In Erlang systems, faults generate crashes. A crash log contains:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;The current stack trace of the failing process&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The last event the process received&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The state of the process &lt;em&gt;before&lt;/em&gt; processing said event&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;My experience is that often, this is enough to provide observability in a fault scenario. You can work from the state and figure out how the event might have lead to the stack trace. In particular you can often figure out what code path was taken and how that would lead to the faulty situation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Most other systems has a state space which are several gigabytes in size. So small dumps like these are &lt;em&gt;impossible&lt;/em&gt; since we cannot find the relevant piece of information. In contrast, process isolation in Erlang can often limit us to the core state for the fault.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;What you &lt;em&gt;can&lt;/em&gt; and should do, however, is to take all coredumps and move these into persistent storage. If your core dump dies with your container, you have no post-mortem debugging and you will not be wiser. In some situations, if you can detect the fault, you can force the core-dump so you have a state you can inspect.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sect2&#34;&gt;&lt;h3 id=&#34;_assertions&#34;&gt;Assertions&lt;/h3&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;If you assert your invariants in your code, then Erlang systems will crash if an invariant is broken, which leads to crash logs for the faulty process. Erlang systems often assert processing as they are executing. This vastly increases cases where the system is observable. As an example, suppose you open a file on disk. You assert that you successfully open the file. If any error occurs, this produces output which allows you to observe the fault.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The key insight is that you don’t know which kind of fault is occurring. It could be that the file is not existent. Or you don’t have access to the file. So by asserting on any non-successful return, you get to learn important information necessary for internal-state-reconstruction. This information is added to the context of the crash log. In erlang systems you often see &lt;code&gt;{ok, _} = file:open(FName)&lt;/code&gt; which asserts the intended operation.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_dynamic_tracing&#34;&gt;Dynamic Tracing&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Tools such as dTrace, eBPF, and the built-in Erlang tracer are tools which can make a system observable. If a fault is detected, you can trace the fault in detail and capture enough information about the fault such that it becomes observable.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Note that the system doesn’t start out as being observable. You often encounter the fault, and scratch your head. Then you add tracing which is specific to a user-id, or a type of request. This trace is what changes the system, dynamically, from a non-observable system to one that is. Once the fault has been dealt with, you can go back and disable tracing.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Tracing is dynamic though. You cannot just add some extra lines to the code and then redeploy to capture the problem. You need to be able to change the system while it is in operation, and without having an impact on the system. The reason this is important is because the system might reset itself under a redeploy. Suppose you have a data structure which some times ends up in a pathological state making your system slow. If you redeploy, you reset this data structure, so now you cannot figure out why it is slow. This is why you need to be able to query the system dynamically.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Also, the impact of adding tracing must be proportional to the haystack/needle problem you have. If you add tracing for a specific customer, we cannot have this affecting any other customer in the system. It might take weeks before we hit the fault again, so we need to have this enabled for a while. If tracing impacts the system efficiency, people won’t enable it in production. And all really interesting errors occur in production.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_cardinality&#34;&gt;Cardinality&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Consider the following:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;I know a web request happened&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I know a web request happened, and I know if it was &lt;code&gt;2xx&lt;/code&gt;, &lt;code&gt;4xx&lt;/code&gt;, &lt;code&gt;5xx&lt;/code&gt; or something else&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I know a web request happened, and I know the exact status code&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The last case of these can be used to derive the other two. But not vice versa. The last case also needs to store more information, because it needs to discriminate the exact status code. Now consider:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;I know the user id of the web request&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;If we have a million users, the space of possible values has a cardinality of a million. Storing this efficiently is non-trivial in most current systems. However, it is paramount to get a scenario where we can observe the system.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>Experience Report: Bidirectional type checking of GraphQL</title>
       <link>https://jlouis.github.io/posts/graphql-bidir-type-check/</link>
       <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/graphql-bidir-type-check/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The core idea of GraphQL is this: let clients have a small, typed,total, functional (declarative) language where they can push programs tothe server side. The server then interprets these programs andprovides data to the client. The natural core for this is a lambdacalculus: a GraphQL &lt;em&gt;fragment&lt;/em&gt; is a lambda over the free variables ofthat fragment, for instance. A &lt;em&gt;query&lt;/em&gt; is also a lambda, but novariables are free, and it is “exported” for others to use. The onlyreason it &lt;em&gt;isn’t&lt;/em&gt; a full functional core is because the currentlanguage is more familiar to typical client programmers.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sidebarblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;&lt;em&gt;Aside:&lt;/em&gt; GraphQL is the ultimate function-as-a-service implementation.In typical &lt;em&gt;serverless&lt;/em&gt; implementations of the FaaS scheme a clientcan execute a singular function on the server side at a time, withoutcaring about the underlying server infrastrucutre and its maintenance.GraphQL amends this by having the client push a program to the serverside, so part of the client runs server-side, using the predeterminedfunctions in the GraphQL Schema. How the functions are implemented,executed and maintained is ignored by the client. It only knows of theGraphQL endpoint as a factor.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This empowers clients and makes software be driven by client code. Italso improves latency since the program is executed server-side with&lt;em&gt;locality&lt;/em&gt;. And it empowers clients with flexibility insofar theserver can evolve and adapt without clients having to change. &lt;em&gt;End of Aside&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Because we are working with a language, the best way to approach theproblem is to treat it as such. Processing GraphQL requests runs thenormal gauntlet of a interpreter:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Scan incoming byte stream into tokens&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Parse tokens into an abstract syntax tree&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Elaborate the tree and type check it as well&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Execute: use an interpreter to execute the request&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;It is important to stress interpretation is often enough. In a typicalimplementation, the work done in the execution phase is not where timeis spent. Usually, we measure the time in μs for the interpretationstep, whereas reading data is usually more costly in the ms-range. Ifyou have any distributed access in the query, that is going to bewhere time is spent. The only counter-example is when you have alldata in memory on the Erlang node, readily available. In principle,you could pre-compile an execution to Erlang code, and then directlyexecute said code if this proved to be too slow. But we aren’t thereyet in the current implementation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The Erlang implementation currently uses interpretation directly onthe AST and doesn’t compile via a Lambda calculus core. This, I think,is mostly a mistake to be fixed at a later point in time.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_type_checking&#34;&gt;Type checking&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In the GraphQL &lt;a href=&#34;https://graphql.github.io/graphql-spec/&#34;&gt;specification&lt;/a&gt;,there are two sections of interest: &lt;em&gt;Type System&lt;/em&gt; and &lt;em&gt;Validation&lt;/em&gt;.Where you &lt;em&gt;can&lt;/em&gt; execute a GraphQL request without worrying about itswell-typedness, it seems rather futile to do so. So we decided to bakethe validation into a proper checking phase in the engine.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In hindsight, we think this has been the correct choice. The languageis quite amenable to a classic operational semantics on its types. Thetransformation into a proper logic uncovered many corner cases in thespecification which needed clarification. Also, we’ve given opinionsfrom time to time on the specification based on what is possible in alogic, and also what is easy to implement in a logic. This helpscoherence of the language quite a bit.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The first type checker we wrote were based on a classic algorithm. Ithad many bugs, mostly because it was built and extended as we wentalong implementing more and more language features. So with thatexperiment behind us, we embarked on the idea to rewrite it using amore modern style, hopefully simplifying and squashing further bugs inthe process. At this point, we had a sizable test suite, so a rewritewould not introduce too many futher faults.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I’m pretty sure bidirectional type checking is part of the folk-lore,but there are some really good expositions on them. One is written byDavid R. Christensen, and another by Frank Pfenning:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://davidchristiansen.dk/tutorials/bidirectional.pdf&#34; class=&#34;bare&#34;&gt;http://davidchristiansen.dk/tutorials/bidirectional.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~fp/courses/15312-f04/handouts/15-bidirectional.pdf&#34; class=&#34;bare&#34;&gt;https://www.cs.cmu.edu/~fp/courses/15312-f04/handouts/15-bidirectional.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Once you start using this style of type checker, you will want towrite every type checker in this style.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sect2&#34;&gt;&lt;h3 id=&#34;_the_core_idea&#34;&gt;The core idea&lt;/h3&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The key observation is that type checking can be split into a coupleof different building blocks. Once these blocks are established, wecan recombine them, as you would in typical algebraic fashion. Thereare obvious similarities to attribute grammars, as we will see.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;We split type checking into three building blocks. We annotate eachentry with a &lt;code&gt;+&lt;/code&gt; if they are given (have positive mode in therelation), and &lt;code&gt;-&lt;/code&gt; if they are returned by the algorithm (havenegative mode):&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Synthesis/Inference: &lt;code&gt;G+ |- e+ ⇒ t-&lt;/code&gt; given an environment &lt;code&gt;G&lt;/code&gt; and anexpression &lt;code&gt;e&lt;/code&gt;, we figure out a type for it, &lt;code&gt;t&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Checking: &lt;code&gt;G+ |- e+ ⇐ t+&lt;/code&gt; check that the expression has given type&lt;code&gt;t&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Subsumption: &lt;code&gt;sub t+ s+&lt;/code&gt; check that the type &lt;code&gt;t&lt;/code&gt; is a subtype of&lt;code&gt;s&lt;/code&gt;. That is that &lt;code&gt;t&lt;/code&gt; “fits inside” &lt;code&gt;s&lt;/code&gt; in an obvious fashion.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The reason one wants to split into these building blocks are that thetype checker becomes simpler. You so-to-speak use checking to pushdown information you have into subexpressions, and then use synthesison the way to switch judgement mode and gather knowledge about types.This pendulum of back-and forth between the two building blocks makesa lot of type checking rules simple. The subtype relation is used toverify you don’t break rules along the way.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;&lt;em&gt;Example:&lt;/em&gt; If we have a type which is non-nullable in GraphQL: &lt;code&gt;t!&lt;/code&gt;and we are checking it against a type &lt;code&gt;s&lt;/code&gt; which is nullable. Then thisamounts to ignoring the non-nullability and check &lt;code&gt;t&lt;/code&gt; against &lt;code&gt;s&lt;/code&gt;.This is because a non-nullable value is “stricter” than a nullableone and fits nicely inside it.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;A typical pendulum operation when checking a request is that of aschema-lookup. To check against a given type we synthesize aschema-lookup, hence obtaining a proper type for the subexpression,which we then proceed to check.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;What is omitted in the above, compared to the real checker, is that wealso &lt;em&gt;elaborate&lt;/em&gt; the AST. We annotate the tree with the types wefound. This eliminates a lot of later hash-table lookups because theneeded type information is already in the tree.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Also, literal values are input-coerced in the type checker. This isdone as a partial execution of the query for the parts which areconstant.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect2&#34;&gt;&lt;h3 id=&#34;_flow_polarity&#34;&gt;Flow Polarity&lt;/h3&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The second observation is that in GraphQL, there are two major flows:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Input: Client → Server (positive flow)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Output: Server → Client (negative flow)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In turn, every GraphQL term is either present in one or both of theseflows. For instance, an &lt;em&gt;input type&lt;/em&gt; has positive flow, whereas anobject type returned has negative flow. There are also nonpolar flowsin scalars and enums.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The flows guide how one should check against types. In the positiveflow direction, we cannot trust the client, but the GraphQL schema onthe server side can be trusted. Hence, we should recurse over the typesof the schema, not what the client provided. This guards against theclient omitting a required argument for instance.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In contrast, the negative flow reverses the recursor: here, we areonly interested in what the client wants, so we only check thosevalues. If the schema/server provides more values but they areillegal, they are ignored since the client did not request them.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Using these observations, it is possible to figure out many questionsone might have when writing the type checker. Most loops writethemselves based on the flow rules. And most checking rules writesthemselves via the three bidirectional building blocks. Theconsequence is a small and lean type checker for GraphQL.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_results&#34;&gt;Results&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;sect2&#34;&gt;&lt;h3 id=&#34;_code_size&#34;&gt;Code size&lt;/h3&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The approach used here currently amounts to about 1000 LOC, includingcomments. The reference implementation uses around 3500 LOC on thesame thing, also including comments.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In addition, our code reads as typical operational semantics, whichmakes it far easier to validate and verify. Many bugs have been fixedby addition of a simple rule, or rearrangement of the rule checkingorder.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;If one wanted to translate GraphQL type rules into a logical frameworksuch as Twelf, or into a proof assistant such as Agda, it should befairly straightforward. Also, the static semantics in operational formshould be easier to write down if one wanted a more formal approach tothe type checking of GraphQL.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect2&#34;&gt;&lt;h3 id=&#34;_speed&#34;&gt;Speed&lt;/h3&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The type checker usually runs much faster than the interpreter phase.A query is static, and not executed per fetched node, whereas theinterpreter has to walk over data returned. Factors of 1000:1 in favorof the type checker is not unheard of. This argues one should writethe type checker for simplicity rather than speed.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>{&#39;EXIT&#39;, joe, goodbye}</title>
       <link>https://jlouis.github.io/posts/joe-goodbye/</link>
       <pubDate>Sun, 21 Apr 2019 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/joe-goodbye/</guid>
       <description>&lt;div class=&#34;quoteblock&#34;&gt;&lt;blockquote&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Jesper, I have this idea in which we’ll connect &lt;em&gt;all&lt;/em&gt; of the worldsErlang systems to each other, imagine if every process could talk toevery other process, world-wide!&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div class=&#34;attribution&#34;&gt;— Joe Armstrong&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Joe was never short on ideas when you spoke to him. At conferences, hewould engage people with his newest idea, or he would find peopleacross the room and connect them. This often resulted in newacquaintances, interesting conversations, and new insights. Joe actedas the fountain from which insights sprang. He always had a newproject going, and was keen to tell about it.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Joe would speak to everyone. It didn’t matter if they were new to theworld of Erlang, or computers, or if you had 20 years of experience.He would quickly find your level, and then discuss at that level.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In my mind, three rules embodied the ideas of Joe:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;They were always practical and wanted to solve a grand problem withcomputers. Most often, the limitations of physics played a role.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;They always felt a little bit crazy, mainly due to the novelty ofthe idea.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;They were going to restructure your brain, and how you thought aboutstuff.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When I was writing a BitTorrent client for Erlang, Joe was quick tocomment on the code “This part uses defensive code style, you canprobably just let it crash.” It took some years for that lesson tofully sink in, as it did with most of Joes stuff. He would gentlynudge you in a direction, and by following his trajectory, youlanded perfectly.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Most people reading this will know Joe for his work on Erlang. But hehad lots of ideas, and not all of them pertained directly to Erlangitself, though it was often the vehicle. He had a keen interest inmusic and did collaboration on the Sonic Pi with Sam Aaron. Up untilrecently, Joe was working on improving wiki tooling. In particular,he’d realized how he needed a quine,&lt;sup class=&#34;footnote&#34;&gt;[&lt;a id=&#34;_footnoteref_1&#34; class=&#34;footnote&#34; href=&#34;#_footnotedef_1&#34; title=&#34;View footnote.&#34;&gt;1&lt;/a&gt;]&lt;/sup&gt; the wiki should contain its own source codeso it could reproduce itself. This would ensure the longevity of thewiki. This work was in April 2019, so he was working on stuff up untilhis untimely death.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Joe liked to find minimal solutions to problems. He would strip layerupon layer off a problem until he had the core. He created a stack ofuniversal binary formats, UBF. The ingenious part of this was that totransfer a term, one would transfer a &lt;em&gt;program&lt;/em&gt; which when executed ona small stack-based virtual machine would yield said term. And thecommands were chosen from the printable ASCII alphabet.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The higher layers in the stack was the basis for a lot of discussionsI had with Joe. Both of us agreed that what happens “inside” anErlang process wasn’t that interesting in the grand scale of things.It was the communication which was important, and it should have acontract system. Joe had certainly invented most of this before Ieven started looking at Erlang as a language. And I still—​to thisday—​believe that this is future of protocol communication.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;To see how visionary Joe was, his idea was to use such a contractsystem to get any Erlang process on any node to talk to another Erlangprocess, somewhere out in the universe. Essentially, this gives you“Serverless” operation, so he was a couple of years ahead of thepack on that.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Joe also wanted to mix this with a content addressable storagespanning the internet. He would speak fondly of IPFS which to a largeextent was this vision. The main idea is to generate the reference keyfor data from the data itself, usually a cryptographic hash over thedata. This in turn provides integrity: if the data changes, so doesits key. Now, if you refer to data by its key, then you can verify yougot the right data. Joe wanted to use this as a basis for software:“I can send you the hash, and you can fetch the library if you don’thave it.” he told me. He also wanted to use this idea to protect oldsoftware so “It could still run after many years.”--another reasonJoe preferred minimalistic approaches to software. “You see, apackage version is the hash of its source code, not a version number,that would be silly.”&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;He was adamant on making computers useful.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The greatest brain restructure, however, was always in the idea thatyour abstract logic of a program &lt;em&gt;has&lt;/em&gt; to execute in the physicalenvironment. This meant coping with failure when it happened as theonly way to build robust software. Programming without this profoundinsight—​software cannot proactively remove all error—​is as silly asit is dangerous in hindsight.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Once you embrace fault tolerance, then you have the feeling of a burdenreleased, and programs gets far easier to write. Of course, the moreseasoned programmer knows when you can be proactive and when you haveto be reactive. But if there one thought which has shaped the way Ithink about programming the most, it is this.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The second greatest brain restructure was Joe’s dismissal ofperformance in software. In a post to the Erlang mailing list, Joewould come up with the following table:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre&gt;This is what we do: (We = ///)    1) hack it in erlang    2) fast enough - ship it    3) tweak the erlang    4) fast enough? - ship it    5) hack it in C?    6) fast enough - ship it    7) tweak the C    8) fast enough? - ship it    9) make an FPGA    10) fast enough - ship it    11) make an ASIC    12) fast enough - ship itAs you go down this list things cost more and more - step 11 costs1M$/try - to pass step 9you need to have a high volume product (10&amp;#39;s to hundreds of thousands of units)&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The core idea is that if you want to go really fast, you need toimplement hardware specific to the problem, and you can only hope totweak the software so far in performance. And he would make a pointabout setting up a specified target before starting the tweakery, soyou’d know when to stop. Over the years, I’ve veered in the samegeneral direction as Joe.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;One thing I liked about Joe was his fearless approach to computing andto life. He’d never bow to authority. He’d would never be afraid toprovoke if it was necessary. He never ever stopped R&amp;amp;D. He wouldtinker with things until he understood them, then find something newto look at. But only after he told you about his findings. Sharing washis modus operandi.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;At conferences—​in which Joe was an attendant—​there would be thishallway track going on where people would talk with Joe. A slot would beskipped here and there. But some interesting conversation would behad, and people would convene around him in a circle that grew everlarger. I’ve watched more than once when a “innocent bystander” wasdrawn into his web of stories, findings, and insights.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Being a speaker with Joe in the audience was always a blast. Once hesensed he was allowed to interact, you could be sure he would“heckle” your talk in the most awesome way. It only took a smirk andyou saying &lt;code&gt;{hello, joe}&lt;/code&gt; and that would be his cue. We should havemic’ed him up at times.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When he did speak up, he would often frame a question such that it puta speaker in a position where they could really show their work. Neverhave I heard a bad question by Joe.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This was the Joe I knew. I think we owe him a lot with regard topushing software and computer science ahead. The best we can do is tomake sure his grand ideas are not lost upon us, and that they areimplemented in the future to come.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;And then perhaps, we will reach a point where Joe’s prediction fromthis Month will ring true:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;quoteblock&#34;&gt;&lt;blockquote&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;One day computers might become useful.&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div class=&#34;attribution&#34;&gt;— Joe Armstrong&lt;/div&gt;&lt;/div&gt;&lt;div id=&#34;footnotes&#34;&gt;&lt;hr/&gt;&lt;div class=&#34;footnote&#34; id=&#34;_footnotedef_1&#34;&gt;&lt;a href=&#34;#_footnoteref_1&#34;&gt;1&lt;/a&gt;. A quine is a self-reproducing program&lt;/div&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>An Erlang/OTP 20.0 optimization</title>
       <link>https://jlouis.github.io/posts/an-erlang-otp-20-0-optimization/</link>
       <pubDate>Sat, 06 May 2017 00:00:00 +0200</pubDate>
       
       <guid>https://jlouis.github.io/posts/an-erlang-otp-20-0-optimization/</guid>
       <description>&lt;h2 id=&#34;an-erlangotp-200-optimization&#34;&gt;An Erlang/OTP 20.0 optimization&lt;/h2&gt;&lt;p&gt;&lt;em&gt;Edit: some word choices have been altered slightly in order to make some parts more clear.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;This is a short blurb about a specific optimization present in Erlang 20.0 which is scheduled for release in June 2017. The README file mentions the following:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;OTP-13529 Application(s): ertsErlang literals are no longer copied during process to process messaging.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And there have been a couple of questions as to what that is and means. Suppose we have the following little Erlang module:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;-module(z).-export([f&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]).&lt;span style=&#34;color:#a6e22e&#34;&gt;bin&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Some binary value&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; #{ a &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, b &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello&amp;#34;&lt;/span&gt; }.&lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; {bin(), map()}.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;which we now compile with beam instruction output (where the instructions are represented as Erlang terms):&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;erlc &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;S z.erl&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The beam data is dumped in &lt;code&gt;z.S&lt;/code&gt; which we can read in and look at. First comes a couple of standard header stuff:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;{module, z}.  &lt;span style=&#34;color:#75715e&#34;&gt;%% version = 0&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;{exports, [{f,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;},{module_info,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;},{module_info,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;}]}.{attributes, []}.{labels, &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;}.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, our functions follow. First, the &lt;code&gt;bin&lt;/code&gt; function:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;{function, bin, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;}.  {label,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;}.    {line,[{location,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;z.erl&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;}]}.    {func_info,{atom,z},{atom,bin},&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}.  {label,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;}.    {move,{literal,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Some binary value&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;},{x,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}}.    return.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The function is executed by running label 2. Note that this is a &lt;code&gt;move&lt;/code&gt; instruction of a &lt;em&gt;literal&lt;/em&gt; value into the register &lt;code&gt;x0&lt;/code&gt;. The Erlang system stores such literals off-heap and ready for reference. The &lt;code&gt;map&lt;/code&gt; function is the same. Since the map is just a constant value, we can represent it as a literal value outside the heap:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;{function, map, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;}.  {label,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;}.    {line,[{location,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;z.erl&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;}]}.    {func_info,{atom,z},{atom,map},&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}.  {label,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;}.    {move,{literal,#{a &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,b &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello&amp;#34;&lt;/span&gt;}},{x,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}}.    return.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, the function &lt;code&gt;f/0&lt;/code&gt; follows. This function allocates a stack slot, calls &lt;code&gt;bin()&lt;/code&gt; to get the first literal and stashes it in the stack slot. Then calls &lt;code&gt;map()&lt;/code&gt; to get the second literal. Now, a tuple is allocated on the heap and the two literal vales are put inside the tuple. Finally, the tuple is returned in the &lt;code&gt;x0&lt;/code&gt; register and we reestablish the original stack by de-allocating the extra slot we used:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;{function, f, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;}.  {label,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;}.    {line,[{location,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;z.erl&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;}]}.    {func_info,{atom,z},{atom,f},&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}.  {label,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;}.    {allocate_zero,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}.    {line,[{location,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;z.erl&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;}]}.    {call,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,{f,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;}}.    {move,{x,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;},{y,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}}.    {line,[{location,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;z.erl&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;}]}.    {call,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,{f,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;}}.    {test_heap,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;}.    {put_tuple,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,{x,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;}}.    {put,{y,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}}.    {put,{x,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}}.    {move,{x,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;},{x,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}}.    {deallocate,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;}.    return.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The Erlang system gains many benefits from literal values since they are easy to reference from multiple processes and are generally “free” values to work with. However, in Erlang versions before 20.0, when you send a literal as a message, it is copied into the message as an ordinary value. This means you lost the beneficial sharing that is going on with the literal value.&lt;/p&gt;&lt;p&gt;The code for message passing in Erlang/OTP 20.0 now handles literal values directly. Rather than copying the contents of the literal into the message, we pass a pointer to the literal area. Of course, in order to do this safely, you must ensure the invariants of literal values are in place. In particular, the literal lives in a module, and if that module is purged from the system, the literal value must be saved somewhere else so references to it are preserved.&lt;/p&gt;&lt;h3 id=&#34;why-does-itmatter&#34;&gt;Why does it matter?&lt;/h3&gt;&lt;p&gt;This change is one which is rather classic for the Erlang BEAM VM over the years. Most systems won’t need this in normal operation, but it helps a little bit along the way. And a few systems will have a tremendous amount of help from this change.&lt;/p&gt;&lt;p&gt;If you value long-running systems without restart, it tend to be the case that the errors you have to fix becomes more and more outrageous. The kinds of errors which makes the system fail in the end require complex interactions between several subsystems. Added memory pressure is among them. Robust operation contains more than simply efficiency, albeit this change also optimizes the system.&lt;/p&gt;&lt;h3 id=&#34;the-compile-module-hack&#34;&gt;The compile-module hack&lt;/h3&gt;&lt;p&gt;A hack that has seen some use throughout time is that if you use a tool such as &lt;code&gt;merl&lt;/code&gt; to construct a module and then compile the module, its literals are essentially “free” in the Erlang VM. Thus, you can avoid some memory pressure if you need some kind of data lookup table — and the table has the property it stays mostly the same and rarely changes. You simply recompile and hot-load the new table on change.&lt;/p&gt;&lt;p&gt;With this change, the compile-module hack is even more powerful, because you can pass the values around between processes without risking a copy and thus increased memory pressure.&lt;/p&gt;&lt;p&gt;All in all, it looks like it is a neat optimization.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Full Queues and Their Woes</title>
       <link>https://jlouis.github.io/posts/full-queues/</link>
       <pubDate>Sat, 18 Feb 2017 00:00:00 +0100</pubDate>
       
       <guid>https://jlouis.github.io/posts/full-queues/</guid>
       <description>&lt;p&gt;Suppose you have a bounded queue of size 10. In a normal setting, you system may load this queue with up to 5 elements. Under load, the queue might increase to say 7 or 8 elements, but you are not going to reach the bound of the queue. Typically the queue is empty, some elements gets added to the queue and then drained again by processing.&lt;/p&gt;&lt;p&gt;In contrast, suppose the queue is full at 10 elements, and that the load increases on the queue. The additional load has to be dropped, and this is a nice feedback mechanism which tells the caller that you have an overload situation. But also note, that you losing information: namely how much additional load that were added on the system. Unless you add some kind of ghost-counter to your queue, so you know how much data you dropped recently, you have no idea of the load situation apart from the fact that the system is over its load capacity.&lt;/p&gt;&lt;p&gt;There are many situations in software engineering where this basic principle applies to your organization. Your queues can’t run at the full capacity because then you lose the ability to see what fluctuations are happening. A solution is to track “ghost entries” of your queues. That is, track elements beyond the queue limit with a count only and a timestamp, not storing data. When consuming a ghost-entry, it is consumed immediately, its processing time not counted against the normal processing time. Above a certain amount of ghost entries, you stop caring about them, but it allows you to answer the question of what would happen should you increase the queue a bit in size.&lt;/p&gt;&lt;p&gt;I claim full queues tend to be a pattern to avoid in software engineering. When you reach the bound, something is amiss in your internals, and you better engineer yourself around that than letting the queue bound be the controller of the flow. When a value is at its maximum, you can’t measure what lies beyond. Interestingly, there are many similar situations, where the concept of a“full” resource blinds you to information that would otherwise have been useful.&lt;/p&gt;&lt;p&gt;One example is the recently developed BBR congestion control mechanism for TCP[0]. Standing network buffers as queues has been a bane of modern networks for a while now (see BufferBloat). The problem is that in order to stop packet loss, manufacturers add yet more buffers to their equipment and the result is that the TCP algorithm fills up these queues. When this happens, we see increased latency and jitter in our TCP connections, which makes the internet unsuitable for low-latency operations. Luckily BBR is a promising fix for these problems.&lt;/p&gt;&lt;p&gt;In the BBR-algorithm, it is noted that if a TCP link runs at the full bandwidth utilization, it is impossible to detect a standing queue in the network. In order to optimize latency, the algorithm periodically lowers the bandwidth in order to detect if there is a queue which should be drained in the network. This is exactly the problem of an overflowing queue as above. At the maximal bandwidth, data enters the queue at exactly the same rate as it leaves. So we can’t detect if there is a standing queue in the system. But if we lower the bandwidth utilization, we run the risk of less efficiency in the link. So hence the periodic probing.&lt;/p&gt;&lt;p&gt;Another example is to run your development team at 100% utilization. If something unforeseen emerges, there is no slack utilization to use, and hence someone has to work overtime to handle the situation or you have to move a deadline. You are essentially in an overflow situation, and thus you can’t detect and react to events beyond the barrier. Had you dropped utilization to, say, 60–80%, then emergencies can be handled as they appear. This is also an example of a “full queue” which permits no flexibility. What usually happens is that the deadline gets moved. And now everyone is unhappy because the deadline was moved.&lt;/p&gt;&lt;p&gt;Worse, good ideas doesn’t happen at 100% utilization. They happen when you have some slack in the schedule and can spend some extra time tuning parts of the system as it goes along. In any kind of process planning in a factory, people know the price of running the plant at 100% utilization: it gets sensitive to small errors. So nobody does that.&lt;/p&gt;&lt;p&gt;The same applies to consultancy: run your consultants at 100% utilization, and there will be no way your consultants can stay ahead of the curve by gaining new knowledge. Worse, it is often hard to spread information between consultants when they are all working at 100%. This means knowledge doesn’t get anchored in the business and you lose valuable information you learned on a project.&lt;/p&gt;&lt;p&gt;A full queue in a Go program means that you have a critical path blocking the speed of the program. But it has no dualized shadow-pricing[1]: if the impeding path is unblocked or removed, you don’t know where the next bottleneck is going to be. If the queue is not full, you can measure the relative change in the queue which can tell you where to worry next.&lt;/p&gt;&lt;p&gt;If a system is at 70% CPU load, you know that it can handle more work before succumbing to increased processing latency. But at 100% CPU load, you don’t know if your system is overloaded and thus queuing work, or if it is an Erlang system that is just using the additional resources for background processing work. The former is probably bad.&lt;/p&gt;&lt;p&gt;Another applicability of the idea is that of Netflix“Chaos Monkey”. A system with 100% uptime over a period will not probe any kind of recovery scenario. Thus, your environment is blind to partial failure of subsystems. The Chaos Monkey introduces errors in the system which then works as “checks &amp;amp; balances” making sure other subsystems can cope with partial failure. Amazon’s AWS also seems to be using fault injection methods to make sure systems running on their infrastructure can cope with transient errors[2]. Suppose that the normal injection rate is 1 in a 1,000,000. Then if the error rate increases to 1 in a 1,000 suddenly, the systems will still cope.&lt;/p&gt;&lt;p&gt;As already written, this insight is well-known. Don Reinertsen[3] has addressed this over the course of many years. At high levels of use, the system can’t cope with more load and it becomes more sensitive. In turn, productivity of the system as a whole tend to falter when this happens. The principles, as this post hopes to show, are widely applicable to more than a single field. The whole concept of “overflow” is dangerous in systems. It is also a good reason for being wary about “bounded queues”. It is better to build a load regulation system on top of an unbounded queue than it is to hard limit the queue bound. It solves the problem, but it pries you from valuable information. At the very least, use something like a ghost-list or provide a warning whenever a queue grows full.&lt;/p&gt;&lt;p&gt;The ghost-list idea on queues are taken from the ARC cache of ZFS. Starting from the well-known LRU cache, where we knock out the least recently used element from a full cache, we start with an observation: entries which are only referenced once in the LRU cache are wasted space. The 2Q cache solves this by having two caches. One cache runs as an LRU cache, but elements are promoted to the second cache if they have been referenced more than once. It only takes a single bit to handle this, and it wipes out the lone stragglers in the LRU cache.&lt;/p&gt;&lt;p&gt;ARC improves on the 2Q scheme by observing that the sizes of the 2 caches are static in 2Q. A ghost entry is an entry in the cache referenced by key only. It doesn’t take up much space. Whenever we boot out an element, we keep a ghost key for that element. By keeping ghost-entries for each cache, it is possible for ARC to answer the question “if we had a bit more cache space, would we have been able to successfully hit this element?” And that can guide automatic sizing of the two caches in a 2Q cache (this is a much condensed description, papers have the details).&lt;/p&gt;&lt;p&gt;[0] Cardwell, Cheng, Gunn, Yeganeh, and Jacobson &lt;a href=&#34;http://queue.acm.org/detail.cfm?id=3022184&#34;&gt;http://queue.acm.org/detail.cfm?id=3022184&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[1] In linear and mixed-integer programming, this is often used in order to build “what-if” scenarios.&lt;/p&gt;&lt;p&gt;[2] This is based on intuition on my part. Their network engineers are way better than the fault rate we are seeing, so we can only assume they have built the system to inject faults.&lt;/p&gt;&lt;p&gt;[3] &lt;a href=&#34;https://www.amazon.com/Principles-Product-Development-Flow-Generation/dp/1935401009&#34;&gt;https://www.amazon.com/Principles-Product-Development-Flow-Generation/dp/1935401009&lt;/a&gt;&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Testing a Parallel map implementation</title>
       <link>https://jlouis.github.io/posts/testing-parallel-map/</link>
       <pubDate>Tue, 20 Oct 2015 00:00:00 +0200</pubDate>
       
       <guid>https://jlouis.github.io/posts/testing-parallel-map/</guid>
       <description>&lt;p&gt;Erlang programs, often have a a list comprehension which implements the ubiquitous serial map of functional programming:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt;(F, Xs) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  [F(X) || X &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; Xs]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If, however, the function given as &lt;code&gt;F&lt;/code&gt; blocks, then the map function blocks as well. This is not a desirable situation if the elements in &lt;code&gt;Xs&lt;/code&gt; are truly independent. We could run all of the comprehension in parallel and then collect the data afterwards. This is the purpose of the pmap function:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;pmap&lt;/span&gt;(F, Es) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;     Parent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self(),     Running &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [           spawn_monitor(&lt;span style=&#34;color:#66d9ef&#34;&gt;fun&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; Parent &lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt; {self(), F(E)} &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;)         || E &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; Es],     collect(Running, &lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt;).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The idea here is we spawn each work unit as a function, and attach a monitor to the spawned function. Once the computation is done, we send the result back to the invoker of pmap/2 together with the pid() of the spawned function. This monitor/pid acts like a future[0] which we can use to later collect the running processes:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;collect&lt;/span&gt;([], _Timeout) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [];  collect([{Pid, MRef} | Next], Timeout) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;receive&lt;/span&gt;      {Pid, Res} &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;        erlang:demonitor(MRef, [flush]),        [{ok, Res} | collect(Next, Timeout)];      {&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;‘&lt;/span&gt;DOWN&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt;, MRef, process, Pid, Reason} &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;        [{error, Reason} | collect(Next, Timeout)]    &lt;span style=&#34;color:#66d9ef&#34;&gt;after&lt;/span&gt; Timeout &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      exit(pmap_timeout)    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There are two cases of collection. Either there are no processes spawned, in which case we can return the empty list. Or we have a pair of a PID and a MonitorRef. In this case, we do a selective recieve from the mailbox in which we expect a result containing the PID. This ought to force the order in which we receive answers to be the same as the order in which the worker processes were invoked.&lt;/p&gt;&lt;p&gt;Once we have the result, we remove the monitor and set the ‘flush’ option to make sure it gets wiped from our mailbox as well should it have made its way in there. Then we recursively collect more results.&lt;/p&gt;&lt;p&gt;Two error paths exist, which we must handle. If the call F(X) in the process fails to return, then we must handle this error. Since we have a monitor on the process, this will result in an asynchronous ‘DOWN’ message sent into our mailbox. So we grab that and return it as an error.&lt;/p&gt;&lt;p&gt;Finally, if we are blocked for more than Timeout milli-seconds, we regard the computation as a whole as an error and crash ourselves. Your mileage may vary here, but for my purpose this is an adequate assumption to make.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Writing the function is only half the battle. How do we test it? There are three major properties of the parallel map function which makes it fairly easy to write a test for:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;It should behave the same as the serial version of a map, as written above.&lt;/li&gt;&lt;li&gt;The fact that we are concerned about blocking behavior is not important in the test.&lt;/li&gt;&lt;li&gt;It has the signature of a purely functional function. Even though its implementation internals are not, any user of the function can regard it as being a purely functional implementation. Had this been OCaml or Standard ML, the module abstraction would be able to hide the fact we are using parallel invocation behind the scenes.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;However, there is also a property which makes it fairly hard to write a test for: if running a test case, it is very likely we will get the same schedule every time we run. So unless we block in the &lt;code&gt;F&lt;/code&gt; function, we can’t test alternative schedules.&lt;/p&gt;&lt;p&gt;Blocking in a test case makes it slow. So now we have the option of not testing alternative schedules, or slowing down the tests it seems. There is a way around this in Erlang which is to start the VM with the &lt;code&gt;+T&lt;/code&gt; flag. This flag will randomize the scheduler and if we then run many tests back to back, we will eventually get alternative schedules.&lt;/p&gt;&lt;p&gt;In this exposition, we will explore another path: Quickcheck and PULSE[1]. We note that we can write a fully stateless test for the parallel map function, and then we can use PULSE to randomize the scheduler of Erlang. An added benefit of this approach is that PULSE automatically compresses time: if every process under its control are sleeping, it will “forward” time to the next point at which something interesting happens. We start out by writing a testing module:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;-module(dht_par_eqc).  &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;compile(export_all).  &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;include_lib(&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;“&lt;/span&gt;eqc&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;include&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;eqc.hrl&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;).  &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;include_lib(&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;“&lt;/span&gt;pulse&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;include&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;pulse.hrl&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And then we write down a crasher function:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;crasher&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;     &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;LET(F, function1(int()),       &lt;span style=&#34;color:#66d9ef&#34;&gt;fun&lt;/span&gt;         (&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; timer:&lt;span style=&#34;color:#a6e22e&#34;&gt;sleep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;6000&lt;/span&gt;); &lt;span style=&#34;color:#75715e&#34;&gt;%% Fail by timing out&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;         (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; exit(err); &lt;span style=&#34;color:#75715e&#34;&gt;%% Fail by crashing&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;         (X) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; F(X) &lt;span style=&#34;color:#75715e&#34;&gt;%% Run normally&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;       &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The idea of this function is that it generates a random function F and then alters it slightly: Giving it -1 will have it sleep for 6000ms. Giving it 0 will have it crash. And every other value it will behave as F.&lt;/p&gt;&lt;p&gt;We can also write down a function which explains the expected result of running the parallel map function:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;expected_result&lt;/span&gt;(F, Xs) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      &lt;span style=&#34;color:#66d9ef&#34;&gt;case&lt;/span&gt; [X || X &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; Xs, X &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;of&lt;/span&gt;          [] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;            [&lt;span style=&#34;color:#66d9ef&#34;&gt;case&lt;/span&gt; X &lt;span style=&#34;color:#66d9ef&#34;&gt;of&lt;/span&gt;               &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; {error, err};               N &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; {ok, F(N)} &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;             || X &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; Xs];          [_|_] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;              {&amp;#39;EXIT&amp;#39;, pmap_timeout}      &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We look for a value of -1. If this value is present, we expect the result to be a pmap_timeout. Otherwise, we run through the &lt;code&gt;Xs&lt;/code&gt; and analyze them one by one through a simple list comprehension, reflecting the responses from the crasher function.&lt;/p&gt;&lt;p&gt;The function here calculates the result as if it had been run serially. This ensures we verify that our parallel version has the same behaviour and interface as the serial version, with the small change that the function &lt;code&gt;F&lt;/code&gt; is run in a crash-resistent manner and errors are caught and transformed into terms.&lt;/p&gt;&lt;p&gt;Now, we can write down the main property. The idea is to generate a list of inputs in which error cases are present, but fairly rare. Once generated, we use the ?PULSE macro to run the parallel map under control of PULSE. Once we have a Result, we can verify that the result matches the expected output:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;prop_pmap&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;FORALL([F, Xs],              [crasher(),               list( frequency([                       {&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;},                       {&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;},                       {&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, nat()} ]) ) ],        &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;PULSE(Result, (&lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; dht_par:&lt;span style=&#34;color:#a6e22e&#34;&gt;pmap&lt;/span&gt;(F, Xs)),          &lt;span style=&#34;color:#66d9ef&#34;&gt;begin&lt;/span&gt;              Expected &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; expected_result(F, Xs),              equals(Result, Expected)          &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;)).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can use this to run numeruos test cases. Here we run the checker for 2 minutes:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; eqc:&lt;span style=&#34;color:#a6e22e&#34;&gt;module&lt;/span&gt;({testing_time, &lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;}, dht_par_eqc).prop_pmap: .........................................................................................................(x10)....................................................................................................(x100)....................................................................................................(x1000)..................................................................(x100).......Time limit reached: &lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; seconds.OK, passed &lt;span style=&#34;color:#ae81ff&#34;&gt;77800&lt;/span&gt; tests[]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In two minutes, we have generated 77800 test cases. Far more than we would have been able to with blocking calls in there. The power of PULSE shows itself since it realizes that the processes under its control can’t continue without time passing and then it automatically forwards time to the next event point.&lt;/p&gt;&lt;p&gt;[0] Note the notions of future and promise are not set entirely in stone. Here, a future is used in the meaning of a read-only value.&lt;/p&gt;&lt;p&gt;[1] PULSE is a scheduler randomizer. It will explore random schedules rather than use the standard Erlang schedule. It transforms Erlang code such that it runs under a manager process that control in which order processes are going to run. This allows you to weed out parallel bugs in the code base which are due to races in concurrent invocation.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>On Scalability, Capacity, and Sensitivity</title>
       <link>https://jlouis.github.io/posts/scalability-capacity-sensitivity/</link>
       <pubDate>Mon, 18 May 2015 00:00:00 +0200</pubDate>
       
       <guid>https://jlouis.github.io/posts/scalability-capacity-sensitivity/</guid>
       <description>&lt;p&gt;Often, when one hears the word “Scalable” used in a context, it is used in an informal way. It is a fuzzy term, used by people to say that their system can handle the future. As if one has divine knowledge of what happens.&lt;/p&gt;&lt;p&gt;What is often meant is how the system handles additional load, for some measure of load. That is, if a company is succesful, and it gains 10 times as many users as now, the system the company uses to run their business keeps operating with next to no perceivable drop in behavior. It is simply business as usual.&lt;/p&gt;&lt;p&gt;There are two ways to achieve this design goal: either design your system for handling the additional load vertically, or design your system so it can be copied horizontally. Scaling along the vertical axis amounts to buying more capable hardware and improving the software so it uses less resources. Scaling along the horizontal axis requires the system to interoperate in a distributed setting, where more than a single physical machine collaborates on handling the load.&lt;/p&gt;&lt;p&gt;But how does one really become scalable in the setting of the real world? As with so many others things in computer software, it is a property of your system architecture, not your programming language choice. That is, the limit is defined by how you constructed the system in the first place, and how you put together your technology stack. People may look down on PHP, but Facebook managed to use it in a way that scaled well, by coupling it with other solutions in the architecture.&lt;/p&gt;&lt;h2 id=&#34;capacity&#34;&gt;Capacity&lt;/h2&gt;&lt;p&gt;One key indicator of a system is its capacity. This measure defines how much simultaneous load your system can cope with. A telephony switch can be snapshotted in time and we can measure how many phone-call-channels are currently in use. This is the load in this setting, maybe set at 70 simultaneous calls. The capacity of the system is how many calls the system can ultimately handle. Maybe it has been certified up to 500 simultaneous calls, but under an emergency accident it has managed to handle 1243 calls. The number 500 is called the engineering capacity whereas 1243 is the peak capacity. For normal operation, you want to be within the engineered capacity of the system. But emergencies do happen and you get close to the peak of the system.&lt;/p&gt;&lt;p&gt;If load increases beyond the peak capacity we say we have an overload situation. How a system operates at the peak capacity and under overload is important for gauging how a system scales, vertically. If the system breaks when it is overloaded, it is likely the system was not built to withstand additional load. And usually the problems start showing up at lesser loads.&lt;/p&gt;&lt;p&gt;Two things often contribute negatively to the load one can handle:&lt;/p&gt;&lt;p&gt;If a data structure or algorithm operates on size n and n is small, the complexity of accessing elements in the data structure, or carrying out the algorithm, may appear to be O(1). But in practice, as n grows, the real complexity class will rear it’s ugly head. It may be O(n) or worse. In modern architectures the actual behavior is further perturbed by the presence of cache hierarchies and lock contention. As load increases, you may end up being pushed out of caches, or you may end up contending on a lock everyone wants access to. In a system nearing its engineering or peak capacity, it will be easier to discern how the algorithms or data structures operate.&lt;/p&gt;&lt;p&gt;The other case has to do with outliers in your data. Maybe the average number of zots a user of your system has is 5. But there is this one user, who has managed to amass 60000 zots. This user, and their zot-abundant siblings, are going to wreak havoc in your system. Your system will try to cope with them and in turn use lots of resources doing so. Some times crashes will occur, even though the system doesn’t appear to be especially loaded in the first place.&lt;/p&gt;&lt;p&gt;If you want a scalable system, you need predictability. In turn, it may not be that you want the fastest algorithm in the common case, if it proves to have bad behavior when the zot-abundant enters. It may be that you want to pick an algorithm that is stable, no matter what happens over one which is blindingly fast. A naive hash-table implementation can degrade if many collisions occur in ways a self-balancing binary tree cannot, for instance. But access in the binary tree is more expensive due to the additional need for key compares and memory reads. The naive hash table may also double its size when it runs out of space due to density. The binary tree uses more memory due to the high number of pointers, but on the other hand, its resource usage is more linear, allocating new internal nodes as it needs them in small sizes.&lt;/p&gt;&lt;h2 id=&#34;erlang-theunit&#34;&gt;Erlang (the unit)&lt;/h2&gt;&lt;p&gt;In queueing theory, an Erlang is defined as E = λ·h.&lt;/p&gt;&lt;p&gt;The λ defines a “call arrival rate” over some unit of time: web server requests per second, telephony calls per minute, and so on. The ‘h’ defines the average call-holding-time in the same unit as λ. So for web server requests where the average request time is 30ms, h = 30/1000. For the telephony example, the average call may be 146 seconds, so h = 146/60.&lt;/p&gt;&lt;p&gt;The Erlang unit, E, measures slightly different things. One way to interpret it is as “instantaneous traffic”, in which we snapshot the system at an instant in time, and measure the amount of simultaneous work. Another way to interpret the unit is that it measures “carried traffic” which is the average number of simultaneous work over a reasonably time period, for instance 15 minutes, one hour, or 1 minute, depending on what it is used for.&lt;/p&gt;&lt;p&gt;The formula E = λ·h defines the relationship between the arrival rate and the holding time. For example, if our system processes 50 reqs/s and each request takes 60ms on average, the system is loaded at 50 · (60/1000) = 3 erlang. If we can improve the system such that the average request takes 45ms, then the load is 50 · (45/1000) = 2.25 erlang.&lt;/p&gt;&lt;p&gt;Aside: One might see that this formula is essentially identical to Little’s Law. I don’t know the exact relationship here, and my searches for how they relate turns up bleak. The remarkable thing about the theorem of Little is that we don’t need to know the distrubtion of the call arrival rate, nor the distribution of the service holding time. Both things also applies to the above relationship. End of aside.&lt;/p&gt;&lt;h2 id=&#34;sensitivity&#34;&gt;Sensitivity&lt;/h2&gt;&lt;p&gt;The notion of load in a system is a way to see how much work it is processing. The problem is when load increases to the point where the system hits capacity and then breaks down. If one request requires full use of one processor core for its duration, then a modern Core i7 CPU hits its peak capacity at 8 erlang[0].&lt;/p&gt;&lt;p&gt;As we pack more requests vertically on one system, we make it more sensitive to fluctuations in holding time.&lt;/p&gt;&lt;p&gt;Imagine we have two systems A and B. In system A, we have 150 reqs/s at 45ms per request. This gives 6.75 erlang. System B is 5 times faster, completing each request in 9ms on average, so we have decided to load B with 400 reqs/s instead. It is thus loaded with 3.60 erlang.&lt;/p&gt;&lt;p&gt;Now, we suddenly hit a hiccup which makes the systems misbehave. Both sees 20ms increased holding time for systems A and B. This means 65ms and 29ms respectively. And now, system A has a load of 9.75 whereas system B has a load of 11.6.&lt;/p&gt;&lt;p&gt;What we see is that the tighter packing of requests on system B means it is more sensitive to small fluctuations in holding time. The tighter we pack requests, the worse the load when we let the holding time fluctuate. In other words, systems with high arrival rates doesn’t cope well with holding time fluctuations.&lt;/p&gt;&lt;h2 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h2&gt;&lt;p&gt;One may wonder if we should always celebrate systems able to process a higher number of requests per second. The added onus of operating such systems is that we need to optimize every code path, or the system topples for outliers, or at system capacity. That is, the price of operating a system may be far higher than we think, simply by the notion of additional optimization needs.&lt;/p&gt;&lt;p&gt;In addition, we may want to celebrate a system having high engineering and peak capacities. Such a system will generally be far more predictable under load that systems with lower capacity limits.&lt;/p&gt;&lt;p&gt;Finally, the simply notion of increasing capacity by going faster isn’t always the right solution. As we have seen, such solutions make the system more sensitive.&lt;/p&gt;&lt;p&gt;The key insight is that in the question of scaling vertically or horizontally, you need to understand what capacity limits your system can cope with, realistically. And in practice, it may be necessary to avoid loading systems to much vertically in order to achieve correct operation when you strike gold when slaving away in the venture capitalist mine.&lt;/p&gt;&lt;p&gt;[0] Perhaps the peak capacity is less, due to the SMT of modern CPUs.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Breaking Erlang Maps #1</title>
       <link>https://jlouis.github.io/posts/breaking-erlang-maps-1/</link>
       <pubDate>Sun, 29 Mar 2015 00:00:00 +0100</pubDate>
       
       <guid>https://jlouis.github.io/posts/breaking-erlang-maps-1/</guid>
       <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&lt;p&gt;Erlang got a new data structure in release 17.0, the map(). This structure is a finite mapping from keys to values with a flat internal representation: a map is essentially two arrays: one of sorted keys and one of values. In turn, maps in this so-called flatmap representation are efficient for small map sizes, but they don’t perform well for large maps.&lt;/p&gt;&lt;p&gt;Release 18.0 is going to eliminate the large-map problem. In 18.0, maps switch to using a HAMT (Hash-Array Mapped Trie) internally once the map grows enough. It is a clever data structure which combines the properties of a hash table with a (level compressed) trie to provide fast lookup as well as persistence. This is the same data structure languages like Clojure, Scala and Haskell (unordered-containers) use. They were designed by the now late Phil Bagwell and the Erlang variant leans itself up against the work of Rich Hickey in Clojure.&lt;/p&gt;&lt;p&gt;Such a new structure however, needs testing. Erlang is a language which prides itself on stability of operation, not necessarily execution speed. So it would seem obvious that one should attempt to test the Erlang Maps extensively before an eventual release of 18.0. I decided to see how far we could get by building an Erlang QuickCheck model for the low-level map operations in Erlang and then testing it against the current stable release as well as 18.0-rc1 release candidate.&lt;/p&gt;&lt;p&gt;The goal of this blog post is to tell the story about the current QuickCheck model. How few lines of code there is in the model, and how little work you need to begin testing by generating tests. It also serves as an example of how to use QuickCheck on a real-world project. It serves to entertain and teach — or that is my hope at least.&lt;/p&gt;&lt;p&gt;There will be multiple blog posts, since it felt right to split up the work into multiple parts. The first part addresses how to generate data and the first simple tests. Later parts will address the more complicated model which uses state machines to drive the generation of tests.&lt;/p&gt;&lt;h2 id=&#34;quickcheck-primer&#34;&gt;QuickCheck primer&lt;/h2&gt;&lt;p&gt;QuickCheck[1] is similar to fuzzing. Where a fuzzer bombs a system with sinister input in order to break it — so one can exploit the mistakes — a QC model checks internal consistency of a system by randomly executing commands against it. The crucial difference is while fuzzers are black-box and often have relatively simple understanding of the inner workings of a program, a QC test is a model. It knows what is supposed to happen in a given situation and makes sure it is so. This gives a QC model far more precision, because it can make use of prior knowledge to guide what should happen next. The price for this additional power is that one has to come up with a proper model in the first place.&lt;/p&gt;&lt;p&gt;In full model checking, one begins by producing a simplified formal description   of the system under test (SUT). The model checker then exhaustively verifies the correctness of the model with respect to the SUT by systematically trying every possible state. The complexity of such an operation is that some models exhibit infinite command sequences. To handle these, it may be necessary to prove that one has a “loop” which will be stable, in order to tie the knot on the infinite sequences, so to speak.&lt;/p&gt;&lt;p&gt;QuickCheck[1] operates as a probalistic model checker in that we don’t check the model exhaustively. Rather, we derive random event traces from the model and verify that they are correct. In the words of John Hughes, we don’t write tests; We generate them. By simple configuration, we can tune the confidence we have in the tests by generating more of them. Spending more time gets us closer to the exhausting model checking algorithms. We can also decide what areas of the model we are interested in. We can weigh the system, skewing the events toward certain areas we know are harder to make correct in the system.&lt;/p&gt;&lt;p&gt;Any test system has a specification limit at which it can’t see further. Even proof assitant systems like, e.g., Coq, are not able to verify a property which is not part of the specification. We simply hope that enough testing form a protective web over the subject matter: math, programs, or hardware making it highly unlikely an error persists. And we hope that any deviation inside the protective web reverberates throughout the web so we eventually catch the mistake. In short,&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Testing shows the presence, not the absence of bugs — Dijkstra, 1969&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;QuickCheck has proven to be efficient at showing the presence of errors, however. The method tends to find very subtle errors in programs which are later found to be malicious rather than benign. And that for a modest additional programming effort. While slower to write than a unit-test, the advantage is coming back thousand-fold once the model is up and running. The ability to run a couple million tests over a night, all different usually finds problems in a code base.&lt;/p&gt;&lt;p&gt;Erlang QuickCheck is an implementation of the QuickCheck idea. It defines a domain-specific-language in which one writes models. And then it contains tools to run those models against real-world code.&lt;/p&gt;&lt;h2 id=&#34;strategy&#34;&gt;Strategy&lt;/h2&gt;&lt;p&gt;The first thing one must do is to come up with a strategy for testing maps. We immediately split low-level maps from things pertaining to the compiler. The maps syntax is compiler specific. But before one tests the notation, we should test that the ‘maps’ module is correct. There is little meaning in testing one without having established confidence at a lower level.&lt;/p&gt;&lt;p&gt;Second, should the test case be stateless or should it be stateful. In a stateless test case, the quickcheck model has no state and thus no knowledge between calls to the map (that is, it is closer to a fuzzer). For functions which are pure, this is often an adequate test method, but real programs are rarely entirely pure. We want to exploit knowledge about “what” and “when”: we want to know what is inside the map at any point in time so we can decide what to do. For instance, we want to check that we can remove an existing element in the map. To do this, we must know what elements are in the map — which is state. Also to check for removal of a non-existing element in the map, we must know what elements are not in the map — which likewise is state.&lt;/p&gt;&lt;p&gt;Furthermore, we need to look at two types of data generation:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;One, we need to generate random map keys and map values we can use to manipulate maps. We also need to quickly be able to generate random maps. That is, we need to generate concrete data we can push into functions we call in the ‘maps’ module.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Two, we need to generate random commands from the ‘maps’ module. This allows us to avoid static tests where the commands are always the same. We will run tens — sometimes hundreds — of commands in each test, randomly deciding what to do, in order to make sure that any combination of ‘maps’ calls are stable. In Erlang QuickCheck, we have the‘eqc_statem’ system, which encodes tests as state machines. In turn allowing for stateful command generation.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For a state machine model, we can exploit an isomorphism. A list of K/V pairs, subject to some constraints, is isomorphic to a map at any time. Altering the map with a function from the ‘maps’ module has a corresponding operation on lists. This leads to the idea that the model should use the list-representation of maps and then verify the map is manipulated in the right way. It is a common trick for QuickCheck modeling: the model has a simple representation of an advanced data structure. And hence we can use the simple and unoptimized model to make sure the complex and optimized structure is correct.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; One might think it is necessary to make the model execute quickly. This is rarely the case, if ever. A model should be focused on clarity and readability. It is much harder to read an advanced representation of data than a simple one. In addition, how a model shrinks is important for generating minimal counter-examples. Often, this means you need a less efficient model, but that sacrifice yields the counter-examples of minimality.&lt;/p&gt;&lt;p&gt;To check maps, we use two models. One is a simple stateless test of simple isomorphism properties for maps. The other is a more advanced stateful test using the above list({K, V}) representation. By splitting the model in two, we can weed out simple properties first. If the simple stateless model fails, it is often easier to find the culprit. Furthermore, once the simple model passes, it provides some confidence which can be supplanted to the more advanced model. It will probably not fail in certain ways.&lt;/p&gt;&lt;h2 id=&#34;generation-of-mapdata&#34;&gt;Generation of map data&lt;/h2&gt;&lt;p&gt;First, we need to address how to generate map contents. If we are to fire off random commands against maps, we need to be able to generate parameters for the map. Say we are to generate a maps:put/3 command. It is called as maps:put(Key, Value, Map), so we need to be able to generate random keys, random values and also random maps.&lt;/p&gt;&lt;p&gt;We define that map keys and values are going to be using the same generator:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;map_key&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; map_term().&lt;span style=&#34;color:#a6e22e&#34;&gt;map_value&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; map_term().&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and then we can define the real map generator in the map_term() function:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;map_term&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;SIZED(Sz, map_term(Sz)).&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/&lt;/span&gt;pre&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We use a standard trick in QuickCheck. The ?SIZED macro allows us to obtain the current size of what is generated by making it into the explicit variable Sz. The size usually starts around 0 in runs and then increases to around 40 in the course of random testing. By having access to the size, we can control how to generate map terms of a given size:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;map_term&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    frequency([      {&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, oneof([int(), largeint(), atom(), binary(),                    bitstring(), bool(), char(), evil_real()])},      {&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, oneof([function0(int()), function2(int())])},      {&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, eqc_gen:&lt;span style=&#34;color:#a6e22e&#34;&gt;largebinary&lt;/span&gt;()}    ]);&lt;span style=&#34;color:#a6e22e&#34;&gt;map_term&lt;/span&gt;(K) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    frequency([      {&lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;, map_term(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)},      {&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;LAZY(list(map_term(K &lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;)))},      {&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;LAZY(&lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;LET(L, list(map_term(K &lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;)),                        list_to_tuple(L)))},      {&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;LAZY(eqc_gen:&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt;(map_term(K &lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;),                            map_term(K &lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;)))}    ]).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There are two cases here. Generating a map of size 0 will always create a scalar value. It will weight its generation. 100 out of 120 times it will generate integers, atoms, binaries, booleans and so on. 10 out of 120 times it will generate a function of either 0 or 2 arguments (which are pure, determinstic and returns ints). And 10 out of 120 a large binary is generated (between 65 bytes and 64 Kilobytes). The evil reals are reals of the form:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;evil_real&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;   frequency([     {&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, real()},     {&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, return(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)},     {&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, return(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)}]).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If one wonders why these are interesting, consider &lt;code&gt;erlang:phash2(0.0)&lt;/code&gt; versus &lt;code&gt;erlang:phash2(0.0/-1)&lt;/code&gt;…[2].&lt;/p&gt;&lt;p&gt;If generating a map term of size K, 40 out of 43 times a scalar is generated. But sometimes a list of map terms, a tuple or a map of map terms are generated. The recursive call divides the size by quite a lot to make sure the next generations are smaller and that we will eventually hit scalars. The ?LAZY parameter avoids generating the recursive composite variants unless the frequency/1 combinator ends up picking that branch. Had we not used ?LAZY, then we would have generated all of the tree every time and then picked in the tree. With this, we only generate a “path” in the tree, which is much faster. Haskell programmers get this for free, but in strict languages, one needs to explicitly state when one wants lazy evaulation.&lt;/p&gt;&lt;p&gt;Now, we can look to generate lists of Key/Value pairs:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;gen_map&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;SIZED(Sz, resize(Sz &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,       list({resize(Sz, map_key()), resize(Sz, map_value())}))).&lt;span style=&#34;color:#a6e22e&#34;&gt;map_list&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      gen_map().&lt;span style=&#34;color:#a6e22e&#34;&gt;map_map&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;LET(ML, map_list(), maps:&lt;span style=&#34;color:#a6e22e&#34;&gt;from_list&lt;/span&gt;(ML)).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The gen_map() uses the ?SIZED macro to obtain the current generation size. We then adjust it up by a factor of 15 for the list generator, but keep it normal for the keys and values. This lets us generate very large lists by default without having to tune a lot more.&lt;/p&gt;&lt;p&gt;Erlang 18.0 has the HAMT structure internally and its internal breakoff point for switching to HAMT are currently 32 elements (2015–03–29). So we need to make sure we generate lists well in that ballpark to test that the HAMT structure is acting like it is supposed to. Also, if we find an error, having a 400 element list is not a problem. QuickCheck shrinks lists by finding elements that can be deleted from the list. So chances are we will find a much smaller list as the counterexample.&lt;/p&gt;&lt;p&gt;With gen_map(), we can directly generate lists suitable for maps. And we can generate maps by calling map_list() and then using the output with maps:from_list/1 to build up a map with the contents.&lt;/p&gt;&lt;h2 id=&#34;stateless-testing&#34;&gt;Stateless testing&lt;/h2&gt;&lt;p&gt;Maps support the functions f = maps:from_list/1 and g = maps:to_list/1. These two functions form a structural isomorphism between the domain M of map(A,B), and domain L, that of &lt;code&gt;list({A, B})&lt;/code&gt;[3]. We can utilize this because if m is any map in M, then f(g(m)) = m. And if l is in L, then g(f(l)) = l. This establishes an isomorphism in the same sense as a mathematical category.&lt;/p&gt;&lt;p&gt;We can implement these rules in two QuickCheck properties. The fg variant is the following:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;prop_list_iso_fg&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;FORALL(M, maps_eqc:&lt;span style=&#34;color:#a6e22e&#34;&gt;map_map&lt;/span&gt;(),          &lt;span style=&#34;color:#66d9ef&#34;&gt;begin&lt;/span&gt;              List &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; maps:&lt;span style=&#34;color:#a6e22e&#34;&gt;to_list&lt;/span&gt;(M),              M2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; maps:&lt;span style=&#34;color:#a6e22e&#34;&gt;from_list&lt;/span&gt;(List),              equals(M, M2)          &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It is essentially an implementation of the above requirement. Its counterpart running the gf path is a bit more involved:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;prop_list_iso_gf&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;FORALL(L, maps_eqc:&lt;span style=&#34;color:#a6e22e&#34;&gt;map_list&lt;/span&gt;(),        &lt;span style=&#34;color:#66d9ef&#34;&gt;begin&lt;/span&gt;          LD &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dedup(L),          M &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; maps:&lt;span style=&#34;color:#a6e22e&#34;&gt;from_list&lt;/span&gt;(L),          LD2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; maps:&lt;span style=&#34;color:#a6e22e&#34;&gt;to_list&lt;/span&gt;(M),          equals(lists:&lt;span style=&#34;color:#a6e22e&#34;&gt;sort&lt;/span&gt;(LD), lists:&lt;span style=&#34;color:#a6e22e&#34;&gt;sort&lt;/span&gt;(LD2))        &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The variant has to remove duplicate keys from the list for the L domain to be isomorphic to M in a well-defined way. And the result has to be sorted in order to make sure there is a canonical representation of the lists. Maps can return K/V pairs in any order.&lt;/p&gt;&lt;p&gt;Before going for 18.0, we run test cases on the current stable version 17.4.1. Running 100 tests for each of these turns out to be fine:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; eqc:&lt;span style=&#34;color:#a6e22e&#34;&gt;quickcheck&lt;/span&gt;(maps_iso_eqc:&lt;span style=&#34;color:#a6e22e&#34;&gt;prop_list_iso_fg&lt;/span&gt;()).  ....................................................................................................  OK, passed &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; tests  true  &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; eqc:&lt;span style=&#34;color:#a6e22e&#34;&gt;quickcheck&lt;/span&gt;(maps_iso_eqc:&lt;span style=&#34;color:#a6e22e&#34;&gt;prop_list_iso_gf&lt;/span&gt;()).  ....................................................................................................  OK, passed &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; tests  true&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;binary-variants&#34;&gt;Binary variants&lt;/h3&gt;&lt;p&gt;Maps can be converted through the functions term_to_binary/2 and binary_to_term/1. These functions are used to serialize data on a wire and are central to Erlang. The distribution protocol uses a variant of these. A lot of places where you need to transfer terms benefit from a compact, compressed, binary representation. Again, it is an isomorphism, since we can convert back and forth from a map. Given enough patience, we can also construct a binary which decodes into a map term. But often this is left out since it is not that easy to build up the binary from scratch.&lt;/p&gt;&lt;p&gt;The term_to_binary/2 function takes a list of options, which we can encode for in the test:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;opts&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;LET({Compressed, MinorVersion},      {oneof([[], [compressed], [{compressed, choose(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;)}]]),       oneof([[], [{minor_version, choose(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)}]])},         Compressed &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; MinorVersion).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And then we can use the opts() generator to generate the real test case:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;prop_binary_iso_fg&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;FORALL([Opts, M],        [opts(), maps_eqc:&lt;span style=&#34;color:#a6e22e&#34;&gt;map_map&lt;/span&gt;()],           &lt;span style=&#34;color:#66d9ef&#34;&gt;begin&lt;/span&gt;             Binary &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; term_to_binary(M, Opts),             M2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; binary_to_term(Binary),             equals(M, M2)           &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It works exactly like in the list_fg case: flip back and forth between the binary representation and verify for equality. We run 100 test cases on Erlang 17.4.1, the stable version:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; eqc:&lt;span style=&#34;color:#a6e22e&#34;&gt;quickcheck&lt;/span&gt;(maps_iso_eqc:&lt;span style=&#34;color:#a6e22e&#34;&gt;prop_binary_iso_fg&lt;/span&gt;()).  ....Failed&lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt; After &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; tests.  #{&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3878269413&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; hill,    &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; stone,    &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;#&lt;/span&gt;Fun&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;eqc_gen.&lt;span style=&#34;color:#ae81ff&#34;&gt;133&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;121384563&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; sand,    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt;  #{&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; stone,    &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3878269413&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; hill,    &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;#&lt;/span&gt;Fun&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;eqc_gen.&lt;span style=&#34;color:#ae81ff&#34;&gt;133&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;121384563&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; sand,    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;}  Shrinking xxxx.x.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx................................xxxxxxxxxxxxxxxxxxxxxxxxxxxx(x10)xxxxxxx(x1).x(&lt;span style=&#34;color:#ae81ff&#34;&gt;35&lt;/span&gt; times)  #{&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; flower,&lt;span style=&#34;color:#ae81ff&#34;&gt;2147483647&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; flower} &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt;  #{&lt;span style=&#34;color:#ae81ff&#34;&gt;2147483647&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; flower,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; flower}  false&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Aha! Failed after 5 tests, and it looks suspicious! The internal ordering of the map is suddenly reversed. This violates the assumption about the internal flatmap representation. Indeed, Wolfram Alpha reports that — apart from being a prime — 2147483647 is also 2³¹-1. It set off some alarm bells when I reported it[4], and a newer stable version of Erlang will have a fix (OTP-12623 is on the current maintenance branch and will be in 17.5 with a bit of luck).&lt;/p&gt;&lt;h2 id=&#34;going-deeper&#34;&gt;Going deeper&lt;/h2&gt;&lt;p&gt;A later post will cover the state machine‘maps_eqc’ model which is used to check the maps module. It verifies every command of the ‘maps’ module and reports far more statistics. The current work is ongoing and we are using these models to weed out errors from Erlang 18.0 and gain confidence we don’t introduce obvious mistakes in the new HAMT implementation. And while here, we also fix existing bugs that we find[5]. The model has already proven its worth, and has found errors, in the release candidate 18.0-rc1. But with the latest patches from the OTP team on top of the release candidate, the models doesn’t provoke errors anymore.&lt;/p&gt;&lt;p&gt;If you are interested in the full model, it is Open Source under an Apache 2.0 license here (at the time of this writing the commit ID is 5a9523f98635. Expect the model to change over time): &lt;a href=&#34;https://github.com/jlouis/maps_eqc&#34;&gt;GH/jlouis/maps_eqc&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; I simplified some of the code in this post because it reads better and avoids having to explain some details. I don’t think anything was lost, but in the interest of full transparency, I better note I did this.&lt;/p&gt;&lt;p&gt;[1] QuickCheck was developed by John Hughes and Koen Claessen. For a good starting point, see the wikipedia article: &lt;a href=&#34;http://en.wikipedia.org/wiki/QuickCheck&#34;&gt;Wikipedia QuickCheck&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] This one was found by Björn-Egil Dahlberg from the OTP Team.&lt;/p&gt;&lt;p&gt;[3] L needs some additional rules. For instance, the list must have unique keys, because otherwise there is no corresponding well defined map. So the domain is not any list, but rather “lists of a certain structure with certain no-junk properties”.&lt;/p&gt;&lt;p&gt;[4] &lt;a href=&#34;http://erlang.org/pipermail/erlang-bugs/2015-March/004840.html&#34;&gt;Dead Link&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[5] “We” means the OTP team, which are doing all of the hard work on HAMTs. The author of this post only writes the QuickCheck model to verify correctness.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Solving the Go Challenge #1 in Erlang</title>
       <link>https://jlouis.github.io/posts/solving-challenge-1/</link>
       <pubDate>Thu, 19 Mar 2015 00:00:00 +0100</pubDate>
       
       <guid>https://jlouis.github.io/posts/solving-challenge-1/</guid>
       <description>&lt;p&gt;&lt;a href=&#34;http://golang-challenge.com/go-challenge1/&#34;&gt;The first Go challenge&lt;/a&gt; is over. So by now, I can take my Erlang solution and write about how you would go around solving the challenge in Erlang. I’m deliberately skipping some details in Erlang, so don’t expect me to explain all the nitty-gritty parts. I do hope a reader with some programming language experience can follow along, even if you have had very little exposure to functional programming.&lt;/p&gt;&lt;p&gt;The goal of the challenge is to implement a parser for a binary format. The binary format encodes drum patterns for a digital drum machine, which are highly popular in many genres of music. The goal is then to produce an output which is a textual representation of the binary format:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;pattern_1.spliceSaved with HW Version: 0.808-alphaTempo: 120(0) kick     |x---|x---|x---|x---|(1) snare    |----|x---|----|x---|(2) clap     |----|x-x-|----|----|(3) hh-open  |--x-|--x-|x-x-|--x-|(4) hh-close |x---|x---|----|x--x|(5) cowbell  |----|----|--x-|----|&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The task requires two steps. First, once must reverse-engineer the binary patterns in the splice format. Next, the format must be parsed, and finally the parsed data must be rendered.&lt;/p&gt;&lt;p&gt;Erlang is built to handle binary protocols, and hence parsing the data in Erlang is going to be pretty easy. Comparing this solution to some of the Go solutions is going to be instructional and explains how different programming languages solve different problems. I’ve kept this solution under covers while the contest were running, mostly because I didn’t want to explain the format. Half the fun of the challenge is to figure out the format used, and then implement that in Go. The solution I have here is close to idiomatic Erlang. One could perhaps improve a thing or two, if one wanted to put the code into a larger project. But everything is a complete solution in about 40 lines of Erlang code, excluding test-code.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&#34;testing&#34;&gt;Testing&lt;/h2&gt;&lt;p&gt;First we set up a function which returns test data:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;test_table&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;   [{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pattern_1.splice&amp;#34;&lt;/span&gt;,     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Saved with HW Version: 0.808-alpha&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Tempo: 120&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(0) kick |x---|x---|x---|x---|&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(1) snare |----|x---|----|x---|&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(2) clap |----|x-x-|----|----|&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(3) hh-open |--x-|--x-|x-x-|--x-|&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(4) hh-close |x---|x---|----|x--x|&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(5) cowbell |----|----|--x-|----|&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;},       {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pattern_2.splice&amp;#34;&lt;/span&gt;,        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Saved with HW Version: 0.808-alpha&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Tempo: 98.4&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(0) kick |x---|----|x---|----|&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(1) snare |----|x---|----|x---|&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(3) hh-open |--x-|--x-|x-x-|--x-|&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(5) cowbell |----|----|x---|----|&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;},        ...].&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Returned is a list of pairs [{FileName, Expected}, …] where the file name is the binary file to read, and the pattern is a textual representation of the correct output. This allows us to implement a system which uses the list as a table-driven-test and verify every output is correct. It is followed by a simple function to test a single test case:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;t&lt;/span&gt;({File, Expected}) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      {ok, Dat} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; file:&lt;span style=&#34;color:#a6e22e&#34;&gt;read_file&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;priv/fixtures/&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; File), &lt;span style=&#34;color:#75715e&#34;&gt;%1&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;      Output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; iolist_to_binary(render(p(Dat))), &lt;span style=&#34;color:#75715e&#34;&gt;%2&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;      Output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list_to_binary(Expected), &lt;span style=&#34;color:#75715e&#34;&gt;%3&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;      ok.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This uses Erlangs binding rules in two ways. The reading of the binary file in (1) asserts that the output is {ok, Dat}. If the file read returns an error, this leads to a crash of the code. This is a common pattern in Erlang in which failures crashes the program. We then install other strategies for restarting failing parts of a program later. In (2) we use the p/1 function to parse the file contents, then send it to the render/1 function and finally converts its output into binary data. We stuff this into the value Output. Finally, the (3) line attempts to stuff the expected output into the same value. The binding semantics of Erlang takes this as an assertion. That is, if the expected output of (3) doesn’t match the output of (2); then the code will crash.&lt;/p&gt;&lt;p&gt;This is in contrast to many programming languages which would overwrite the value Output. But languages like Erlang and Prolog uses this to define an assertion. It is an often used trick in Erlang, since it avoids having to write assertion checks for a lot of code. In particular I don’t need the common&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;err&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; { &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt; }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;which is common in Go programs.&lt;/p&gt;&lt;p&gt;We can now write the test-driver for the system:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;test&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      lists:&lt;span style=&#34;color:#a6e22e&#34;&gt;foreach&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;fun&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, test_table()).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Testing the code amounts to call our t/1 function on every data point in the test_table list. If this code doesn’t crash, our tests passed. If the code crashes, Erlang returns a structural error with all the information we need to figure out what is wrong. Larger Erlang programs usually employ one the test systems Eunit or Common Test. But for a simple program, it is somewhat simpler just to use a simple function call to make sure things work as they should.&lt;/p&gt;&lt;h2 id=&#34;parsing&#34;&gt;Parsing&lt;/h2&gt;&lt;p&gt;Now we are ready to implement the the parser, which we do in the p/1 function. The format contains an identifying header, followed by some global information about the drum pattern and then followed by the instruments present in the drum pattern. We will have to parse these in order to handle the format and for the sake of simplicity we will parse the data and represent it internally as an abstract syntax tree. Then this tree will be fed to the rendering function later in order to render data in the textual format. In principle we are writing a compiler from the binary format to the textual format.&lt;/p&gt;&lt;p&gt;An &lt;code&gt;atom()&lt;/code&gt; intermezzo is needed to explain a concept which may be helpful in the following. In Erlang, an unquoted alphanumeric identifier starting with an upper-case character, such as “Payload” is a variable. An alphanumeric starting with a lower-case character such as “instrument” is an atom. Atoms are interned by representing them as integers in the VM. That is, when the file is loaded, each atom is mapped to an integer, picking a new integer if the atom has not been seen before. If the atom already occurs in the VM, the designated number for that atom is used of course. They are used as “tags” in programs to discriminate data, and in Erlang they are also used to represent module names and function names in some situations.&lt;/p&gt;&lt;p&gt;The advantage of atoms are their very quick equality check, because one doesn’t have to walk through a costly string comparison. It is so-to-speak paid for in advance when the module is loaded into the system (or when foreign data enters the VM node).&lt;/p&gt;&lt;p&gt;And now, back to parsing…&lt;/p&gt;&lt;p&gt;Parsing the identifying header is the following function:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;p&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SPLICE&amp;#34;&lt;/span&gt;, Len:&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;integer, Payload:Len&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary, _&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    p_data(Payload).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The function defines what is called a binary pattern match where the function expects binary data and then the function proceeds by “destructuring” (picking apart) the binary data according to the specfication given. This specification says:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;First comes 6 bytes with ascii codes“SPLICE”&lt;/li&gt;&lt;li&gt;Next comes a 64-bit Big-Endian integer which we parse as the value Len&lt;/li&gt;&lt;li&gt;Next comes the Payload, which is Len bytes and are binary data.&lt;/li&gt;&lt;li&gt;Finally comes more data, which we disregard. This is needed because pattern 5 includes errornous data in the end and we have to match it.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Any parsing error crashes the function. If we manage to parse the data, we send the Payload on to the p_data/1 function:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;p_data&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;HWStr:&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary, Tempo:&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;float&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;little, Data&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    Instruments &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; instruments(Data),    #{ format &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; splice, hardware_string &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; trim_hwstring(HWStr),     tempo &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; Tempo, instruments &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; Instruments }.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Again, we match the expected content. First comes 32 bytes of hardware string identification information. Then comes a 32 bit IEEE 754 Floating Point value in Little-Endian form. The rest is Instrument data, which we parse in a helper function called instruments/1. The return value is a map containing the data we found in the parse. The language is dynamic and we don’t have to predeclare the contents of the map, but we simply just create one and add the necessary fields. The function trim_hwstring/1 is used to get rid of the trailing 0&#39;es which is in the end of the hardware ID string:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;trim_hwstring&lt;/span&gt;(B) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    Str &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; binary_to_list(B),    string:&lt;span style=&#34;color:#a6e22e&#34;&gt;strip&lt;/span&gt;(Str, right, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Only two functions remain. The first one is decoding each instrument line:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;instruments&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;Num:&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;integer, L:&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;integer, Name:L&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary,                Pattern:&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary, Rest&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    [{instrument, Num, Name, pattern(Pattern)} | instruments(Rest)];  instruments(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;gt;&amp;gt;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    [].&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here, we have two possible matches. The first match is the one that picks an instrument apart. We expect:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;An integer in 8 bits&lt;/li&gt;&lt;li&gt;A length in a 32 bit Big-Endian integer&lt;/li&gt;&lt;li&gt;A name, whose length was just given&lt;/li&gt;&lt;li&gt;A pattern, which is 16 bytes of pattern data&lt;/li&gt;&lt;li&gt;The “rest” or remainder of the binary data.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We then create a tuple {instrument, Num, Name, Pat} where the ‘instrument’ part is an identifying atom/symbol we can use later to discriminate instruments from other data. The function recurses on the remainder of the data (the call to instruments(Rest)) and then when that call returns, it front-appends the current instrument to the list being built.&lt;/p&gt;&lt;p&gt;The other variant identifies &amp;laquo;&amp;raquo; which is the empty binary. If there are no instruments to parse, we return [] which is the empty list. The recursion here then gradually builds up a list of instruments by recursing to the end of the instrument data and then building up the list of instruments “in reverse”.&lt;/p&gt;&lt;p&gt;We only need to parse patterns:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;pattern&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;P1:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary, P2:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary, P3:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary, P4:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;binary&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      [binary_to_list(P) || P &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; [P1, P2, P3, P4]].&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A pattern are split into 4 groups with 4 bytes in each. We then use a list-comprehension, to convert each pattern binary into a list of bytes. Read: for each P in the list [P1, P2, P3, P4] replace P with binary_to_list(P). This returns a list(list(byte())) which will come in handy when we want to render output.&lt;/p&gt;&lt;p&gt;As an example, let us run this on pattern 1 and print its output. Erlang has a REPL which comes in handy for such exploratory tests:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;3&amp;gt; {ok, Pattern1} = file:read_file(&amp;#34;priv/fixtures/pattern_1.splice&amp;#34;).{ok,&amp;lt;&amp;lt;83,80,76,73,67,69,0,0,0,0,0,0,0,197,48,46,56,48,56,      45,97,108,112,104,97,0,0,...&amp;gt;&amp;gt;}4&amp;gt; decoder_dm:p(Pattern1).#{format =&amp;gt; splice,  hardware_string =&amp;gt; &amp;#34;0.808-alpha&amp;#34;,  instruments =&amp;gt; [{instrument,0,&amp;lt;&amp;lt;&amp;#34;kick&amp;#34;&amp;gt;&amp;gt;,               [[1,0,0,0],[1,0,0,0],[1,0,0,0],[1,0,0,0]]},   {instrument,1,&amp;lt;&amp;lt;&amp;#34;snare&amp;#34;&amp;gt;&amp;gt;,               [[0,0,0,0],[1,0,0,0],[0,0,0,0],[1,0,0,0]]},   {instrument,2,&amp;lt;&amp;lt;&amp;#34;clap&amp;#34;&amp;gt;&amp;gt;,               [[0,0,0,0],[1,0,1,0],[0,0,0,0],[0,0,0,0]]},   {instrument,3,&amp;lt;&amp;lt;&amp;#34;hh-open&amp;#34;&amp;gt;&amp;gt;,               [[0,0,1,0],[0,0,1,0],[1,0,1,0],[0,0,1,0]]},   {instrument,4,&amp;lt;&amp;lt;&amp;#34;hh-close&amp;#34;&amp;gt;&amp;gt;,               [[1,0,0,0],[1,0,0,0],[0,0,0,0],[1,0,0,1]]},   {instrument,5,&amp;lt;&amp;lt;&amp;#34;cowbell&amp;#34;&amp;gt;&amp;gt;,               [[0,0,0,0],[0,0,0,0],[0,0,1,0],[0,0,0,0]]}],  tempo =&amp;gt; 120.0}5&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This looks about right. We now have the parser in 16 lines of code and can begin focusing on the next part, the renderer.&lt;/p&gt;&lt;h2 id=&#34;rendering&#34;&gt;Rendering&lt;/h2&gt;&lt;p&gt;For rendering, we need a couple of helper functions:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;conv&lt;/span&gt;(Pat) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [render_c(C) || C &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; Pat].&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;render_c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;$-&lt;/span&gt;;  render_c(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;$x&lt;/span&gt;.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These two functions are helpers which are going to be used to convert a pattern such a &lt;code&gt;[0,0,1,0]&lt;/code&gt; into &lt;code&gt;[45, 45, 120, 45]&lt;/code&gt; which are the ASCII bytes for “ — x-”. Again, we use a list comprehension to work over the list and converting each element in the list.&lt;/p&gt;&lt;p&gt;We also need to handle the tempo, and in the output, a floating point value such as 120.0 is to be rendered as an integer 120 with no trailing 0. There is no such function in Erlang by default, so we test if the result is close to 0 and then convert the output into an integer if that is the case:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;format_float&lt;/span&gt;(F) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;      &lt;span style=&#34;color:#66d9ef&#34;&gt;case&lt;/span&gt; abs(F &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; trunc(F)) &lt;span style=&#34;color:#66d9ef&#34;&gt;of&lt;/span&gt;          K &lt;span style=&#34;color:#66d9ef&#34;&gt;when&lt;/span&gt; K &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;0001&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; integer_to_list(trunc(F));          _ &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; float_to_list(F, [{decimals, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;}, compact])      &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And now, we are ready for the rendering function. Before that however, I need to have another little intermezzo about iolists in Erlang.&lt;/p&gt;&lt;p&gt;The iolist() datatype is a way to output data in Erlang. It is an inductively generated datatype, where the type itself is part of the type. The specification is&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;-type iolist() :: list(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt; | binary() | iolist()).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;which one can read as “iolists are defined as lists consisting of 3 alternate things: integers in the range 0..255, binaries, and iolists themselves”. The last part makes the definition inductive such that iolists are really trees built out of lists. They are convenient because you can avoid having to explicitly concatenate strings in many situations. Say you want to quote a string, which can be done by writing the following function:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;quote&lt;/span&gt;(String) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;$&amp;#34;&lt;/span&gt;, String, &lt;span style=&#34;color:#e6db74&#34;&gt;$&amp;#34;&lt;/span&gt;].&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The notation &lt;code&gt;$X&lt;/code&gt; evaluates to the ascii code for the symbol X. And this forms a quoted string without ever copying String. Since all terms in Erlang are persistent (immutable), no risk is had by this construction.&lt;/p&gt;&lt;p&gt;Many typical output points in Erlang programs accepts iolists() as well as other data. Writing to a socket or file for instance. This is highly convenient as you often avoid having to manually concatenate data, but can just build up the iolist() structure and then have the system itself handle the concatenation later on. It also means the Erlang VM is free to optimize data output. For instance by pre-calculating the size needed for the concatenated target and by the use of the writev(2) system call to do “gather output” writing.&lt;/p&gt;&lt;p&gt;The render function of the drum machine decoder uses iolists(). It also employs another trick: each parsed element has a unique representation. Hence, we can simply analyse an element and then recurse deeper down into our abstract syntax tree. The render function always returns iolists() so we can “plug in” those into a larger iolist. The test function above then aptly uses the iolist_to_binary/1 function to convert the iolist into a binary we can use to test against the expected output.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;render&lt;/span&gt;(#{ format :&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; splice, tempo :&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Tempo,          instruments :&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Instruments, hardware_string :&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; HWS}) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Saved with HW Version: &amp;#34;&lt;/span&gt;, HWS, &lt;span style=&#34;color:#e6db74&#34;&gt;$\n&lt;/span&gt;,     render({tempo, Tempo}), &lt;span style=&#34;color:#e6db74&#34;&gt;$\n&lt;/span&gt;,     render(Instruments)];&lt;span style=&#34;color:#a6e22e&#34;&gt;render&lt;/span&gt;(List) &lt;span style=&#34;color:#66d9ef&#34;&gt;when&lt;/span&gt; is_list(List) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    [render(Elem) || Elem &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; List];&lt;span style=&#34;color:#a6e22e&#34;&gt;render&lt;/span&gt;({tempo, T}) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Tempo: &amp;#34;&lt;/span&gt;, format_float(T)];&lt;span style=&#34;color:#a6e22e&#34;&gt;render&lt;/span&gt;({instrument, N, Name, Pattern}) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    Prefix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; io_lib:&lt;span style=&#34;color:#a6e22e&#34;&gt;format&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;~B&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;) &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;~s&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, [N, Name]),    Grid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; render({pattern, Pattern}),    [Prefix, Grid, &lt;span style=&#34;color:#e6db74&#34;&gt;$\n&lt;/span&gt;];&lt;span style=&#34;color:#a6e22e&#34;&gt;render&lt;/span&gt;({pattern, [P1, P2, P3, P4]}) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    [&lt;span style=&#34;color:#e6db74&#34;&gt;$|&lt;/span&gt;, conv(P1), &lt;span style=&#34;color:#e6db74&#34;&gt;$|&lt;/span&gt;, conv(P2), &lt;span style=&#34;color:#e6db74&#34;&gt;$|&lt;/span&gt;, conv(P3), &lt;span style=&#34;color:#e6db74&#34;&gt;$|&lt;/span&gt;, conv(P4), &lt;span style=&#34;color:#e6db74&#34;&gt;$|&lt;/span&gt;].&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is all of the renderer. We pattern match on different possible inputs and then handle them by outputting something which is right for that input. Two tricks are being used to make discrimination explicit. Rendering of the tempo calls recursively with {tempo, Tempo} and pattern rendering calls recursively with {pattern, Pat}. This ensures each input term is unique and thus we can employ the same rendering function for all cases.&lt;/p&gt;&lt;p&gt;In languages with static type systems, such a function must often be broken into several different small functions. And it is also advisable to do so in Erlang had the rendering function been larger. For a renderer this small, however, it is fine to keep functions close to each other.&lt;/p&gt;&lt;p&gt;We are at 39 lines and we are done. We can exploratively test our code by noting that our pattern from above was the output of shell command #4 and then use this as an input in a later command:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; io:&lt;span style=&#34;color:#a6e22e&#34;&gt;format&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;~s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, [iolist_to_binary(decoder_dm:&lt;span style=&#34;color:#a6e22e&#34;&gt;render&lt;/span&gt;(v(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)))]).  Saved with HW Version: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;808&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;alpha  Tempo: &lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;  (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) kick        |x&lt;span style=&#34;color:#f92672&#34;&gt;---&lt;/span&gt;|x&lt;span style=&#34;color:#f92672&#34;&gt;---&lt;/span&gt;|x&lt;span style=&#34;color:#f92672&#34;&gt;---&lt;/span&gt;|x&lt;span style=&#34;color:#f92672&#34;&gt;---&lt;/span&gt;|  (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) snare       |&lt;span style=&#34;color:#f92672&#34;&gt;----&lt;/span&gt;|x&lt;span style=&#34;color:#f92672&#34;&gt;---&lt;/span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;----&lt;/span&gt;|x&lt;span style=&#34;color:#f92672&#34;&gt;---&lt;/span&gt;|  (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) clap        |&lt;span style=&#34;color:#f92672&#34;&gt;----&lt;/span&gt;|x&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;----&lt;/span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;----&lt;/span&gt;|  (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;) hh&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;open     |&lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;|x&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;|  (&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) hh&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;close    |x&lt;span style=&#34;color:#f92672&#34;&gt;---&lt;/span&gt;|x&lt;span style=&#34;color:#f92672&#34;&gt;---&lt;/span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;----&lt;/span&gt;|x&lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;x|  (&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;) cowbell     |&lt;span style=&#34;color:#f92672&#34;&gt;----&lt;/span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;----&lt;/span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;----&lt;/span&gt;|  ok&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;notes&#34;&gt;Notes&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;There is very little copying going on. The parsed binary is never copied, but match contexts are generated when recursing down the data. These are somewhat equivalent to a slice in Go (or Standard ML). Large parts of the output is never copied, since we are using iolists. Rather, pointers to the underlying persistent data is used by the VM.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Pattern matching is very efficient. A pattern match compiler analyzes the patterns and compiles alternatives into jump tables and/or if analysis with binary split. Further, both positive and negative match information is propagated such that you don’t have to “start over” for each possible match but can rely on data which has already been successfully matched or rejected in earlier patterns.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;There is no error handling code whatsoever. This is typical of Erlang programs. An error returns a structural error which can be analyzed by Erlang programs or printed out. It is common Erlang systems have error loggers which handles crashes and writes out the structured error to disk for post-mortem analysis. The system as a whole doesn’t crash because Erlang is a truly concurrent environment where one process is (logically) isolated from other processes. Hence, the system is always able to clean up from a process crash with no trailing garbage or inconsistent state left behind.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It took about 30 minutes to come up with this solution in programming time. It is standard Erlang code, without magic tricks or things you would only do to act clever. In other words, the implementation is the straightforward one from an experienced Erlang programmer.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The implementation is reasonably speedy and clocks in at 13 microseconds on my machine for parsing pattern 1. There are some optimizations possible, but I don’t think it is necessary. Go should be roughly 5–10 times faster on this problem, but so should e.g., OCaml.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The tests are directly portable to Common Test, which uses the same assertion method as I used above. It is just that Common Test requires more boilerplate, as in Go’s testing package.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</description>
     </item>
   
     <item>
       <title>Ranking 4 Million Quake Live Duels in 1.5 seconds</title>
       <link>https://jlouis.github.io/posts/ranking-4-million-ql-duels/</link>
       <pubDate>Sun, 04 Jan 2015 00:00:00 +0100</pubDate>
       
       <guid>https://jlouis.github.io/posts/ranking-4-million-ql-duels/</guid>
       <description>&lt;p&gt;The last couple of days, I’ve been toying with a little hobby project of mine.&lt;/p&gt;&lt;p&gt;The project is to rank players which player Quake Live duels, and I have reported on it before. I’ve been gathering duels since February 2012 up to now. The project is written as a hybrid. Most of the code for storage, retrieval and presentation is written in Erlang. The ranking code is written in Go.&lt;/p&gt;&lt;p&gt;At the moment, I have gathered up exactly 4067842 matches of which I deem 3898355 to be eligible for ranking. Sometimes, Quake Live reports a match to have one player only, and some times, a match only lasted a couple of seconds. I remove these from the ranking as I don’t think they are good enough. There are around 165000 players in the database right now, but the average number of played matches varies a lot from player to player. Some only played one duel while some clock in over 60 duels a week (which is a lot given duels often take 10 minutes).&lt;/p&gt;&lt;p&gt;Everything is stored in my database of choice, Postgresql. I recently upgraded to 9.4, which meant I could change the internal representation from Erlang’s &lt;code&gt;term_to_binary/1&lt;/code&gt;, &lt;code&gt;binary_to_term/1&lt;/code&gt; conversions into the &lt;code&gt;jsonb&lt;/code&gt; storage type directly in Postgres. The price is storage. Where Erlangs serialization format took up 6.8 gigabytes of disk space, jsonb takes up 9.7 gigabytes. The advantage is ease. I can now do queries directly on the JSON representations in the database; take the query here as an example&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; id&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; core.raw_match&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; ((content &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;RANKED&amp;#39;&lt;/span&gt;)::int &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;which will look inside the ‘content’ JSON column and grab rows having a ‘RANKED’ top-level key where it’s integer representation is equal to 0. This simplifies a lot of processing as I can use UPDATE statements to pre-analyze large swaths of duels without having to do low-level work on them in Erlang.&lt;/p&gt;&lt;h2 id=&#34;erlang&#34;&gt;Erlang&lt;/h2&gt;&lt;p&gt;The choice of using Erlang for the processing have proved its worth again and again. Number of restarts due to fatal failures is around 2. The reason is the fault-tolerance of Erlang: small mistakes will not affect the code as a whole. Often, these mistakes is not in our end, but in the end of the &lt;a href=&#34;http://quakelive.com&#34;&gt;http://quakelive.com&lt;/a&gt; (This is now on steam). To handle these, there is a &lt;code&gt;fuse/circuit-breaker&lt;/code&gt; installed[0] on the request code, which will clamp down on the operation if the site experiences problems. Either because it is unreachable, or because we trip a timer where requests are too slow to process. This means our end backs off if the Quake Live site experiences trouble.&lt;/p&gt;&lt;p&gt;In order to limit concurrent access to the QuakeLive site, we have installed the &lt;code&gt;safetyvalve&lt;/code&gt; application[1], which defines a request queue and a policy for how fast that request queue will be emptied. This means we can run the Erlang system with an internal concurrency level around 150 outstanding processes which all tries to fetch from QuakeLive. But the queue then controls the policy and sets up limits:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;How many outstanding concurrent requests do we allow?&lt;/li&gt;&lt;li&gt;Which frequency we start new requests&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In short, Erlang is the right tool of choice for a long-running daemon service which must not go down, even if the database does, or the foreign system on which we rely do. One example of the power is when QuakeLive upgrades their service and takes it down. I had to change 0 lines of code in order to handle that. The fuse simply blows, and the system then rechecks connectivity every 5 minutes.&lt;/p&gt;&lt;p&gt;Another important design decision were to make all database operations idempotent. Since Postgresql gives us atomic operations, we can simply make sure jobs are idempotent and can be retried later on. The system is always trying to ‘catch up’ to the current state. And the system is always behind real time by some (small) factor. If we should go down, we can handle the situation by catching up and the virtue of idempotence will save us. QuakeLive only removes matches some 4–5 weeks after they have been played (for non-paying customers—I bet they keep them internally). So we have at least 28 days before we have to act on a grave problem.&lt;/p&gt;&lt;h2 id=&#34;go&#34;&gt;Go&lt;/h2&gt;&lt;p&gt;Erlang shines due to the fault tolerance, robustness and by being a nice functional language in which you can write succinct code. Go is somewhat the opposite: imperative, explicit data layout, statically typed with a simple type system. However, Go is compiled to native code, provides good parallelism and has some very nice unique features in interfaces and channel-based-message-passing. Some of the things where I think Go shines are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Syntax. For a C-like imperative language it was the first language in about 35 years to actually innovate and simplify thelanguage. When writing Go, you only what is necessary and this is important. Another brilliant decision is to getrid of semicolons and use a simple layout rule (while still keeping a mostly LALR(1) grammar) and provide theexcellent ‘go fmt’ tool to re-indent code to a pre-defined default.&lt;/li&gt;&lt;li&gt;Packages. Go’s way of handling libraries and importedcode is something other languages should be picking up by now. The trick is that an import statement is a string,like “github.com/jlouis/glicko2&amp;quot;, but then an external tool understands how to parse this string andautomatically fetch the source code for the library and compile it. This coalesces the concept of packagedependencies into the language itself and removes a lot of external boilerplate management.&lt;/li&gt;&lt;li&gt;Toolchain. Quick recompilation of software helps a lotwhen developing and removes the overhead of compilation. Coming from other languages with very fast compilers likeOCaml or Erlang, this is nice. You shouldn’t have to wait on the compiler. One design decision is that transitivedependencies doesn’t have to be recompiled. If A depends on B which depends on C. Then when compiling B, everythingrelated to C is pulled into the resulting object file. In turn, when compiling A, we only have to look at B and canavoid C. This helps compilation times a lot.&lt;/li&gt;&lt;li&gt;Interfaces. In Go, packages and interfaces are yourstructuring tools which allows you to break a large system into smaller parts. This increases modularity of the codebase since altering one module of the code is less likely to yield alterations in other modules. Decoupling is byfar the most important construction for handling large code bases. In Erlang, you write an independent application.In OCaml, you create a module or a functor, and in Go, you write a separate package and eventually use an interface.The abstraction provided is different from a parameterization as in a Java generic or an OCaml functor. But I havenot really experienced any limitations of the approach yet.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In an Earlier post of mine, I looked at Glicko2 rankings for different approaches in different languages[r1]. I ended up choosing Go over OCaml and Erlang. Erlang is not strong at number crunching in the floating point domain. And OCamls current lack of parallelism excluded it. I have recently updated the &lt;code&gt;glicko2&lt;/code&gt; Go package[2] so it is better and simpler to use than ever.&lt;/p&gt;&lt;p&gt;The main interface to the package is the following:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Opponent&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;interface&lt;/span&gt; {    &lt;span style=&#34;color:#a6e22e&#34;&gt;R&lt;/span&gt;() &lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;RD&lt;/span&gt;() &lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;Sigma&lt;/span&gt;() &lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;SJ&lt;/span&gt;() &lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;}&lt;span style=&#34;color:#66d9ef&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Rank&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;rd&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;sigma&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opponents&lt;/span&gt; []&lt;span style=&#34;color:#a6e22e&#34;&gt;Opponent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;tau&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;) (&lt;span style=&#34;color:#a6e22e&#34;&gt;nr&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;nrd&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;nsigma&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To rank a player, you call rank with the player parameters‘r’, ‘rd’ and ‘sigma’, a set of opponents, given as a slice and a configuration parameter for the system called ‘tau’. Opponent is an interface which you have to implement. By making Opponent an interface, we avoid the problem where a caller has to take their code and mangle it to fit our scheme. Rather, they can wrap their data structures and provide Opponent interfaces for them. In turn, we can rank games.&lt;/p&gt;&lt;p&gt;The code can also optimize the configuration parameters tau and the initial ‘rd’ to use in the system, by running a Nelder-Mead optimization routine[r2][3]. Here, the API is&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Optimize&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;func&lt;/span&gt;([]&lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;start&lt;/span&gt; [][]&lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;cf&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;func&lt;/span&gt;([]&lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;)) ([]&lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;where you will optimize the function “f” subject to start values “start” and under constraints “cf”. Note that speed is of no concern here as the overhead is in the “f”function and its computation. To make everything work out, we have adapted a simple parallel variant of ranking computation to speed them up. Full ranking of 150 weeks of matches takes less than 2 seconds. Full optimization is completed in 43 seconds (Core i7–4900MQ, 16 Gigabyte RAM, Lenovo W540). All of the technical code is at [4].&lt;/p&gt;&lt;h2 id=&#34;d3jsthe-nextsteps&#34;&gt;D3.js — the next steps&lt;/h2&gt;&lt;p&gt;The next phase of the project is to employ D3.js in order to provide nice graphical output of the data. I initially tested the output in R with the very nice plotting package“ggplot2” by Hadley Wickham. But in order to make it easier for everyone to use the system, I’ve decided to build a front-end which uses D3.js to plot results. This work is currently ongoing, but once it is done, I should have a way to present the data.&lt;/p&gt;&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;&lt;p&gt;[0] &lt;a href=&#34;https://github.com/jlouis/fuse&#34;&gt;https://github.com/jlouis/fuse&lt;/a&gt;[1] &lt;a href=&#34;https://github.com/jlouis/safetyvalve&#34;&gt;https://github.com/jlouis/safetyvalve&lt;/a&gt;[2] &lt;a href=&#34;http://godoc.org/github.com/jlouis/glicko2&#34;&gt;http://godoc.org/github.com/jlouis/glicko2&lt;/a&gt;[3] &lt;a href=&#34;http://godoc.org/github.com/jlouis/nmoptim&#34;&gt;http://godoc.org/github.com/jlouis/nmoptim&lt;/a&gt;[4] &lt;a href=&#34;http://godoc.org/github.com/jlouis/rank&#34;&gt;http://godoc.org/github.com/jlouis/rank&lt;/a&gt;[r1] &lt;a href=&#34;https://medium.com/@jlouis666/glicko2-benchmarking-1-548b3f99136e&#34;&gt;https://medium.com/@jlouis666/glicko2-benchmarking-1-548b3f99136e&lt;/a&gt;[r2] &lt;a href=&#34;https://medium.com/@jlouis666/glicko2-benchmarking-2-775b573c086f&#34;&gt;https://medium.com/@jlouis666/glicko2-benchmarking-2-775b573c086f&lt;/a&gt;&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>ProgLang design with evidence</title>
       <link>https://jlouis.github.io/posts/proglang-design-evidence/</link>
       <pubDate>Fri, 05 Dec 2014 00:00:00 +0100</pubDate>
       
       <guid>https://jlouis.github.io/posts/proglang-design-evidence/</guid>
       <description>&lt;p&gt;Let us assume the programming language market is effective and free. In this case, the best programming languages are the most popular ones: PHP, Javascript, Java, C#, C, C++ and so on. By definition, fringe languages can’t be the best languages. New fringe languages, like Go and Rust still has a chance in this world order, but long-time languages like Common Lisp, Haskell and OCaml are all dead. They have tried to show their worth for real-world development, but have been forever displaced into the dark corners of academia.&lt;/p&gt;&lt;p&gt;The problem, by far, is that we don’t design languages based on evidence, but design them based on whim. New programming languages are designed by looking at existing languages and re-hashing the ideas. Only rarely does a language introduce a genuinely new concept from research. There has been some initial work by Andreas Stefik et.al, in the language &lt;a href=&#34;http://quorunlanguage.com&#34;&gt;Quorum&lt;/a&gt; where language constructs are designed by evidence. This means that until you have a stastistical significant test for a given construct, it is not included.&lt;/p&gt;&lt;p&gt;But most languages are designed at random based on other constructions:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Standard ML has a formal specification, which is as close to being mechanized (In Twelf) as you can get. This means the language bases itself under an assumption of “Logic is a good guide for language design”. In the world of proof assistants and very formal settings, this is almost unvariably true. There is no way you can get a system like Coq, Twelf, or Agda to work without using the knowledge of Logic. Otherwise, encoding logic and mathematics would be almost impossible.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Haskell and OCaml are functional languages, picking typical functional features. Both languages have a tiny kernel doing the base computation. But also, both languages are growing bigger and bigger with every new release. Learning all parts of the languages will take time.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Essentially, this is the school of language academia. By alluding to logic and math, the hope is to get good, elegant and productive programming languages. The problem however, is that we have no evidence. There are relatively few controlled experiments, and those which exist have several shortcomings.&lt;/p&gt;&lt;p&gt;On the contrary, most industrial languages are rehashes of older languages. You can trace most modern languages back to C[0]. And a lot of the language designs are influenced by a few ideas: imperative execution, and object oriented programming. Even modern variants of the strain, Go and Rust, takes inspiration from the world of the well-known, rather than inventing something truly new. The traits of these languages are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Each new generation is a rehash of an older generation with ideas systematically cherry-picked from academia: Garbage collection, lambda-expressions, parametric polymorphism (generics), structural subtyping to name a few examples.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A distinct industry-focus: large and comprehensive standard libraries with support for the data format of the decade: XML, JSON, or ASN.1. Large IDEs that support the development effort. Eco-systems for todays technology. Debuggers, profilers, linters and static analysis tools to make up for the shortcomings of the language.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Large development teams, spending efforts on maximizing the language performance, often paid for by the industry.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Development effort does not focus on research and features, but on stability and robustness.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The programmer is expendable to a certain extent. It is more imporant getting 100 people to work together than to get each one to perform at their optimum.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;To a certain extent, the industry will find an optimal language for programmers. The inputs deciding the language will be many, some of which will be highly doubtful: programmer availability, programmer expendability, safety in numbers, nobody ever got fired for choosing IBM.&lt;/p&gt;&lt;p&gt;But an optimal language could be a locally extreme value. It may be there are other languages out there which are far better for the industry, but random process would have we ended up picking a weaker language as the language we choose.&lt;/p&gt;&lt;p&gt;Worse, in industry, you may have a selection bias against the best language. Managers measure their power in the size of their staff. A better language means you need a smaller staff to carry out the task, which is in opposition to gaining power within the corporate structure. Consultants have a harder time working on projects with fewer oppurtunities for fixing errors. Employees lose their sense of value if they can’t fix the bugs the programming language inadvertedly introduce for them. Certain programmers take pride in solving deep complex shared-state bugs by lurking over a debugging screen for days.&lt;/p&gt;&lt;p&gt;In the following I revisit old behemoths of discussion. My purpose is to make it obvious that there are many good questions to ask in the design of programming languages. I am not viewing language design from a theoretic perspective, nor am I viewing it entirely from a question of practicality. That is, the language design doesn’t stop at the construction of an operational semantics specification. And likewise, you can’t say you define a language by its sole implementation and thus define how it operates.&lt;/p&gt;&lt;h2 id=&#34;types&#34;&gt;Types&lt;/h2&gt;&lt;p&gt;With respect to types, there are two major claims:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Static typing makes the programmers more effective and productive.&lt;/li&gt;&lt;li&gt;Dynamic typing makes the programmers more effective and productive.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The experiment here has a null hypothesis:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;There are no measureable difference in programmer productivity in a controlled experiment where we evaluate a dynamic vs static typing discipline.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;If there is a difference, it doesn’t matter that much to which side it falls in the first place. Just that there is a measurable difference in itself would be interesting.&lt;/p&gt;&lt;p&gt;It is not a priori obvious what works best. There are good arguments for and against the static/dynamic typing discipline question. What makes it hard to answer decisively is that the experience of different programmers are varying to a large degree.&lt;/p&gt;&lt;p&gt;As an example, proponents of static typing often cite that it works well for large programs, since it captures bugs in the large. Yet, the key of software modularity is to split up programs in small modules which then can work independently. And modularity works in a dynamic typing discipline as well; weakening the claim considerably.&lt;/p&gt;&lt;p&gt;On the other hand, proponents of dynamic typing often cite the added tediousness of adding types to code as a slowdown in productivity. Yet, type inference automatically discovers types, and constructions like “open types” and “polymorphic variants” in OCaml can simplify many situations where the use of static typing would normally require a lot of ascriptional work of relating type to value.&lt;/p&gt;&lt;p&gt;Dan Luu has done a magnificent job. His post “&lt;a href=&#34;http://danluu.com/empirical-pl/&#34;&gt;The Empirical Evidence That Types Affect Productivity and Correctness&lt;/a&gt;” summarizes a large set of papers and goes through each one in order to describe what it is trying to measure and how well it does it. In almost every paper, he has valid critique of the experiment, methodology and approach.&lt;/p&gt;&lt;p&gt;The point is that while these papers shows almost no effect in either direction, they are often used to “Justify your view” in one direction or the other. At best, many of these studies are inconclusive. And unfortunately, few people read the underlying papers, which means more misinformation.&lt;/p&gt;&lt;p&gt;There are other interesting questions to ask inside the umbrella of types. For instance:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;The language will automatically convert values of differing types under certain operators. A good example is promotion of integers to floats in C, integer size conversions in C, or the automatic conversion of integers to strings in string concatenation in Javascript. Commonly this is called weak typing, but other names exist for the concept.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The language disallows automatic conversion and forces the programmer to convert between types. This is true in Python, Ruby, Go, OCaml, Haskell, Erlang and a whole other slew of languages. Often this is called strong typing.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Again, it is a toss-up what is the most effective. Certainly, weak typing is beneficial when the programmer gets to type less and the conversions work like they should. Given this view, strong typing feels like a nuisance and a source of irritation. On the other hand, the automatic conversion sometimes introduces subtle bugs in the program which will not occur in a language with manual type conversion.&lt;/p&gt;&lt;h2 id=&#34;null&#34;&gt;NULL&lt;/h2&gt;&lt;p&gt;Many languages include a “NULL” or “nil” value, which is represented as a pointer to the address of zero. In the Java platform, the dreaded NullPointerException rears its ugly head whenever you try to dereference such a value.&lt;/p&gt;&lt;p&gt;Many academic languages, and a few industrial ones (Erlang for example), has no concept of a nil value. Instead, you have to explicitly nominate when a value can be invalid. This default is akin to defining all your database columns as NOT NULL.&lt;/p&gt;&lt;p&gt;Again, we have a relevant question: is there a statistically significant difference in the error rate of languages with a NULL default compared to a NOT NULL default.&lt;/p&gt;&lt;h2 id=&#34;garbage-collection&#34;&gt;Garbage collection&lt;/h2&gt;&lt;p&gt;Does a garbage collector improve productivity? And for what kind of programs? Certainly, not having to manually work with memory is helpful in many situations. But it is also true that a garbage collector doesn’t automatically remove memory leaks. Bad programming can still make the program use up more memory than it should. And a logical memory leak is still possible. Haskell for instance—with its lazy evaluation model—is prone to leaking computation into memory in what could be called a thunk-leak.&lt;/p&gt;&lt;p&gt;The benefit of faster development due to Garbage collection must be measured against the time used for tuning the GC algorithm of the program running in production. Increased service latency due to long GC pause times is a very real problem and it is not a priori clear the inclusion of garbage collection by default is a step in the right direction.&lt;/p&gt;&lt;h2 id=&#34;persistentephemeral-data&#34;&gt;Persistent/ephemeral data&lt;/h2&gt;&lt;p&gt;In programs, data are either persistent (immutable) or ephemeral (mutable). Functional programming languages usually default on using persistent data structures, eschewing the ephemeral ones in the process. It is not that you can’t get access to mutable structure when you need it. It is simply not the default mode of operation. In such languages a question arises:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Null hypothesis: there are no measurable difference between programs written with mutable data structures and immutable data structures.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Another worthy hypothesis to ask is if there is a measurable difference in the efficiency of the executing software, depending on data structure choice. The answer is usually yes, but a more interesting question is wether in practice the choice between an O(n) ephemeral structure and a O(n lg n) persistent ditto matters much. And what robustness guarantees are obtained by picking one over the other.&lt;/p&gt;&lt;h2 id=&#34;other-questions&#34;&gt;Other questions&lt;/h2&gt;&lt;p&gt;While I have only picked a few questions, here are some other interesting questions, I like:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Does exceptions help or hinder the programmer in producing correct programs.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Are generics valuable in an OO-style language, or do they just add so much complexity it hurts the programmer.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Does syntax matter? And how much?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Many operating systems provide memory protection between executing programs by means of using the hardware MMU for the purpose. To what extent would it help to add such a construction to a language design?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Does size limits on integers like int32 and int64 by default lead to bugs? How much slower are arbitrarily sized integers by default in large programs?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;To what extent can a well-designed standard library and 3rd party library availability cover for a badly designed language? (Note: this is a fun experiment. Kill npm and have Node.js people implement everything from scratch. Compare to Python. Compare to Go. Compare to OCaml)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Does compilation speed affect programmer productivity?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Is there any measurable advantage in having a REPL for the language?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Will full, global, ubiquitous introspection capability help the programmer under development? Under production?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;If we measure how well a program performs over its lifetime (analysis, design, development, deployment and most important maintenance under production), is there any difference?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Is there any correlation between language choice and development time?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Is there any correlation between language choice and error rate?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Is there any correlation between language choice and execution efficiency?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Does language choice affect time-to-alteration for an existing program of a certain size.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&#34;a-critique-of-current-experiments&#34;&gt;A critique of current experiments&lt;/h2&gt;&lt;p&gt;Currently, our experiments are weak and use some dubious methodology when carrying out experiments of programming languages.&lt;/p&gt;&lt;p&gt;It is important to stress the activity of programming is one involving human beings. That is, the programming language is the ultimate test of user experience (UX) for a computer. The programming language interface to the computer is the universal one which lets you write anything you want. In contrast to many normal programs which are about limiting the experience to a few well-defined things you can do, the idea of programming languages falls in the opposite category, where the goal is to be able to extend the existing machine. And do so with maximal efficiency and productivity.&lt;/p&gt;&lt;p&gt;Because it is a human activity, it has to involve human beings. This means we have to select a sample of programmers to test our hypothesis on.&lt;/p&gt;&lt;p&gt;It is here we see, what I often deem to be an almost universal weakness: test on freshmen. The problem with undergraduates in the 1st year is variance. Some will have seen programming languages for the first time when they enter the study. And some will have been programming for 5–10 years in advance. This variant diversity hurts your statistical models since you need far larger groups to show a difference. In fact, it may be you can avoid a lot of the problems by only selecting those students with no to little prior programming experience.&lt;/p&gt;&lt;p&gt;The other weakness of freshmen are the lack of experience they may have. Some people claim that while dynamic typing is easier to learn, static typing is only appreciated when you have written code for some time. If true, this will affect your experiments.&lt;/p&gt;&lt;p&gt;Another weakness is not to control for language difference. Comparing Standard ML to Python for instance:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Python has a vast large standard library. Standard ML does not. You will have to cripple Pythons Stdlib so it is on par with SML or extend the SML library to the same extent as Pythons.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Python has built-in hash-tables in the form of “dictionaries”. You will have to provide the same structure to users of Standard ML. Otherwise, you risk the availability of dictionaries in Python to be a confounding variable in your experiment.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;How do people interact with Python? If they have access to an IDE providing automatic help for programming, it will confound the experiment.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;While it may seem unfair to artificially cripple one language to match it to the other language, it is important to ask “what are you measuring?”. Any experiment is about controlling for weaknesses in the method used. And ignorance is the fastest way to a wrong conclusion.&lt;/p&gt;&lt;p&gt;The question of generic programmer variance is also up in the open. There is an oft cited paper, “&lt;a href=&#34;http://www.dtic.mil/dtic/tr/fulltext/u2/645438.pdf&#34;&gt;EXPLORATORY EXPERIMENTAL STUDIES COMPARING ONLINE AND OFFLINE PROGRAMING PERFORMANCE&lt;/a&gt;”, from 1966. The paper is often cited in the scope of the 10x programmer myth: “some programmers are 10 times as effective as their colleagues”. In reality the paper is sound statistical work providing two major insights at the time:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Programmers would either write their programs on punched cards with no help from a computer, or their would develop the program “online”directly on the computer. The former, offline, method was argued to be better by some because it forced the programmer to think before writing code. The study found that online editing is significantly better. At the time, this was a trade-off since time on the computer was expensive and limited. Today, this limitation is non-existent.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Programmers writing in higher-level languages (JOVIAL Time-sharing System—JTS) were significantly faster at solving the task compared to programmers writing in a low-level language.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In passing, the paper mentions the large variance between programmers and invites more research in that area. It would seem this kind of research is still up for grabs for any interested party.&lt;/p&gt;&lt;p&gt;Furthermore, it would be interesting to see if programming variance changes with experience. Clearly, freshmen, one with 2 months of programming experience, the other with 10 years would likely be different. The programmer with 10 years of experience is more skilled. Even in the event where the language in which they are writing is a new language. Writing code in different languages have a peculiar overlap and learning a new language becomes easier the more languages you happen to know.&lt;/p&gt;&lt;p&gt;But take the same two people as graduates and 3–4 years of experience in industry. Is the variance still large, or has it changed in any way?&lt;/p&gt;&lt;p&gt;The kind of tasks in the tests also needs some work. A large chunk of modern programming is not about building something genuinely new, but rather to glue together existing systems. A lot of programmer productivity today can be measured on how well code fit together. Interestingly, a language like Go seem to focus much more on seamless implicit glueing of code than many other languages. I’d love to see an experiment where one is to integrate with existing code.&lt;/p&gt;&lt;p&gt;Another experiment I would like to see is the solution of a typical industrial problem with industrial and academic languages in the experiment. Implementing a spelling checker, while interesting, is not the typical task of a modern programmer.&lt;/p&gt;&lt;p&gt;It is my hope we see more falsifying experiments. We need experiments that soundly attempt to disprove certain commonly held beliefs. It would seems that we are a point where we have lots of questions and relatively few sound answers. Starting in the small by destroying some common myths would be a good way to move us foward.&lt;/p&gt;&lt;p&gt;The purpose of science is surprise. We want to have studies which surprises us and shows us something deeper about the world we did not know. I’d love repeated experiments which fails to reject to null hypothesis that static/dynamic languages are equally productive. That would argue the discussion is pointless. Or perhaps that there is a significant difference, which also makes the discussion pointless. It would move us forward and we could start looking at other merits of static/dynamic typing.&lt;/p&gt;&lt;p&gt;Language design is not additive. Like genes, changing one aspect of a language may affect other aspects. Rob Pike put it succinctly in “&lt;a href=&#34;http://commandcenter.blogspot.dk/2012/06/less-is-exponentially-more.html&#34;&gt;Less is exponentially more&lt;/a&gt;”, where he makes the argument that it is the sum and not the individual parts which makes up a language design.&lt;/p&gt;&lt;p&gt;In this light, I also hope for surprising outcomes:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;The execution efficency of programs doesn’t matter as much as proper software design. Efficient parallelism is more important than single-core execution speed.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Logic programming in Prolog or Mercury yields significantly fewer program errors than writing in Haskell. The programs also run faster.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Dependent types are found to slow down the programmer too much. Hindley-milner inference turns out to be the soft-spot providing the best of all worlds.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;There is no measurable advantage of writing unit tests for a statically typed language.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;In practice, QuickCheck finds all the bugs which was found by formal verification in Coq—and did so in 10 times less development effort.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Modern C static checkers: flexelint, coverity, address sanitization, and valgrind can find any bug in practice so it doesn’t matter C has undefined behaviour.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Functional programming in the large is more memory efficient than imperative programming and thus executes faster on modern memory-constrained machines.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Using formal parser and grammar theory can eliminate all security bugs w.r.t input parsing.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;DSLs are easier to write in homoiconic languages, especially Clojure. It is found that they are far harder to write in Haskell.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Experiments show message passing is more correct and more efficient than shared-memory methods of software-transactional-memory, mutexes and lock free data structures.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The myth of garbage collection pauses is dispelled and garbage collection can be used for hard realtime systems.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Over a large experiment, it is shown that there is a frequency-dependent system in which most people prefer imperative languages, but a small size of the population thrives on using functional programming. There is no hope in forcing one group to use the tools of the other group.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;An experiment connects the aptitude of natural language to the aptitude of programming languages. As a corollary, women—usually outpacing men in language-based tests—happens to be the better programmers on average.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It is shown that the 10x-programmers outperform others not due to their ability to program, but because they have a much better understanding of human sociology.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;[0] The right root is perhaps ALGOL68, but certainly, the syntax and semantics of C permeate almost all modern programs written.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Mnesia and Cap</title>
       <link>https://jlouis.github.io/posts/mnesia-and-cap/</link>
       <pubDate>Tue, 23 Sep 2014 00:00:00 +0200</pubDate>
       
       <guid>https://jlouis.github.io/posts/mnesia-and-cap/</guid>
       <description>&lt;p&gt;We start out with the TL;DR treatise: The mnesia database is not CP, nor AP. And it cannot be CA, because CA doesn’t make any meaningful sense. In short, it is broken with respect to the CAP theorem.&lt;/p&gt;&lt;p&gt;Note: Things get subtle once you begin digging into the intricacies of the CAP theorem. I am not a native speaker of English, though Danish is “dangerously close”. I apologize in advance for my mistakes, and beg of you to write a correction if I stray too far from understandable prose.&lt;/p&gt;&lt;p&gt;Aside: Some people oppose CAP is a theorem. The argument is based on the inherent informal treatment the theorem gets in literature, and the lack of well-defined premises for the theorem to apply. In spite of that, However, I will use the word “theorem” here. End of aside.&lt;/p&gt;&lt;p&gt;The subtle thing about the CAP theorem is the ease with which you can misinterpret it. They way you “beat” CAP is by twisting your words until you end up in the land of the informal and then you cheat your way to become a database that beats CAP.&lt;/p&gt;&lt;p&gt;The CAP theorem is often stated as Consistency, Availability, Partitioning Tolerance—pick two! However, this way of framing CAP is highly misleading. The result is an impossibility result stating that getting those three properties at the same time is impossible. This does not necessarily lead to a situation where a database system can “pick” among the pairs CP, AP and CA. Rather, it turns out that CA doesn’t have any meaningful connotation at all.&lt;/p&gt;&lt;p&gt;To level the playing field, it is important to note that CAP is a very specific theorem about very specific interactions. The C, consistency, is actually linearizability — a term with very specific meaning and with formal specification. There are numerous good write-ups about CAP out there, and I don’t want to repeat those. Henryr[2] is one, but do read more than one source as this is hard information to convey. Don’t fall into the trap believing this is easy stuff. Also note that there is a complete hierarchy of impossibility results for distributed systems. Of which CAP is the most famous.&lt;/p&gt;&lt;h2 id=&#34;network-partitions&#34;&gt;Network partitions&lt;/h2&gt;&lt;p&gt;A common “trick” is to claim:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;We assume network partitions can’t happen. Therefore, our system is CA according to the CAP theorem.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;This is a nice little twist. By asserting network partitions cannot happen, you just made your system into one which is not distributed. Hence the CAP theorem doesn’t even apply to your case and anything can happen. Your system may be linearizable. Your system might have good availability. But the CAP theorem doesn’t apply.&lt;/p&gt;&lt;p&gt;What makes it more odd is that a Postgres cluster together with sharding through PL/Proxy[0] has exactly the same safety semantics as any system as long as there are no network partitions. And if a partition does occur it may even be, depending on configuration, that the PL/Proxy solution falls neatly as CP, whereas your system just loses data.&lt;/p&gt;&lt;p&gt;In fact, any well-behaved system will be “CA” as long as there are no partitions. This makes the statement of a system being “CA” very weak, because it doesn’t put honesty first. I tries to avoid the hard question, which is how the system operates under failure. By assuming no network partitions, you assume perfect information knowledge in a distributed system. This isn’t the physical reality.&lt;/p&gt;&lt;p&gt;It is important to understand network partitions not as a discrete “toggle” but as a probability function over the system configuration. Any system has a risk of partitioning due to equipment/hardware failure. The particular configuration defines how risky the system is.&lt;/p&gt;&lt;p&gt;If you have a 1000+ node cluster over Ethernet, then you can be fairly sure there will be at least one partition going on, all the time. While the risk of a partition between any two machines is rather low, the probabilities team up against us. The reason is that while the risk of a single link fails is low, the risk accumulates when we have many links.&lt;/p&gt;&lt;p&gt;On the other hand, if you have a 3 node cluster, connected with a dedicated network, then the risk of a partition is much lower. It is not zero. But it may be so low you can accept the risk for your system.&lt;/p&gt;&lt;p&gt;Beware though. As Peter Bailis and Kyle Kingsbury[1] argues, the risk of a partition is very real. And it is not only limited to hardware only, but can also stem from software—long GC pause times needs specific mention. Large software installations are highly dynamic in nature and their operating point constantly changes. This excerbates the situation a lot.&lt;/p&gt;&lt;h2 id=&#34;axd-301&#34;&gt;AXD 301&lt;/h2&gt;&lt;p&gt;In the Ericsson AXD 301 switch[3], measures are taken such that network reliability is very high. There are two processing boards, connected through a dedicated switch control backplane. If the backplane experiences failure, then chances are that the switch as a whole fails since ATM connections are also moving along the backplane.&lt;/p&gt;&lt;p&gt;Because of the low number of processors, and the high reliability of backplane, it was deemed unlikely that a switch backplane failure would result in operation termination. Instead, the likely cause for failure is processor error, where one processor dies whereas the other one continues normal operation.&lt;/p&gt;&lt;p&gt;In such a highly specialized environment, the reliability of the control backplane essentially removes some of the worries which the CAP theorem introduces. In fact, the CAP theorem doesn’t really apply since it can be argued that the system is not even distributed. Risk management would suggest that network partitions are so unlikely that it would not be beneficial to worry about them.&lt;/p&gt;&lt;h2 id=&#34;mnesia&#34;&gt;Mnesia&lt;/h2&gt;&lt;p&gt;Mnesia, running in the AXD 301 switch or on a more unreliable network, protects well against processor failure where one processor board fails in a detectable way while the other continues nominally. In this case, the Mnesia database can be configured to replicate state among both processor boards, and since the other processor board has state, it can take over the operation in the event of a failure.&lt;/p&gt;&lt;p&gt;However, in the case of a switch fabric failure, mnesia fails to do things correctly.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Tables configured to live on one node only fallsinto the CP camp. Clients on the wrong side of the partition won’t be able to communicate with the table.The other side will have a consistent image though.&lt;/li&gt;&lt;li&gt;Fragmented (sharded) tables could in principlebe consistent but not available, so they also fall into the CP camp.&lt;/li&gt;&lt;li&gt;Replicated tables will throw away data. In thesplit brain scenario, both sides of the partition will keep taking writes. And when the partition heals, youwill have to pick which side is “correct”. Data from the other side is lost. This is definitely notconsistent. And arguably, it is not available either: the system accepted a write which it subsequentlylost. A system like “Jepsen[4]” would easily uncover this situation and show it is very real. We can’tautomatically heal the system.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;There is a section in mnesias documentation about network failure: “Recovery from Communication Failure” — where it is explicitly stated that in the case of a failure, picking a side from which to recover is outside the scope of mnesia. In other words, we punt the ball and let somebody else worry about this.&lt;/p&gt;&lt;p&gt;Having established that Mnesia is good at protecting against processor failure, but bad at handling split brain, we have to turn ourselves to the design criteria of mnesia[5]:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Fast realtime key/value lookup&lt;/li&gt;&lt;li&gt;Complicated non-realtime queries mainly foroperation and maintenance&lt;/li&gt;&lt;li&gt;Distributed data due to distributedapplications&lt;/li&gt;&lt;li&gt;&lt;em&gt;High fault tolerance&lt;/em&gt; [emphasis mine]&lt;/li&gt;&lt;li&gt;Dynamic re-configuration&lt;/li&gt;&lt;li&gt;Complex objects&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;When designing such a system, trade-offs must invariably be made. The central point for this discussion is high fault tolerance. But it is clear from the document[5] focus were not on handling the split brain scenario at all. Thus, mnesia protects against some failure, but definitely not by taking a stance on the CP/AP choice, which means that network disasters is a manual recovery scenario.&lt;/p&gt;&lt;p&gt;Mnesia is an excellent database. But it is important to understand it will fall short quickly if you have high data consistency guarantees or if you need an AP split.&lt;/p&gt;&lt;p&gt;== Solutions&lt;/p&gt;&lt;p&gt;If you can’t live with the above caveats, pick another database system.&lt;/p&gt;&lt;p&gt;I’m going to be very partial here. If you need a CP solution on a fairly regular sized data set (less than, say, 5 Terabytes), and can do with Read-Committed isolation levels, pick Postgres.&lt;/p&gt;&lt;p&gt;If your data set is large, I’m partial to Riak for an AP solution. For a CP solution at large scale, I would probably look at Riak 2.0 right now, plan for a deployment in 6–12 months and have at it.&lt;/p&gt;&lt;p&gt;In many cases however, it turns out that both of these solutions are overkill.&lt;/p&gt;&lt;p&gt;If you can manage the risk and disaster recovery, the in-memory properties of Mnesia makes it excellent for many tasks. It does put a size limit on your database since it has to fit in RAM. But for prototypes and smaller system installations it is a very good database solution. You just need to know that it is broken and the ability to scale indefinitely is non-existent.&lt;/p&gt;&lt;p&gt;Mnesia is excellent for Erlang applications because you keep the database in the same memory space as the application. This makes database queries blazingly fast. It also removes the impedance mismatch since you are storing Erlang terms directly in the database rather than having to traverse a (albeit local) network connection.&lt;/p&gt;&lt;p&gt;Mnesia is excellent for data which are derivable from somewhere. If you have another database system acting as a low-level log from which you can reconstruct the mnesia data, then it can often simplify a lot of operations.&lt;/p&gt;&lt;p&gt;I do hope this document clears up some misconceptions about what mnesia is and isn’t. In particular, I want to drive a stake through the virtual vampire that mnesia took a stance w.r.t CAP theorem. In fact, mnesia predates the CAP conjecture itself, so it is logical that another solution was sought. I’m also trying to argue that not heeding CAP isn’t in itself a problem as long as you clearly state that it is so. Many databases out there are broken in some way. Yet they still manage to do good work every day, with few errors in between.&lt;/p&gt;&lt;p&gt;[0] &lt;a href=&#34;https://wiki.postgresql.org/wiki/PL/Proxy&#34;&gt;https://wiki.postgresql.org/wiki/PL/Proxy&lt;/a&gt;[1] &lt;a href=&#34;http://queue.acm.org/detail.cfm?id=2655736%E2%80%8A&#34;&gt;http://queue.acm.org/detail.cfm?id=2655736 &lt;/a&gt;— The Network is Reliable[2] &lt;a href=&#34;http://henryr.github.io/cap-faq/&#34;&gt;http://henryr.github.io/cap-faq/&lt;/a&gt;[3]There are probably better documents out there, but this one will do: &lt;a href=&#34;http://pdf.aminer.org/000/275/505/axe_automatic_quality_of_service_control.pdf&#34;&gt;http://pdf.aminer.org/000/275/505/axe_automatic_quality_of_service_control.pdf&lt;/a&gt;[4] &lt;a href=&#34;http://aphyr.com/tags/jepsen&#34;&gt;http://aphyr.com/tags/jepsen&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/aphyr/jepsen&#34;&gt;https://github.com/aphyr/jepsen&lt;/a&gt;[5] &lt;a href=&#34;http://erlang.se/publications/mnesia_overview.pdf&#34;&gt;http://erlang.se/publications/mnesia_overview.pdf&lt;/a&gt;&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Quickcheck Advice</title>
       <link>https://jlouis.github.io/posts/quickcheck-advice/</link>
       <pubDate>Sat, 13 Sep 2014 00:00:00 +0200</pubDate>
       
       <guid>https://jlouis.github.io/posts/quickcheck-advice/</guid>
       <description>&lt;p&gt;Roberto Aloi has written a nice write-up about QuickCheck with a lot of good advice[0]. This is my attempt to add to those notes and come up with a set of additional advice you can use.&lt;/p&gt;&lt;p&gt;There is one problem I hear again and again with QC. Which is “How do I start on doing this for this particular project?” The premise is that you have an existing project and want to magically QuickCheck it so you can know that it works. However, this leads to the first problem of writing QC tests: coming up with good models.&lt;/p&gt;&lt;p&gt;In QC, the model reigns supreme. You can only check those things for which you can define a model. So constructing good models is definitely one of the things you want to cover in any exposition.&lt;/p&gt;&lt;p&gt;Most model construction currently happens by example. You see one model and this leads you to understand how to build other models. The hope is that cross-pollination between the different examples will lead to a person being able to model on his own.&lt;/p&gt;&lt;p&gt;It turns out that good model construction is an art form. Much like good code can be beautiful, elegant, and a delight to read, so can a proper QuickCheck model. But the skills you need to create one is somewhat more aligned with math than programming. It has to be approached as a new set of skills you have to train for, as you trained in order to become good at programming in the first place.&lt;/p&gt;&lt;p&gt;There are still some pitfalls from a more generic viewpoint you may want to think about. That is, by reading, you can accellerate your knowledge—like you can when learning a new programming language or concept.&lt;/p&gt;&lt;h2 id=&#34;common-model-advice&#34;&gt;Common Model Advice&lt;/h2&gt;&lt;p&gt;I think the most common problem is when you try to build a model which is as complicated and complete as the System Under Test (SUT). This never ever works. You want a simple model that cuts corners in some way so you don’t have to re-implement the same solution twice. Furthermore, having two equivalent implementations, one in the model and one in the SUT is not going to be a good use of your time.&lt;/p&gt;&lt;p&gt;So my advice is: Simplify your models!&lt;/p&gt;&lt;p&gt;Suppose you are checking a data structure of some kind. There is often a simple implementation with vastly different performance characteristics. A good example is a finite map, which can be implemented as a association list in most languages. The idea then is that your model runs as an association list—parallel to the SUT. And if they disagree you know there is a bug in one of them. This allows you to use a simple model, where lookup is O(n), to test an advanced SUT, where lookup is O(lg n). But your model doesn’t have the complexity of the SUT.&lt;/p&gt;&lt;p&gt;A common trick I use all the time is to come up with very very trivial models. The most trivial one is the totality model. It basically just does random things to the SUT and verifies the SUT doesn’t fail with an exception or crashes. It makes sure the system is robust against odd inputs.&lt;/p&gt;&lt;p&gt;Another trick is to dilute the precision of the model:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;If you check a stack or a queue, you can have a model which just models how many elements are in the stack or the queue.&lt;/li&gt;&lt;li&gt;If you check a queue say, you can simplify the model such that there can be at most one element in the queue.&lt;/li&gt;&lt;li&gt;Say a configuration parameter can vary from 1 to N. Alter this to vary from 0 to 1.&lt;/li&gt;&lt;li&gt;Deliberately have the model support a subset of the SUT.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The goal here is to simplify the model to a point where you can understand it. And then you can “paint” layer on layer and advance the complexity of the model afterwards. A good example is how I built the model for safetyvalve[1]: I started with a model where the queue in the system is empty or full. This simplifies the model a whole lot. Yet this simplified model still found nasty bugs in the implementation.&lt;/p&gt;&lt;p&gt;Another example is in transit-erlang[2], where the model started out as being able to generate the value ‘null’ only. It generated 100 test cases of the value ‘null’. But then you can gradually extend this. We added UTF-8 Strings, Integers, Timepoints, UUIDs, URIs and so on. When the primitive types worked, we started adding in arrays, maps, lists, sets and so on. Your first version of the model doesn’t have to contain all of the system.&lt;/p&gt;&lt;h3 id=&#34;more-thanone&#34;&gt;More than one&lt;/h3&gt;&lt;p&gt;Use more than a single model! You much rather want 2 or 3 models which are simple and covering than one large model which tries to be everything.“Modularization” is as important in QC code as it is in other code bases. When you model grows and becomes the size of Quviq’s AUTOSAR models, you need to think about how you split up the model into modules and handle things separately. Otherwise it becomes a mess to maintain.&lt;/p&gt;&lt;p&gt;Layer your models as well. Write small models checking one aspect of the system. And assume that part is right and write a model on top under the assumption. In fuse[3], we plug in a fake/mock timing system so we can control the passing of time (more on this in the next section). This timing model has a separate QC model so we can be sure it is correct when we use it in the larger set of things. You might say that if QuickCheck properties are theorems, the models further down in the layers are lemmas. While this analogy is not true entirely, the similarities in the way you work is striking.&lt;/p&gt;&lt;h3 id=&#34;time&#34;&gt;Time&lt;/h3&gt;&lt;p&gt;Time is a problem in almost all advanced developments where state is part of the system. Once part of the system calls some kind of sleeping or timing library, you have to handle it (In Erlang, a call to ‘timer:sleep/1’ or ‘erlang:now/0’ or a receive clause with an ‘after’ clause is a dead give-away).&lt;/p&gt;&lt;p&gt;There are two ways to handle time in models: Inject time, or mock time. In the injection solution, you rewrite your SUT such that all calls take an extra parameter, “Now”, and you use this parameter to inject the current time into the system. You can often write your system such that this happens silently to users of your system. Now, since time is injected, it can become part of your model. And your model can choose when it wants to advance time.&lt;/p&gt;&lt;p&gt;Another solution is to write your code so you can mock timing and plug in another timing module for the normal one. This is what we do in fuse[3]. now, we control the passing of time through the mock, and we can choose when time advances. This means we can reproduce, shrink, and work with time as if it was another parameter of the system.&lt;/p&gt;&lt;h3 id=&#34;rewrite-yoursut&#34;&gt;Rewrite your SUT&lt;/h3&gt;&lt;p&gt;If you have control over the code in the SUT, you can rewrite it. This is often necessary because it can make testing so much easier. Write testable code. Inject parameters rather than call out for them.&lt;/p&gt;&lt;p&gt;A common rewrite is to add some kind of introspection to the SUT. A call which can expose internal state can be very helpful because it can become part of an invariant check. You want to catch invariant breaches early on so the shrinking can get to work on the right error early on. Safetyvalve[1] exposes internal queue sizes among other things which are then used in postcondition checks.&lt;/p&gt;&lt;h3 id=&#34;algebraic-properties&#34;&gt;Algebraic properties&lt;/h3&gt;&lt;p&gt;Exploit algebraic properties of your data! In transit-erlang[2], we use the algebraic principle of an inverse in one direction:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=:=&lt;/span&gt; decode(encode(X))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This works at the lowest level for any transfer format or any low-level protocol with an obvious inverse. Other good algebraic properties stems from monoids, group theory, category theory and so on. Sometimes the (group) rules of commutativity, associativity, neutral elements and inverses applies. Sometimes you have an isomorphic property to exploit. If the problem you are working with has the triangle-inequality, use this fact in your models.&lt;/p&gt;&lt;p&gt;If your problem does not have such properties, it often has some kind of monotonicity or balance guarantee. In a monetary transaction involving two accounts, the change has to add to zero. Time can’t flow backwards. Some systems have convergence properties you can exploit. Adding two positive numbers yield a number strictly larger than the largest one.&lt;/p&gt;&lt;p&gt;Another algebraic property is to use a transformation to another domain. This is what you do in algebraic topology, where you turn a topology into an algebraic structure. If the algebraic structure of topologies X and Y differ, the topologies themselves must differ. You can for instance be working with functors from Top to Grp. In QuickCheck, the same idea can be exploited easily. You can view a system under some kind of transforming functor and verify properties under the functor.&lt;/p&gt;&lt;h3 id=&#34;amplification&#34;&gt;Amplification&lt;/h3&gt;&lt;p&gt;The “trick” with QC is amplification. You want a simple model. And then randomization of that model leads to a model with a much better amplification factor. Where QC excels is, in the words of Torben Hoffman, in the case where you have rather few things you can do to a SUT, but where these things can be composed. The complexity of the possibilities arising from these compositions is exactly what makes it hard to make sure you caught every corner case.&lt;/p&gt;&lt;p&gt;Transit-erlang[2] is such an example. Whereas it is fairly easy to test some transit-terms, it is hard to make sure you caught all the interactions. Transit comes with a large unit-test base of exemplars on which you can test your implementation. Yet our QC model has found as many additional interaction problems which the unit tests were unable to find. It easily caught a double-escaping problem, which the standard exemplars did not find since there were no input for this interaction.&lt;/p&gt;&lt;p&gt;To maximize amplification, it is important to build up your system as many small parts which can compose. To do this, you want to think about generators.&lt;/p&gt;&lt;h3 id=&#34;positive--negativetesting&#34;&gt;Positive &amp;amp; Negative testing&lt;/h3&gt;&lt;p&gt;There are two polarities in testing:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Positive: If we supply valid inputs, the system behaves as it should.&lt;/li&gt;&lt;li&gt;Negative: If we supply invalid inputs, the system does not misbehave.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Most testing is positive. But it is important to inject faults into the system now and then and test that the system behaves correctly, even if faults are injected. It can be used to check that the system has certain robustness properties one wants. One common thing is to make sure that the errors the system reports are consistent with the fault that was injected. In other words, you want to test the “happy path” of a system where it proceeds along the successful path. And you also want to test the system when it strays from the “happy path” and steps onto an errornous one.&lt;/p&gt;&lt;p&gt;When you do negative testing, it is important that your model knows it is injecting a failure. Otherwise, you can’t check the expected output. Again, simple properties can be enough. If you generate an input which is not among the valid inputs, the system MUST generate some kind of error and give it back. A common thing to test for is that the system is stable and doesn’t crash even if it is supplied invalid inputs.&lt;/p&gt;&lt;p&gt;Negative testing also has similarities to the security scenario. Namely the notion of fuzzing—where you supply data to a system through a stochastic process in order to make it fail. The idea is that once you have an input leading to crashes, you can try altering the input slightly in order to exploit a missing safety property in the underlying language: that there is a buffer overflow, an integer over/underflow, weak type coercion, forced cast[4], or worse.&lt;/p&gt;&lt;h3 id=&#34;on-generators&#34;&gt;On Generators&lt;/h3&gt;&lt;p&gt;The other half of efficient QuickCheck has to do with generators. The idea here is to generate interesting specimens of data for your random inputs. It is also this which sets apart a good QuickCheck implementations from an excellent one.&lt;/p&gt;&lt;p&gt;The thing is, you actually do not want uniform generators. You want generators which exploit the fact that some numbers are much more problematic in a system. This is also why it doesn&#39;t work to automatically derive generators from algebraic data types. You often want fine-tuning control over the generated values.&lt;/p&gt;&lt;p&gt;In transit-erlang[2], it turns out that powers of two are interesting. A generator of the form&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;Sign &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; math:&lt;span style=&#34;color:#a6e22e&#34;&gt;pow&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, X) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; P&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;where X is a natural number, Sign is either 1 or -1 and P is a small pertubation in the range -5..5 is highly useful. It instantly found a bug in the Erlang/OTP implementation. It also found numerous bugs because the interesting things often happens at the powers of two values.&lt;/p&gt;&lt;p&gt;Of course, we only pick this generator some times. We also pick deliberately small and large values. Because we know there are three ways in Transit which you can use to format numbers and we need to be fairly sure we can round-trip over all of these formatting possibilities.&lt;/p&gt;&lt;p&gt;The power of a generator can be measured in how fast it can find trouble. Ideally, you want a generator to uncover trouble in 100 test cases or less. If a generator needs several thousand samples to generate trouble, it is weak. The reason being that once you compose several generators, the numbers work against you because they are inherently multiplicative. This makes it much harder to find a problematic case.&lt;/p&gt;&lt;h3 id=&#34;what-togenerate&#34;&gt;What to generate&lt;/h3&gt;&lt;p&gt;It is important to discuss table driven unit tests. A table driven unit test is one where we have a large number of test cases driven by a table: given inputs foo and bar, we expect output baz. These are essentially enumeration generations which tries to generate all possible inputs and check the output.&lt;/p&gt;&lt;p&gt;Where enumerate generators fall short is when the set of possibilities grows exponentially. That is, when there are so many possibilities, that we cannot hope to list them all in a lifetime. In that case, we want to generate things in a stochastic way and skew the distribution so it tends toward the places we believe are hard to get right. The stochastic process aims to capture the fact that we might forget to generate certain particular states. The randomness of the process then solves this by occasionally generating things we did not think about.&lt;/p&gt;&lt;p&gt;Thus, we want to weight our generators such that they generate states which occur rarely in a real system. After all, the real system will continously check for the common case in production. So we want the corner case to be exposed in the test. This can amount to the fact, that a certain command can only fire in a rarely occurring state. In this case, we might make the command more likely to occur in that particular state. But one has to be vary of doing so.&lt;/p&gt;&lt;p&gt;First, if we inflate the chance of running command by a too large factor, then our system will always generate that command in the state. This means we don’t get to generate other commands in that state, making our model weaker.&lt;/p&gt;&lt;p&gt;Second, it may be more beneficial to weigh the system such that the state which is rare occurs more often. Then the command doesn&#39;t need changing, since the state is now merely uncommon, but not rare.&lt;/p&gt;&lt;h3 id=&#34;measure&#34;&gt;Measure&lt;/h3&gt;&lt;p&gt;The commands ‘aggregate’, ‘classify’ and‘collect’ are there for a reason. To make sure you are generating the right distribution you need to measure if you are generating things like you expect. If the distribution skews too much toward some states, you want to tune the generator. Use the distribution commands to measure that you get the right states.&lt;/p&gt;&lt;p&gt;Further, you can do as in fuse[3], and add classification to the model. The model records a set of requirements and uses this to verify which requirements are hit in a test run. If a given requirement is not hit, this is bounds for worry. The way this works is that there is a set in the model and each path taken in the model is annotated with the requirements this path covers:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;R01 - Heal non-installed fuse (must never be triggered)R02 - Heal installed fuse (only if blown already)Group install:R03 - Installation of a fuse with invalid configuationR04 - Installation of a fuse with valid configurationGroup Reset:R05 - Reset of an uninstalled fuseR06 - Reset of an installed fuse (blown and nonblown)Group Melt:R11 - Melting of an installed fuseR12 - Melting of an uninstalled fuseGroup run/2:R07 - Use of run/2 on an ok fuseR08 - Use of run/2 on a melted fuseR09 - Use of run/2 on an ok fuse which is melted in the processR10 - Use of run/2 on an uninstalled fuseGroup blow:R13 - Blowing a fuseR14 - Removing melts from the window by expiryGroup ask/1:R15 - Ask on an installed fuseR16 - Ask on an uninstalled fuse&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;after a test run, we can see what requirements were hit by that run. This makes it easy to check we are generating the right values.&lt;/p&gt;&lt;h3 id=&#34;shrinking&#34;&gt;Shrinking&lt;/h3&gt;&lt;p&gt;The final key to good generators are to make them shrink well. A failing test is of no use if we can’t figure out what is wrong and fix it. To help with this, it is crucial that when we generate a failing test, we can generate a minimal failing test.&lt;/p&gt;&lt;p&gt;When building generators, it is worth spending some time on how they will shrink. Roberto’s post[0] has much more detail on how to do this. But one additional trick is to build stuff as (binary) trees rather than as lists and then shrink toward one of the subtrees. This is also good when generating command sequences. From transit-erlang, we have the following snippet, illustrating the idea:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;transit_l&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, _N, _G) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [];&lt;span style=&#34;color:#a6e22e&#34;&gt;transit_l&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, N, G) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;LET(E, G(N), [E]);&lt;span style=&#34;color:#a6e22e&#34;&gt;transit_l&lt;/span&gt;(Sz, N, G) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt;LETSHRINK([L, R],               [transit_l(Sz &lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, N &lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, G),                transit_l(Sz &lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, N &lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, G)],      L &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; R).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The idea here is that to generate a list of size Sz, generate two halves, L and R and join them. The ?LETSHRINK combinator then shrinks to either the left or the right subtree. This allows the system to shrink a test case like this:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;#{&lt;span style=&#34;color:#ae81ff&#34;&gt;4436653002&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; ferb,  &lt;span style=&#34;color:#ae81ff&#34;&gt;5011044860&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;u&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;a324f310&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;c501&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;70&lt;/span&gt;cd&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fc42&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;fa0d338a2be&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;},  &lt;span style=&#34;color:#ae81ff&#34;&gt;7244902917&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; phineas,  &lt;span style=&#34;color:#ae81ff&#34;&gt;9902687802&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;130&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;156&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;156&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;175&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;144&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;182&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;138&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;135&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;130&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;179&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;179&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;172&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;148&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;189&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;144&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;135&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;131&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;184&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;166&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;183&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;178&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;183&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;172&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;145&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;162&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;163&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;151&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;142&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;161&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;191&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;129&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;145&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;131&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,  &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;‘&lt;/span&gt;Z&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;gt;&amp;gt;&lt;/span&gt;,  undefined &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; ab,  {transit_datetime,{&lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;397133&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;962000&lt;/span&gt;}} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;‘~&lt;/span&gt;n&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt;,  {transit_datetime,{&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;604233&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;708000&lt;/span&gt;}} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1702153900&lt;/span&gt;,  {transit_datetime,{&lt;span style=&#34;color:#ae81ff&#34;&gt;22&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;775839&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;627000&lt;/span&gt;}} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; undefined,  {transit_datetime,{&lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;458072&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;234000&lt;/span&gt;}} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;‘&lt;/span&gt;o&lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;,:T(&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;\\&lt;/span&gt;U&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt;,  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;230&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;151&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;157&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;165&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;189&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;129&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;177&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;176&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;139&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;188&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;140&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;188&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; undefined,  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;180&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;151&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;135&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;161&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;189&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;162&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;190&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;166&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;131&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;171&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;185&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;167&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;175&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;133&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;152&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;186&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;155&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;149&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;181&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;187&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;174&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;153&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;172&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;150&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;131&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;135&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;166&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;131&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;133&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;188&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;130&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;164&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;149&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;152&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;163&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;189&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;148&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;150&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;177&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;175&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;134&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;147&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;179&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;155&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;ab&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;},  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;141&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;149&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;191&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;139&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;155&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;176&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;182&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;160&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;135&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;231&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;158&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;190&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;155&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;145&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;149&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;152&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;166&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;180&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;190&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;162&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;169&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;238&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;185&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;173&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {transit_datetime,{&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;448876&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;895000&lt;/span&gt;}},  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;174&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;183&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;155&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;133&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;153&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;138&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;150&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;149&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;184&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;173&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;134&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;191&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;133&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;140&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;190&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;180&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;132&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;146&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;173&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;190&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;187&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;153&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;140&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;150&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;159&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;156&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;156&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;169&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;148&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;155&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;148&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;135&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;145&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;140&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;140&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;181&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;153&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;168&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;},  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;u&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;08&lt;/span&gt;f7fe71&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1070&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4345&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;a252&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;f0724608fe6&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt;quot;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {transit_datetime,{&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;520256&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;575000&lt;/span&gt;}},  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;u&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4040908&lt;/span&gt;a&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;783&lt;/span&gt;b&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;47&lt;/span&gt;a7&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;fde&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fff8040aba59&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt;quot;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; undefined,  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;u&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4236&lt;/span&gt;b550&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;00&lt;/span&gt;de&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f0ac&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;abf&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;14250&lt;/span&gt;dc28585&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt;quot;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {transit_datetime,{&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;165752&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;72000&lt;/span&gt;}},  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;u&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;706998&lt;/span&gt;d9&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;a0c&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;a9b&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;17&lt;/span&gt;d5&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1840&lt;/span&gt;b630a728&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt;quot;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;bcdefg&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;},  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;u&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;b0ea26b5&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;c974&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;813&lt;/span&gt;a&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;be1&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;d7c4fe21a024&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt;quot;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;u&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;b4ebcb3&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;e70&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8316&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;e76f&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;ca463210f38c&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;},  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;u&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;c762ae1a&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f244&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;d11&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;e25&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;ac91c48bd9b0&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt;quot;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {transit_datetime,{&lt;span style=&#34;color:#ae81ff&#34;&gt;22&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;869945&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242000&lt;/span&gt;}},  {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;u&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;ed9327c2&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;618&lt;/span&gt;b&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;e07d&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;b94b&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;ba904153af41&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt;quot;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; candace,  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;candace&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;},  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;160&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;159&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;166&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;236&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;153&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;160&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;239&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;132&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;182&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;188&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;170&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;150&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;146&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;175&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;153&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;143&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;130&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;146&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;141&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;175&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;226&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;169&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;191&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;130&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;190&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;135&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;186&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;150&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;137&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;163&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;158&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;184&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;137&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;157&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;182&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;146&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;144&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;187&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;173&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;175&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;159&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;129&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; undefined,  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;161&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;177&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;185&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;137&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;174&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;146&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;159&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;168&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;162&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;144&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;131&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;159&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;144&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;145&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;170&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;176&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;180&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;145&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;178&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;134&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;157&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;162&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;170&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;139&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;164&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;146&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;233&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;130&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;188&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;177&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;191&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;u&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;ef5a0950&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;fbe&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;27&lt;/span&gt;bb&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;fc4&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;–&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;94750&lt;/span&gt;b80ae64&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt;quot;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;},  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;164&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;149&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;152&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;226&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;158&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;149&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;135&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;146&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;144&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;169&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;153&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;139&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;153&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;144&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;189&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;173&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;164&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;135&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;191&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;185&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;169&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;164&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {tagged_value,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;”&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$”&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;,  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;143&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;181&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;181&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;241&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;158&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;186&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;145&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;132&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;143&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;146&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;157&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;179&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;242&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;130&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;150&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;132&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;}}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Down to this:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;  #{undefined &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt;gt; &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;‘~^’&lt;/span&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;which was much easier to work with and figure out.&lt;/p&gt;&lt;p&gt;This is why proper shrinking matters. Somewhere inside the big blurb of text, a more complicated variant of the simple test is hiding. But if we can’t minimize the input and find it, we will have no chance at catching these kinds of bugs.&lt;/p&gt;&lt;p&gt;This is also why you should know how combinators for generators shrink. By knowing the minimization patterns, you get a much better generator.&lt;/p&gt;&lt;p&gt;Parting words This ended up being much longer than I envisioned. It took two hipster-retro lattes, one coffee shop, liqorice, overhearing a conversation about studies, a happy waitress waiting for her boyfriend to get off work, and a rainy day full of downpour to write this. Interestingly, since I forgot my headphones, no music were involved in the making.&lt;/p&gt;&lt;p&gt;[0] &lt;a href=&#34;http://roberto-aloi.com/erlang/notes-on-erlang-quickcheck/&#34;&gt;http://roberto-aloi.com/erlang/notes-on-erlang-quickcheck/&lt;/a&gt;[1] &lt;a href=&#34;http://github.com/jlouis/safetyvalve&#34;&gt;http://github.com/jlouis/safetyvalve&lt;/a&gt;[2] &lt;a href=&#34;http://github.com/isaiah/transit-erlang&#34;&gt;http://github.com/isaiah/transit-erlang&lt;/a&gt;[3] &lt;a href=&#34;http://github.com/jlouis/fuse&#34;&gt;http://github.com/jlouis/fuse&lt;/a&gt;[4] In a way, SQL Injections are just a variant of a weak type coercion, where an SQL expression gets intermingled with a parameter “hole” in that expression. It is most often due to this weak stringly typed identification we see problems with SQL injection.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Two Technologies which are Bad for You</title>
       <link>https://jlouis.github.io/posts/two-tech-bad-for-you/</link>
       <pubDate>Fri, 05 Sep 2014 00:00:00 +0200</pubDate>
       
       <guid>https://jlouis.github.io/posts/two-tech-bad-for-you/</guid>
       <description>&lt;p&gt;For some odd reason, we end up in situations in this industry which looks even more grave than earlier. In this post, I am going to rant. I am going to rant on two things, which I think contributes negatively. I wanted to write a nice clean post, but rants sometimes fits ones mood better, I guess.&lt;/p&gt;&lt;h2 id=&#34;json&#34;&gt;JSON&lt;/h2&gt;&lt;p&gt;How did we get JSON? Well, we had ASN.1 which is a fine format for many things. But the complexity of that format had us rethink the way we do computing. XML was born. XML is arguably the worst format ever. It is expensive to parse. It carries little structure. There are 2–3 ways of encoding the same data. And it has a myriad of complicated layers for which most people can only comprehend a small fraction. At once I knew these intricately — but today I have luckily forgotten most of the details.&lt;/p&gt;&lt;p&gt;Enter JSON. It is a simple format. Everyone can write a somewhat decent parser/unparser for it. So it won. But JSON is utterly miserable:&lt;/p&gt;&lt;p&gt;First off, we would have been better off if we locked down the encoding to UTF-8. That is, the media type[0] for JSON documents mandates UTF-8 and then we have separate media types for insane encodings. This would allow us to come with a big hammer and reject any JSON document encoded in other ways.&lt;/p&gt;&lt;p&gt;Second, JSON inherits all the miserable bad traits from everyones favorite language to hate: javascript.&lt;/p&gt;&lt;p&gt;In JSON, a number is a crippled IEEE 754 double floating point value (binary64). In 754, we use 52 bits for the significand with an extra bit implicitly present. This gives 53 bits of precision. Thus, up until the value 9007199254740992 we have a precise integer representation, but once we go beyond this, we lose precision. Try storing the above number +1 in a piece of code. It is not representable directly in JSON, which means you have to resort to other solutions. The most common one being to write the string “9007199254740993” into the JSON document. But this only works well for languages with implicit conversions of types. Any other language will not work well for this construction.&lt;/p&gt;&lt;p&gt;There is no distinction between binary data and string data. Since the encoding is UTF-8 this is important, since there are byte-sequences which are not valid UTF-8. The consequence is that whenever you want to send binary data, you have to encode it, typically in base64 or base85. This leads to each subsystem having to implement the same encoding and agree. Whenever your code has to work with a new kind of JSON data, you have to adhere to its rules which requires more code.&lt;/p&gt;&lt;p&gt;JSON has a dictionary/object type. This type only allows keys which are strings. That is, the type is (using Erlang spec’s)&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;-type json() :: &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;…&lt;/span&gt; | [{string(), json()]}.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Storing anything indexed by a non-string family is impossible. No using the values ‘true’, ‘false’ or a number value as the index. This seems oddly limiting. Again, you have to resort to a predetermined encoding as above for integers to make this work out.&lt;/p&gt;&lt;p&gt;The type Zoo of JSON is extremely weak. There are almost no constructions. Since there is no well-defined way of tagging subtrees in JSON, you can’t really encode things. You need to define encodings that looks like&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-erlang&#34; data-lang=&#34;erlang&#34;&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;~#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Date&amp;#34;&lt;/span&gt;, DateRep]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;where the notion “~#Date” says that second element of the array is a representation of dates in some predetermined format.&lt;/p&gt;&lt;p&gt;Another problem is that JSON has no built-in hyperlink which utterly crippled HATEOAS (see the next section).&lt;/p&gt;&lt;p&gt;Finally, JSON is expensive to parse. It has a self-describing nature so keys in objects repeats in the data. This leads to having to traverse more bytes leading to slower parses. Furthermore, getting parsing right slows down the parser rather than speeds it up; encouraging hacks of incorrectness.&lt;/p&gt;&lt;h3 id=&#34;the-solution&#34;&gt;The Solution&lt;/h3&gt;&lt;p&gt;Luckily, the guys at Cognitect thought about this and more. They defined the format Transit[2, 3] in which all of the limitations have been cleared away. While the format still has some way to go, it is a far better solution than what we have now.&lt;/p&gt;&lt;p&gt;To be viable, Transit needs a more formal specification of its implicit caching. I have spent some time with an OCaml and Erlang implementation (the Erlang implementation together with Isaiah Peng). And we are far from something that is stable enough for daily use. But given enough time, it will eventually improve to the point where it can replace JSON.&lt;/p&gt;&lt;p&gt;Transit is clever because it reuses JSON (or MsgPack) as the underlying transport. This enables systems to interoperate with Transit, as long as they have a proper Transit library. It also means any new self-describing format can probably used as a transport for Transit. The de-coupling of format from transport is a nice welcome change. The architecture layers nicely.&lt;/p&gt;&lt;h2 id=&#34;rest-httpapis&#34;&gt;REST HTTP APIs&lt;/h2&gt;&lt;p&gt;Here is a recent announcement by Google[4]:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Designed to let you easily deliver Gmail-enabled features, this new API is a standard Google API, which gives RESTful access to a user’s mailbox under OAuth 2.0 authorization. It supports CRUD operations on true Gmail datatypes such as messages, threads, labels and drafts.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Stop right there! This is not a protocol. It is an endpoint in the Google infrastructure which requires the Google infrastructure to operate. If you build anything on this, you tie yourself into that infrastructure, with no way to get out again.&lt;/p&gt;&lt;p&gt;It is true of any “API” by any company: Micro-soft, Facebook, Twitter. API is originally “Application Programming Interface”. But in this new-fangled context, it is more akin to “Automatic Prison Installation” in which your system becomes part of a walled garden.&lt;/p&gt;&lt;p&gt;The internet is built on open protocols. But “these are not the protocols you are looking for”. An API is not an open, decentralized protocol. It is a closed environment which is closed for extension. Worse, the success of Javascript and HTTP have forced everyone to speak HTTP to solve their problems. To interact in the modern world is to speak HTTP, preferably with JSON or XML data (oh, the horror!).&lt;/p&gt;&lt;p&gt;REST is a magnificent idea[5]. But we aren’t doing it. We are doing some subset of what REST entails in many situations. We ignore HATEOAS, mostly because JSON can’t represent links in unique ways. We can’t even agree on a standardized de-facto way of doing pagination in REST environments because so many systems only understands a subset of what it entails. Interaction with old systems has you breaking REST again and again, making it a sorry replacement for the original ideas of Fielding[6].&lt;/p&gt;&lt;p&gt;The end result is more walled gardens with closed implementations of software. We are tightly coupling our work to the work of the big centralized companies which are only keen on selling information about our behavior to 3rd parties, or doing a business by acting as middlemen, pairing our behavior with 3rd parties.&lt;/p&gt;&lt;p&gt;What made a protocol like HTTP or TCP beautiful is that they specify a minimal set of requirements for interoperation. TCP is very wide in the sense you can implement it on an Arduino shield with one buffer around 1 kilobyte. And also in hardware on a 40 gigabit Ethernet card. And those two implementations can talk to each other, albeit slowly. TCP is simple enough you can build a conforming implementation on a Commodore 64 or less. Likewise, a minimal HTTP implementation is easily possible.&lt;/p&gt;&lt;p&gt;The reason this works is because the protocol specify minimal requirements while being open for extension. None of these new APIs do that. Ugh!&lt;/p&gt;&lt;h3 id=&#34;the-solution-1&#34;&gt;The solution&lt;/h3&gt;&lt;p&gt;We need to go back to our roots and start building protocols again. This change will never come from a large company. It has to rely on an open tinkerer culture. We need well-defined protocols and multiple implementations of these. Protocol design is quickly becoming a lost art. Rather, people are satiated with “APIs” to the point where they can’t recover.&lt;/p&gt;&lt;p&gt;We need de-centralization. The internet is built on the idea of end-to-end interaction between machines. The current state is more of a client/server infrastructure in which few central entities drive the status quo.&lt;/p&gt;&lt;p&gt;We need distribution. If we rely on big players, we tie ourselves to their solutions. This will be a bane going forward as we build infrastructure around vendors only interesting in lock-in.&lt;/p&gt;&lt;p&gt;And finally, we need education. A lot of the current “protocol design” is so bad compared to what can be found in old RFCs. If you want to implement something new, you need to study the past a lot before you build it. If you reject an old idea, you need to explain why. If you reinvent an old idea, you need to know you reinvented it and what happened historically for that idea not to catch on.&lt;/p&gt;&lt;p&gt;If we don’t do anything, the internet as we know it will be taken from us.&lt;/p&gt;&lt;p&gt;[0] Some call this MIME-type, but the name was changed a long time ago.[1] See &lt;a href=&#34;http://en.wikipedia.org/wiki/Double-precision_floating-point_format&#34;&gt;http://en.wikipedia.org/wiki/Double-precision_floating-point_format&lt;/a&gt;[2] See &lt;a href=&#34;http://blog.cognitect.com/blog/2014/7/22/transit&#34;&gt;http://blog.cognitect.com/blog/2014/7/22/transit&lt;/a&gt;[3] &lt;a href=&#34;https://github.com/cognitect/transit-format&#34;&gt;https://github.com/cognitect/transit-format&lt;/a&gt;[4] &lt;a href=&#34;http://googleappsdeveloper.blogspot.dk/2014/06/introducing-new-gmail-api.html&#34;&gt;http://googleappsdeveloper.blogspot.dk/2014/06/introducing-new-gmail-api.html&lt;/a&gt;[5] &lt;a href=&#34;http://blog.steveklabnik.com/posts/2011-07-03-nobody-understands-rest-or-http&#34;&gt;http://blog.steveklabnik.com/posts/2011-07-03-nobody-understands-rest-or-http&lt;/a&gt;[6] Roy T. Fielding: &lt;a href=&#34;http://en.wikipedia.org/wiki/Roy_Fielding&#34;&gt;http://en.wikipedia.org/wiki/Roy_Fielding&lt;/a&gt;  —  funnily enough, as of this writing, someone stuck a link to Sinatra on Roy’s wikipedia page. Sinatra is a Ruby-framework for doing “REST”. It is funny because Sinatra is everything — except for being a nice HTTP citizen. If you want a better approach, look at Webmachine or Cowboy-REST (both Erlang projects).&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Erlang and code style</title>
       <link>https://jlouis.github.io/posts/erlang-and-code-style/</link>
       <pubDate>Tue, 20 May 2014 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/erlang-and-code-style/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Correct Erlang usage mandates you do not write any kind of defensive code. Thisis called &lt;em&gt;intentional programming&lt;/em&gt;. You write code for the intentional controlflow path which you expect the code to take. And you don’t write any code forthe paths which you think are not possible. Furthermore, you don’t write codefor data flow which was not the intention of the program.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_it_is_an_effectsilly&#34;&gt;It is an effect, silly&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;If an Erlang program goes wrong, it crashes. Say we are opening a file. We can&lt;em&gt;guard&lt;/em&gt; the file open call like so:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;{ok, Fd} = file:open(Filename, [raw, binary, read, read_ahead]),&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;What happens if the file doesn’t exist? Well the process crashes. But note wedid not have to write any code for that path. The default in Erlang is to crashwhen a match isn’t valid. We get a badmatch error with a reason as to why wecould not open the file.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;A process crashing is not a problem. The program is still operating andsupervision—An important fault-tolerance concept in Erlang—will make sure thatwe try again in a little while. Say we have introduced a race condition on thefile open, by accident. If it happens rarely, the program would still run, evenif the file open fails from time to time.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;You will often see code that looks like:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;ok = foo(...),&amp;lt;br&amp;gt;ok = bar(...),&amp;lt;br&amp;gt;ok = ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;which then asserts that each of these calls went well, making sure code crashesif the control and data flow is not what is expected.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Notice the complete lack of error handling. We don’t write&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;case foo(...) of  ok -&amp;gt; case bar(...) of ... end;  {error, Reason} -&amp;gt; throw({error, Reason})end,&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Nor do we fall into the trap of the Go programminglanguage and write:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;res, err := foo(...)if err != nil {  panic(...)}res2, err := bar(...)if err != nil {  panic(...)}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;because this is also plain silly, tedious and cumbersometo write.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The key is that we have a crash-effect in the Erlang interpreter which we caninvoke where the default is to crash the process if something goes wrong. Andhave another process clean up. Good Erlang code abuses this fact as much aspossible.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_intentional&#34;&gt;Intentional?&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Note the word intentional. In some cases, we do expect calls to fail. So we justhandle it like everyone else would, but since we can emulate sum-types inErlang, we can do better than languages with no concept of a sum-type:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;case file:open(Filename, [raw, read, binary]) of    {ok, Fd} -&amp;gt; ...;    {error, enoent} -&amp;gt; ...end,&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Here we have written down the intention that the file might not exist. However:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;We only worry about non existence.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;We crash on &lt;code&gt;eaccess&lt;/code&gt; which means an access error due to permissions.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Likewise for &lt;code&gt;eisdir&lt;/code&gt;, &lt;code&gt;enotdir&lt;/code&gt;, &lt;code&gt;enospc&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_why&#34;&gt;Why?&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Leaner code, that’s why.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;We can skip lots of defensive code which often more than halves the code size ofprojects. There are much less code to maintain so when we refactor, we need tomanipulate less code as well.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Our code is not littered with things having nothing to do with the “normal” codeflow. This makes it far easier to read code and determine what is going on.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Erlang process crashes gives lots of information when something dies. For aproper OTP process, we get the State of the process before it died and whatmessage was sent to it that triggered the crash. A dump of this is enough inabout 50% of all cases and you can reproduce the error just by looking at thecrash dump. In effect, this eliminates a lot of silly logging code.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_data_flow_defensive_programming&#34;&gt;Data flow defensive programming&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Another common way of messing up Erlang programs is to mangle incoming datathrough pattern matching. Stuff like the following:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;convert(I) when is_integer(I) -&amp;gt; I;convert(F) when is_float(F) -&amp;gt; round(F);convert(L) when is_list(L) -&amp;gt; list_to_integer(L).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The function will convert “anything” to an integer. Thenyou proceed to use it:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;process(Anything) -&amp;gt; I = convert(Anything), ...I...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The problem here is not with the process function, but with the call-sites ofthe process function. Each call-site has a different opinion on what data isbeing passed in this code. This leads to a situation where every subsystemhandles conversions like these.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;There are several disguises of this anti-pattern. Here isanother smell:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;convert({X, Y}) -&amp;gt; {X, Y};convert(B) when is_binary(B) -&amp;gt;    [X, Y] = binary:split(B, &amp;lt;&amp;lt;&amp;#34;-&amp;#34;&amp;gt;&amp;gt;),    {X, Y}.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This is stringified programming where all data are pushed into a string and thenmanually deconstructed at each caller. It leads to a lot of ugly code withlittle provision for extension later.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Rather than trying to handle different types, enforce the invariant early on theapi:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;process(I) when is_integer(I) -&amp;gt; ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;And then never test for correctness inside your subsystem. The dialyzer is goodat inferring the use of I as an integer. Littering your code with is_integertests is not going to buy you anything. If something is wrong in your subsystem,the code will crash, and you can go handle the error.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;There is something to be said about static typing here, which will force you outof this unityped world very easily. In a statically typed language, I couldstill obtain the same thing, but then I would have to define something along thelines of (* Standard ML code follows *)&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;datatype anything = INT of int                  | STRING of string&amp;lt;br&amp;gt;                  | REAL of real&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;and so on. This quickly becomes hard to write pattern matches for, so hencepeople only defines the anything type if they really need it. (Gilad Bracha waspartially right when he identified this as a run-time check on the value, butwhat he omitted was the fact that the programmer has the decision to avoid acostly runtime check all the time—come again, Gilad ☺).&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sect2&#34;&gt;&lt;h3 id=&#34;_the_scourge_of_undefined&#34;&gt;The scourge of undefined&lt;/h3&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Another important smell is that of the &lt;code&gt;undefined&lt;/code&gt; value. The story here is thatundefined is often used to program a Option/Maybe monad. That is, we have thetype&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;-type option(A) :: undefined | {value, A}.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;(For the static typists out there: Erlang does have a type system based onsuccess types for figuring out errors, and the above is one such typedefinition)&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;It is straightforward to define reflection/reification into an exception-effectfor these. Jakob Sievers&lt;a href=&#34;https://github.com/cannedprimates/stdlib2/blob/master/src/s2_maybe.erl&#34; class=&#34;bare&#34;&gt;https://github.com/cannedprimates/stdlib2/blob/master/src/s2_maybe.erl&lt;/a&gt; stdlib2library already does this, as well as define the monadic helper called do(Though the monad is of the Error-type rather than Option).&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;But I’ve seen:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;-spec do_x(X) -&amp;gt; ty() | undefined  when X :: undefined | integer().do_x(undefined) -&amp;gt; undefined;do_x(I) -&amp;gt; ...I....&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Which leads to complicated code. You need to be 100% incontrol of what values can fail and what values can not. Constructions like the above silently passes undefined on.This has its uses—but be wary when you see code like this. The &amp;lt;em class=&amp;#34;markup—​em markup—​p-em&amp;#34;&amp;gt;undefined&amp;lt;/em&amp;gt;value is essentially a &amp;lt;em class=&amp;#34;markup—​em markup—​p-em&amp;#34;&amp;gt;NULL&amp;lt;/em&amp;gt;. And those were C.A.R Hoare’s billion dollarmistake.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The problem is that the above code is nullable. The default in Erlang is that you never have NULL-like values.Introducing them again should be used sparingly. You will have to think long and hard because once a value isnullable, it is up to you to check this all the time. This tend to make code convoluted and complicated. It is betterto test such things up front and then leave it out of the main parts of the code base as much as possible.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect2&#34;&gt;&lt;h3 id=&#34;_open_data_representations&#34;&gt;“Open” data representations&lt;/h3&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Whenever you have a data structure, there is a set of modules which knows aboutand operates on that data structure. If there is only a single module, you canemulate a common pattern from Standard ML or OCaml where the concrete datastructure representation is abstract for most of the program and only a singlemodule can operate on the abstract type.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This is not entirely true in Erlang, where anyone can introspect any data. Butkeeping the illusion is handy for maintainability.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The more modules that can manipulate a data structure, the harder it is to alterthat data structure. Consider this when putting a record in a header file. Thereare two levels of possible creeping insanity:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;You put the record definition in a header file in &lt;code&gt;src&lt;/code&gt;. In this case only theapplication itself can see the records, so they don’t leak out.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You put the record definition in a header file in &lt;code&gt;include&lt;/code&gt;. In this case therecord can leak out of the application and often will.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;A good example is the HTTP server cowboy where its request object is manipulatedthrough the cowboy_req module. This means the internal representation can changewhile keeping the rest of the world stable on the module API.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;There are cases where it makes sense to export records. But think before doingso. If a record is manipulated by several modules, chances are that you can wina lot by re-thinking the structure of the program.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect2&#34;&gt;&lt;h3 id=&#34;_the_values_true_and_false_are_of_typeatom&#34;&gt;The values ‘true’ and ‘false’ are of type atom()&lt;/h3&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;As a final little nod, I see too much code looking like&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;f(X, Y, true, false, true, true),&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Which is hard to read. Since this is Erlang, you can just use a better name forthe true and false values. Just pick an atom which makes sense and then producethat atom. It also has the advantage to catch more bugs early on if argumentsget swapped by accident. Also note you can bind information to the result, bypassing tuples. There is much to be said about the concept of boolean blindnesswhich in typical programs means to rely too much on boolean() values. Theproblem is that if you get a true say, you don’t know why it was true. You wantevidence as to its truth. And this can be had by passing this evidence in atuple. As an example, we can have a function like this:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;case api:resource_exists(ID) of    true -&amp;gt; Resource = api:fetch_resource(ID), ...;    false -&amp;amp;gt; ...end.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;But we could also write it in a more direct style:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;case api:fetch_resource(ID) of    {ok, Resource} -&amp;gt; ...;    not_found -&amp;gt; ...end.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;(Edit: I originally used the function name &lt;code&gt;resource_exists&lt;/code&gt; above but Richard Carlsson correctly points out this isa misleading name. So I changed it to something with a better name)&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;which in the long run is less error prone. We can’t by accident call thefetch_resource call and if we look up the resource, we also get hold of theevidence of what the resource is. If we don’t really want to use the resource,we can just throw it away.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect2&#34;&gt;&lt;h3 id=&#34;_closing_remarks&#34;&gt;Closing remarks&lt;/h3&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Rules of thumb exists to be broken. So once in a while they must be broken.However, I hope you learnt something or had to stop and reflect on something ifyou happened to get here (unless you scrolled past all the interesting stuff).&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I am also interested in Pet-peeves of yours, if I am missing some. The way tobecome a better programmer is to study the style of others.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>Erlang String Handling</title>
       <link>https://jlouis.github.io/posts/erlang-string-handling/</link>
       <pubDate>Sun, 23 Feb 2014 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/erlang-string-handling/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The cat is out of the bag. Now, since WhatsApp had success using Erlang, morepeople will gravitate toward the platform. One of the common things that willhappen as a result is that people who do not understand the string handlingcapabilities of the Erlang BEAM VM will fail to use it correctly. This costs alot of unneeded clock cycles and this post aims to thwart it.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;First of all, since this is rather VM specific, it also applies to Elixir users.The VM basically handles strings the same way, so you should be thinking in thesame general direction as I am doing here, for Erlang. Though Elixir, to thebest of my knowledge, maps its string type onto binaries.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The first thing to understand is that Erlang is a functional language first andforemost. This means, among other things, data will be immutable by constructionand there is no way to circumvent that. It also means certain tricks pertainingto ephermeral mutability is out the window. And it would be outright against thespirit of Erlang to have mutable data in any form.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_when_you_should_avoid_using_erlang_in_the_firstplace&#34;&gt;When you should avoid using Erlang in the first place&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Erlang as a language fares bad at programs where you have a &lt;em&gt;small&lt;/em&gt;computational kernel which &lt;em&gt;has to&lt;/em&gt; be extremely fast. This is the case for alot of heavyweight processing tasks. It is often better to take your kernel andmove it into another language, or in some cases move the kernel onto an FPGA orinto hardware, depending on your needs.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Depending on the problem, it may not be efficient to spend your timeimplementing the code in Erlang. Unless you plan to utilise some of the otherErlang strengths, like robustness, you may be better off by just implementingyour system in Go or Clojure. Alternatively, you can write a NIF and then handlethe core kernel in C. Don’t use Erlang when another tool solves the job in a waybetter and way faster way. A rough estimate is that C code is 20-50 times fasterfor tight computational kernels.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The Erlang language is built for handling more complex interactions where theraw execution speed matter less and the program structure matters more. If yoursystem has no specific kernel which is executing for heavyweight processing,then Erlang might suit your needs. If your system is bound to memory or I/O thenErlang may be &lt;em&gt;very&lt;/em&gt; suitable.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;You goal is to get most processing out of the emulator loop and onto the BEAM VMcore. The runtime core is very efficient at handling large amounts of data andmany structures are built such that they can sustain heavy load. A good way tolook at this is with the linux perf(1) tool. Run perf on the beam.smp emulatorand if &lt;code&gt;beam_emu.c&lt;/code&gt; is spending too much time, chances are you are processingheavy. Even processing-heavy applications I have written tend to have 20% timespent in the emulator loop. The consequence is you can’t win much by replacingthe interpreter with a JIT or a native code compiler. You can only, at best,squeeze the 20% so it is limited how much faster you can get the code by doingthis.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;quoteblock&#34;&gt;&lt;blockquote&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Aside: A JIT would still be useful so more of the Erlang system could be writtenin Erlang rather than C. But for most code, it is not given a priori it wouldyield a speedup.&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_what_is_a_string&#34;&gt;What is a string()?&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The Erlang string type is implemented as a single-linked-list of unicode codepoints. That is, if we write “Hello” in the language, this is represented as&lt;code&gt;[$H, $e, $l, $l, $o]&lt;/code&gt;. The overhead of this representation is massive. EachCons-cell use 8 bytes for the code point and 8 bytes for the pointer to the nextvalue. This means that the 5-byte ASCII-representation of “Hello” is 5*16 = 80bytes in the Erlang representation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Strings are shared. If we write &lt;code&gt;L = &amp;#34;World&amp;#34;,&lt;/code&gt; followed by &lt;code&gt;A = &amp;#34;Hello&amp;#34; ++ L&lt;/code&gt;,then A and L shares the tail, due to persistence and immutability. In some casesthis can be utilised to limit the amount of data present in a system, andsomewhat help with the massive data blowup you will otherwise see.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Erlang is not unique in having the string-as-integer-list representation. It isthe same representation which is used by Haskell. But since no type informationis present, you can’t discriminate between a list of integers and a string. Youwill have to know from the code at hand.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;There are a lot of disadvantages of this representation. It results in memoryblowup, more cache misses, more data bandwidth use, and so on. On the otherhand, all the normal list-processing functions are present and can be used onstrings alike. So to manipulate strings, you have access to four modules:&lt;code&gt;[string, lists, unicode, re]&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The module &lt;code&gt;string&lt;/code&gt; contains valuable helper functions for manipulation of strings. Most importantly:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;dlist&#34;&gt;&lt;dl&gt;&lt;dt class=&#34;hdlist1&#34;&gt;&lt;code&gt;string:tokens/2&lt;/code&gt;&lt;/dt&gt;&lt;dd&gt;&lt;p&gt;which can be used to split a string into parts, and&lt;/p&gt;&lt;/dd&gt;&lt;dt class=&#34;hdlist1&#34;&gt;&lt;code&gt;string:join/2&lt;/code&gt;&lt;/dt&gt;&lt;dd&gt;&lt;p&gt;which can join strings together with a separator.&lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I normally only use plain strings like these when the data sizes are rathersmall and we are not on a critical code path. Otherwise, you need to dosomething else in order to make things work quickly and efficiently.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The &lt;code&gt;lists&lt;/code&gt; module contains many functions which are useful for working withstrings. As an example, &lt;code&gt;lists:prefix/2&lt;/code&gt; can be used on strings as well.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The &lt;code&gt;re&lt;/code&gt; module implements regular expressions. Here is thebasic rule:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;quoteblock&#34;&gt;&lt;blockquote&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Do NOT use the &lt;code&gt;re&lt;/code&gt; module&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Usually, there are better ways to handle data than to supply a regularexpression to handle it. Mind you, I utterly love using regexes in editors and Ialso like using them in lexers. But for most normal data processing, regularexpressions are overkill. Also, the regular expression engine in Erlang has beenaltered so it preempts. This avoids a long-running regex to destroy the VM’sscheduling mechanism.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Typical code will have maybe one or two calls to the &lt;code&gt;re&lt;/code&gt; module per 5000 linesof code. If you have more than that, chances are you are trying to program PERLin Erlang. And that is a bad idea.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;However, the &lt;code&gt;re&lt;/code&gt; module is way faster than the older &lt;code&gt;regexp&lt;/code&gt; module which was deprecated.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_the_binarytype&#34;&gt;The binary() type&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Erlang, like Haskell, saw the problem with a memory-heavy string type. So theyboth implement a type which is more efficient at handling large amounts of data.In Erlang, this is called a &lt;code&gt;binary&lt;/code&gt; and in Haskell it is called a &lt;code&gt;ByteString&lt;/code&gt;.Binaries are arrays of binary data. They are immutable, which means they can beshared. Also, referral to subparts of a binary can be shared by having thesystem store 3 values called a sub-binary:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A pointer to the original binary&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;An offset&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A size&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Note that sub-binaries work a bit like Go’s slice construction in this way. TheVM is built such that passing around binaries and subbinaries are alwaysefficient. The trick is immutability, which allows the system to pass pointerson binaries rather than passing the binary value itself.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Binaries, like in Go, also has extra &lt;em&gt;capacity&lt;/em&gt; in the sense that in some casesa binary can be appended to efficiently without having to copy the binary datato a new place. The system will automatically extend binaries with extracapacity when they are copied, ensuring efficient append.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When programming Erlang, the compiler and VM will automatically generatebinaries and sub-binaries for you. Write your code in a straightforward andreadable manner first. Then compile your program with &lt;code&gt;+bin_opt_info&lt;/code&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;to have the compiler report on which binaries were not optimised in code whichis heavily traversed by the program.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Binaries can be pattern matched. This is extremely efficient, but sometimes youcan’t write a matching rule since they essentially work from the beginningalways. You can’t “search” in a binary until you hit something which matches bya single pattern match. The way to handle this problem is by using the &lt;code&gt;binary&lt;/code&gt;module:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;binary:split/3&lt;/code&gt; is extremely powerful. It is the binary variant of&lt;code&gt;string:tokens/2&lt;/code&gt; but it is returning shared data and so does only produce asmall amount of garbage. The split string simply refers into the original binarythrough sub-binaries. Be very aware of the option “[global]” which will allowyou to split the binary into more than two parts.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;binary:match/3&lt;/code&gt; is your generic search routine for picking out parts deeply in binary data.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;binary:compile_pattern/1&lt;/code&gt; allows you to build some simple compiled patterns like a weaker(but way faster) regular expression search&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;binary:copy/1&lt;/code&gt; forces a copy of a binary. This is useful if you have a 1 megabyte binary andyou have found a 45 byte sequence in it—and you only want that sequence. Then you can copythe sequence which means you don’t hold on to the 1 megabyte binary anymore—in turn allowingthe garbage collector to collect it. This is extremely useful if you are cutting input intopieces (with &lt;code&gt;split/3&lt;/code&gt;) and storing it at rest for a long time. For instance in ETS.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_the_iodata_type&#34;&gt;The iodata() type&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;There is another quite important data type which I want to describe. These arecalled &lt;code&gt;iodata()&lt;/code&gt; or &lt;code&gt;iolists()&lt;/code&gt;. The rule is the following:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A list of integers in the range 0..255 is IOData.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A binary is IOData.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Lists of IOData is IOData.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In particular, this means you can form IOData by collecting IOData as lists.This means string concatenation in the language is O(1). &lt;code&gt;p(IOData) → [&amp;#34;&amp;lt;p&amp;gt;&amp;#34;, IOData, &amp;#34;&amp;lt;/p&amp;gt;&amp;#34;].&lt;/code&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The &lt;code&gt;p/1&lt;/code&gt; function given here will wrap IOData in a standard paragraph sectionin HTML, but it will not reallocate any data, nor will it generate any garbage.The sections “&amp;lt;p&amp;gt;” and “&amp;lt;/p&amp;gt;” are constants, so the only allocation that willhappen will be for the front of the list, two list elements.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Most IO functions in Erlang understands IOData directly. This means you canavoid having to flatten data, but just send the IOData out over a socket or thelike. It avoids costly allocations and copies on the IO pipe in your program.Highly recommended!&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;A good way to gauge how well thought out a library is is to look at how well ithandles IOData. If it doesn’t and requires you to explicitly call&lt;code&gt;iolist_to_binary/1&lt;/code&gt; then chances are the library is not that well written.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_handling_unicode_data&#34;&gt;Handling &lt;code&gt;unicode()&lt;/code&gt; data&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Unicode data in Erlang is handled by the &lt;code&gt;unicode&lt;/code&gt; module, which can convert betweenrepresentations of Unicode. My recommendation however, would be to keep most unicode data as UTF-8 stringsin binaries. You can match on unicode code-points:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;-module(z).-export([len/1]).len(B) when is_binary(B) -&amp;gt;len(B, 0);len(&amp;lt;&amp;lt;&amp;gt;&amp;gt;, K) -&amp;gt; K;len(&amp;lt;&amp;lt;_ /utf8, Rest/binary&amp;gt;&amp;gt;, K) -&amp;gt; len(Rest, K+1).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This is useful together with the ability to input character strings as UTF-8:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;listingblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;Erlang R16B03-1 (erts-5.10.4) [source-ce3d6e8] [64-bit] [smp:8:8] [async-threads:10] [hipe] [kernel-poll:false][dtrace]Eshell V5.10.4 (abort with ^G)...2&amp;gt; z:len(&amp;lt;&amp;lt;”Rødgrød med fløde”/utf8&amp;gt;&amp;gt;).173&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In Release 17.0, the default will be UTF-8 in Erlang files. This will probablyhave some deep effects on Erlang source code, but it will ultimately helpgetting Unicode into Erlang. Release 18.0 is planned to accept unicode atoms aswell, to open up the design space.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_attack_vectors&#34;&gt;Attack Vectors&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The basic rule of all Erlang string handling is this:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;quoteblock&#34;&gt;&lt;blockquote&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Never never NEVER work on stringly typed data&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When data is “stringly” typed, it means that your data has no structure andeverything are represented in strings. This is fairly expensive to work on for asystem since you are limited to use the string-handling code. Parsing is alwaysexpensive and this hurts your processing speed. Some languagues, like awk orperl are built to process these kind of things. But you rather do not want to dothis processing in Erlang.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The way you avoid stringly typed data is to take the input and transform it asearly as possible into structured data inside your code. That way, you can avoidworking on the string data, and you only need it in a few places. The morestructure you can attach to the data, the better.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The primary problem is when you have to work with a bad data format. Again, thetrick is to turn the bad format into something sensible quickly and then processit as sensible data.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Erlang is designed to work with data that has structure. With structure, you canpattern match which is fast. Without structure, you have to rely on standardtechniques and this is almost always going to be a pain in the language. Sodon’t do it. Convert data into a structured format and then proceed by handlingthe structure with pattern matches.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_immutability&#34;&gt;Immutability&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Erlang takes a stance. All data are immutable. In particular, strings areimmutable. Binaries are immutable. There will be an overhead to this stance. Ifyou can’t accept this, you must pick another language. That said, the advantagesof immutability far outshine the benefits of immutability.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Erlang is immutable because it eliminates a large source of programming errorsand programming mistakes. After all, the value of an incorrect program is lowerthan a correct one. This stance is highly unlikely to be changed, since thesafety guarantee provided by immutability is part of the Erlang-DNA.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_when_you_have_control_of_data&#34;&gt;When you have control of data&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In some situations you control the format of the data you are going to use. Thisis an &amp;lt;em class=&amp;#34;markup—​em markup—​p-em&amp;#34;&amp;gt;excellent&amp;lt;/em&amp;gt; oppurtunity to picksome clever ways of working with data. In particular to enforce structure ondata by default. If communicating between Erlang systems, you can use&lt;code&gt;term_to_binary/1&lt;/code&gt; &amp;amp; &lt;code&gt;binary_to_term/2&lt;/code&gt; and just put data at rest in thestandard Erlang-format. If the foreign system also supports this format, it isan excellent way to interchange data. The encoder/decoder for this format iswritten in C and it also handles very large terms with grace—the running processwill be preempted while producing the binary.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The man page for &lt;code&gt;inet&lt;/code&gt;, &lt;code&gt;erl -man inet / setopts\( RET&lt;/code&gt; describes common socketoptions you can set on a socket. By setting the &lt;code&gt;packet&lt;/code&gt; option you can controlhow the system decodes inbound data. Most interesting, you can set ASN.1 BERencoding or Line-wise encoding. If you value speed, you should consider anefficient binary format.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_json&#34;&gt;JSON&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The ubiquitous format today, you need to handleis JSON data. I don’t particularly like JSON as a data exchange format, since it is very weak in whattypes it encodes. I’d much rather have a format like Joe Armstrong’s UBF or the Clojure &lt;code&gt;edn&lt;/code&gt; &amp;amp; &lt;code&gt;data.fressian&lt;/code&gt; encodings. But JSON it is. There are two good JSON libraries for Erlang:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;dlist&#34;&gt;&lt;dl&gt;&lt;dt class=&#34;hdlist1&#34;&gt;jsx &lt;/dt&gt;&lt;dd&gt;&lt;p&gt;&lt;a href=&#34;http://github.com/talentdeficit/jsx&#34; class=&#34;bare&#34;&gt;http://github.com/talentdeficit/jsx&lt;/a&gt;&lt;/p&gt;&lt;/dd&gt;&lt;dt class=&#34;hdlist1&#34;&gt;jiffy&lt;/dt&gt;&lt;dd&gt;&lt;p&gt;&lt;a href=&#34;http://github.com/davisp/jiffy&#34; class=&#34;bare&#34;&gt;http://github.com/davisp/jiffy&lt;/a&gt;&lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;They differ in how they are implemented. The jsx library is implemented in pureErlang and is the slower of the two. The jiffy library uses a C NIF (NativelyImplemented Function) to run the encoder and decoder and is about 10 timesfaster.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Beware: the jiffy library can’t be used to decode large JSON data sets. Thedecoder is not a well-behaved NIF and as such it can mess up the schedulers ifit is used to decode large data strings. If the JSON takes more than 1ms todecode, you should probably avoid using it. In Release 17.0, we get so-called&lt;em&gt;dirty schedulers&lt;/em&gt; which can be used to work around this problem.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The other problem with JSON data is the internalErlang representation. Right now, there is no isomorphic mapping for JSON objects/dictionaries intoErlang. This will be fixed in Release 17.0 as well, since it includes maps soyou can obtain a native mapping of objects/dictionariesinto Erlang data. I also have a side project on the run to properly handle JSON to Record encoding inErlang, but this still ongoing work. And it will take some time before it is fully implemented.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;On the other hand, note that JSON will never be a fast interchange format. Ifyou use JSON to move large amounts of data, you are screwed. Plain and simple.You best bet is then to hope data are sent as many small pieces so you can usejiffy on them. Or wait till 17.0 so you can get jiffy in a dirty-schedulervariant.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_files&#34;&gt;Files&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;You should study the section “PERFORMANCE” of the man page &lt;code&gt;erl -man file&lt;/code&gt; Notethat in order to have fast file I/O you need to open the file in “raw” mode, usebinaries, and you can usually also benefit by following some of the advice inthe section about performance. The general rule of IOData applies: If you supplyIOData, the underlying file driver is able to map this onto a unix &lt;code&gt;pwrite(2)`&lt;/code&gt;call which is highly efficient.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Not opening in raw mode does have its benefitsthough, because you can then get the IO subsystem to work. This subsystem allow you to open a file on aforeign file system (on another node) and then operate on that file. If you don’t need the high speed,this is desirable in many situations, should your system span multiple nodes.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_closing_off&#34;&gt;Closing off&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;It is a myth erlang strings are slow. You will have to think a bit moreabout what you do in order for the system to speed up. But chances are that string processing won’t beyour limit. It is much more conceivable your bottleneck will have to do with a lock, or the wrongstructure of processes than it will be slow strings.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>Error Kernels</title>
       <link>https://jlouis.github.io/posts/error-kernels/</link>
       <pubDate>Fri, 14 Feb 2014 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/error-kernels/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In any computer system, we can split the system into the part which must be correct—no matter what happens; and the part where we don’t need the system to be correct all the time.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;A typical example of this is the operating system kernel. We believe the operating system kernel to be correct, but we don’t &lt;em&gt;a priori&lt;/em&gt; trust the userland applications. If one of those fails, the kernel can take over, reap the process by killing it and reclaim the resources the process used. The reason for this is memory protection and the fact that the kernel controls the memory space.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;For programs, there is often a similar piece of the system which has to be correct at all times. But there are also computations we don’t care about. The only thing we care about is that if the system transitions from a state S1 and reaches a state S2, then this new state is consistent. And if we fail in between the transition, we can clean up by removing the failing computation from the system.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Smart programmers will identify the &lt;em&gt;Error Kernel&lt;/em&gt; of their computer system. This is the part of the code base which MUST not fail in any way. And then they will seek to make that kernel as small as possible. This corresponds to the concept of limiting the trusted computer base of a system.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Once you have identified the Error Kernel, you can design your system in a way such that you protect this part of the system the most. If you do it correctly, you should have very few lines of code which needs uttermost correctness. And better yet, you can often keep performance critical and complex code outside of the kernel.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In most languages, the way to control the Error Kernel is by the use of an exception. The idea is that code proceeds along a given path. If something goes wrong along that path, then the code raises an exception which is then handled elsewhere to clean up afterwards.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The key in exception handling code is that you must foresee the possibility of an error. Some languages used checked exceptions in order to force you to handle all possible exceptions. Others use the type system by turning the effect into a monad and then force handling through the type system. And yet others rely on the concept of human oversight to make sure that all exceptional paths are handled correctly.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Erlang uses a different mechanism—albeit it is slightly related to the exception mechanism of most languages. In Erlang, an error crashes the process. And you let another process handle the error. Done correctly, this has a number of interesting consequences:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Your program will automatically have stop-gap measures which limits faults whenever you have a concurrent activity. And you can use processes to build compartments which encapsulate error in the system. The key tools here are persistence and isolation of individual Erlang processes.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Even if you forgot to handle error in an individual process, you can use the default stance to protect the system from total failure. This is the primary reason as to why Erlang copes well with unforeseen errors in the system.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You can omit writing &lt;em&gt;defensive code&lt;/em&gt; in a lot of places. Any process which operates outside the error kernel does not need to protect itself by being defensive. This does not remove the need to check that operations succeed, but it removes the code path that tries to cope with the error locally. Rather, if something goes wrong, you “nuke it from orbit” and start all over again later or with a different premise.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The notion of the &lt;em&gt;Error Kernel&lt;/em&gt; is not confined to Erlang. It persists in any program you will write. Thinking about it tend to yield more robust system designs, and I encourage any programmer to identify it for their programs.&lt;/p&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>A moonpig-like system</title>
       <link>https://jlouis.github.io/posts/a-moonpig-like-system/</link>
       <pubDate>Sun, 29 Dec 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/a-moonpig-like-system/</guid>
       <description>&lt;div class=&#34;quoteblock&#34;&gt;&lt;blockquote&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The Raven that used to sing—​and other stories&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Mark Jason Dominus wrote about &lt;code&gt;&amp;#34;Moonpig&amp;#34;&lt;/code&gt;, which is his and Rik Signeswork on building a billing system in Perl. He wrote up his story over onhis &lt;a href=&#34;http://blog.plover.com/prog/Moonpig.html&#34;&gt;blog&lt;/a&gt;. At&lt;a href=&#34;http://www.issuu.com/&#34;&gt;Issuu&lt;/a&gt;, Francesco Zanitti, Anders Fugmann,and I wrote a system which has some similarities to Moonpig. This is ahash through that system. Currently, we mostly handle post-paidservices.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Billing mostly sucks. It is one of those areas of software where therealities of the world clashes with your nice logically structured codebase. This clash often produces problematic complications in systems forone reason or the other. Furthermore, to rub salt into the wound, mostbilling solutions out there sucks even more. So we decided, like Markand Rik, to write our own.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In hindsight, there are things we should probably have done differentlyin the structure of the system. And there are things we should perhapshave treated in other ways. But the system is in production and runs. Itrarely gets updates.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_inspiration&#34;&gt;Inspiration&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When we wrote the system, two papers inspired us.&lt;a href=&#34;http://research.microsoft.com/en-us/um/people/simonpj/papers/financial-contracts/contracts-icfp.htm&#34;&gt;ComposingContracts&lt;/a&gt; by Peyton Jones, Seward and Eber describes a small contractlanguage for financial transactions. And this language is compiled withseveral compilers to produce different interpretations of the samesyntax.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The other source of inspiration was the 3gERP project at&lt;a href=&#34;http://www.diku.dk/&#34;&gt;DIKU&lt;/a&gt; lead by Fritz Henglein. Of interest is&lt;a href=&#34;http://www.diku.dk/~hvitved/&#34;&gt;Tom Hvitved&lt;/a&gt;&amp;#39;s Phd dissertation,which describes an ERP system based on &lt;em&gt;contracts&lt;/em&gt; and &lt;em&gt;eventlogs&lt;/em&gt;. Roughly the idea is that events in the system is sent to apersistent log which is never deleted. Code in contracts read eventsfrom the log and proceed to execute. A central aspect is the concept of&lt;em&gt;replay&lt;/em&gt; where a contracts state can be replayed from the start oftime. This provides Point-in-time-recovery (PITR) of any contract at anypoint, as well as an audit log. Current contract state is kept&lt;em&gt;in-memory&lt;/em&gt; and is never persisted. Only the events that will leadto that state.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Our system—​and the 3gERP model—​consist of contract processes andagent processes. A contract poses &lt;em&gt;obligations&lt;/em&gt; which are read byagents. Once agents fulfill the obligation they send back&lt;em&gt;transactions&lt;/em&gt; to the event log—​and transactions are subsequentlypicked up by the contracts. A powerful concept in the model is that of&lt;em&gt;blame.&lt;/em&gt; If we can’t proceed in a contract due to a time constraintbeing hit, we can see which party had the obligation of an action. Thismeans we can identify if it is the customer or the company which madethe error, and handle it accordingly.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Since our system is written in Erlang, agents are separate(Erlang-)process groups. This allows our system to handle eventsconcurrently, and allows multiple subsystems to proceed. We can alsoreplace standard contracts and agents with mock variants for testing.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Currently we handle all contracts in a single Erlang-process, but thisis clearly a design mistake. We could get better isolation properties bysplitting each contract into a process of its own and then let contractsrun in a truly concurrent fashion.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Another mistake is that we route obligations and transactions over&lt;em&gt;buses&lt;/em&gt; inside the system. But it would probably have been betterto make contracts to direct-calls through a routing/proxy layer to atarget process. The current bus-model is not very Erlang-idiomatic.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_the_key_observations_aboutbilling&#34;&gt;The key observations about~billing&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Here is the primary key observation about billing:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;quoteblock&#34;&gt;&lt;blockquote&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Profit scales proportionally with the billing system load&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Modern computers are incredibly beefy. We can run a gigantic billingsystem in memory on a 7.5 or 15 Gigabyte instance on Amazon EC2. Even ifwe outscale it and need a 244 Gigabyte machine at almost \$7 per hour,chances are our profits are such that this amount of money is peanuts.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Hence, worrying about system performance is—​for most companies—​goingto be premature optimization. Much more important is correctness,durability and resilience. Thus, the focus should be on that and not&lt;em&gt;lolspeed&lt;/em&gt;. This is a welcome change of pace.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This key principle is an efficient driving force behind designdecisions. You can opt for the simple and verifiable algorithms and datastructures over the fast ones. If you ever need to go back and tune thesystem for scale, you will be making so high a profit it will be aproblem of luxury.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Some napkin math: A typical customer account runs a single contract. Acontract is around 2 Kilobytes of memory in Erlang. I have 244 Gigabytesof memory. We will run out around 128 million paying customers. Assumeprofits of $1 per customer and this is not a problem.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The second key observation is this:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;quoteblock&#34;&gt;&lt;blockquote&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;We can arrange the system such that we take all the blame for errors&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;That is, whenever we are in doubt, we give the benefit to the customer.Mark wrote about this when he decided to handle rounding errors bygiving customers the fraction which cannot be divided.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;But there are many places where this principle can be used to simplifythe code base. If a given feature costs $30,000 to implement but onlyyields you $50 a year, then the effort of implementation is clearly notworth it.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This principle gives us more freedom and flexibility in theimplementation because we can handle certain problematic areas by justignoring them while measuring their impact.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Finally:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;quoteblock&#34;&gt;&lt;blockquote&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The world is not perfect and faults will happen&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Our system is systematically built to acknowledge certain subsystemswill fail. And the approach is to regard that we are always in a statewhere the subsystem failed. More on that later.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_storage&#34;&gt;Storage&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;We store all data in a flat file on disk. Data are stored as Erlangterms in a pseudo-human-readable format (think XML, S-expressions orJSON). This is deliberate. It is much easier to read and verify.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The &lt;em&gt;current&lt;/em&gt; state is handled by a built-in database in Erlangcalled &lt;em&gt;mnesia&lt;/em&gt;. This database stores an in-memory current view.Provides a transactional store loced to the on-disk log and so on. Itprovides a cache of what is in the flat file on disk. We can alwaysthrow away the database and replay the log from the dawn of time (whichis somewhere around Nov. 2011 for this system). In principle Mnesia canalso bootstrap the system faster since we can skip over large parts ofthe log, but we have not had the reason to implement that optimizationyet. A reboot just replays from the start.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The Mnesia part also explains how we can do reporting. We have adatabase, almost Relational in nature, which we can query to extractreports. The PITR-property of the event log also lets us answerquestions back in time. But for simplicity, we just store all datapersistently in Mnesia in classic OLTP-manner.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_other_storage_options&#34;&gt;Other storage-options&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;One option we have thought of is to keep a flat file per contract andone global file. The advantage is we can then boot contracts on demandwhen we need them. The disadvantage is we loose an important property ofthe current system: linear time ordering.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The current system forces an ordering on all events and only forwardsevents in that order. This simplifies almost all of the code base.Distribution afficianados might claim that this will be a problem forperformance. But due to the primary key observation, we can ignore it.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The other option is to introduce a database to run the event log.Postgres is an obvious candidate. We have not given this much thought,but it may be an option and simplify some parts of the system.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_handling_time&#34;&gt;Handling time&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Time in our system is handled roughly like time is handled in Moonpig.Time is &lt;em&gt;injected&lt;/em&gt; or &lt;em&gt;pushed&lt;/em&gt; into the system. It is neverpulled by the system. Whenever an event happens, there is a timeparameter which is sent into the system and tells us what time it is.Functions inside the system pass on the &lt;code&gt;&amp;#34;current time&amp;#34;&lt;/code&gt; and we nevercall &lt;code&gt;erlang:now()&lt;/code&gt; nor &lt;code&gt;os:timestamp()&lt;/code&gt; inside the codebase.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The consequence is that testing is now suddenly possible. We can quicklyplay out scenarios where time is forwarded a couple of years. The testsystem controls the time fully, so it is easy to play outwhat-would-have-happened scenarios.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When running normally, we inject time at the boundary of the system whensome event happens. In effect, other users do not have to cope with thefact that time is injected into the model. But from a testingperspective, we can just pick the variant of the call where time can beoverridden.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_current_time_contract_time&#34;&gt;Current time &amp;amp; contract-time&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;A distinction from Moonpig is how we handle time in contracts. InMoonpig, time is handled by heartbeats and it is the responsibility ofsubsystems to ignore heartbeats which were duplicated etc.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In our system, contracts have an internal time which we can call &lt;code&gt;C&lt;/code&gt;. If &lt;code&gt;T&lt;/code&gt;denotes current time, we always have the property that &lt;code&gt;C &amp;lt; T&lt;/code&gt;.That is, the contracts time is always behind the current time by somesmall epsilon value. The scheme where the contract always lags behindreal time allows us to handle heartbeats in a slightly different manner.When an event is injected into the contract, a timestamp T is also sent.The contract now &lt;em&gt;forwards&lt;/em&gt; itself to the next point in time wheresomething interesting happens on the contract. This makes sure duplicateinjections of time and events are ignored by the contract.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This model also describes how we handle problems where the system fails.We have backup procedures. We can just restart the system a couple ofdays later, and it will forward time and do things correctly. Ifanything important should have happened on the days in between, theywill be handled at this point.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Note the implication: our system is always in a catch-up mode. It alwaysthinks the state of affairs is that it is behind and need to dosomething to catch up to the current situation.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_quickcheck&#34;&gt;QuickCheck&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;We never got around to do QuickCheck models for contracts, but there isan interesting property of contracts which is worth mentioning: Acontracts state is derivable from a stream of transactions. Such acontract should be indifferent to heartbeat-events and other eventstypes that happens in between the transactions. This can beprobalisitically verified by an &lt;a href=&#34;http://quviq.com/&#34;&gt;ErlangQuickCheck model&lt;/a&gt;. But we did not get to do that.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_idempotence&#34;&gt;Idempotence&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;A very important aspect of our system is idempotent &lt;code&gt;&amp;#34;best effort&amp;#34;&lt;/code&gt;delivery. When contracts want to have something done, they send out an&lt;em&gt;obligation.&lt;/em&gt; These are picked up by agents and then handled.Obligations may get lost. They are periodically restated by thecontract. If an Agent crashes, it doesn’t matter that it did not handleall the obligations. We will catch up eventually.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Agents track which obligations they have already fulfilled. If so, theyidempotently produce the same answer as before as a &lt;em&gt;transaction&lt;/em&gt;which is then sent back to the contract. Thus, if our event log systemcrashes, the agent can just send in the transaction again.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Charging works on this system as well. A charge contains a uniquereference and it handles transactions idempotently. So it doesn’t matterif the charging system sits in the other end of the world and we losethe network connection. We will just retry the charge with the samereference. Since our end handles the unique reference persistenly ondisk, we can’t generate another reference for the charge. And the otherend can safely store a transaction in their database.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Many areas can be handled with a fire-and-forget type of message. Weonly try to send mails once. If the underlying system accepts the mail,we idempotently mark it as &lt;code&gt;&amp;#34;done and sent&amp;#34;&lt;/code&gt;. This minimizes annoyanceson customers, should we have to try to resend mails.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Note that each agent is usually very simple. Often they are less than 40lines of code. And they can be checked individually, without the rest ofthe system.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;We only have to worry about progress, but that can be measured. Oursystem extensively uses the&lt;a href=&#34;http://github.com/boundary/folsom&#34;&gt;folsom&lt;/a&gt; system in Erlang totrack counters and gauges so we can see what is happening inside thenode. In fact, we track almost everything with probes in the system.Full instrumentation is something we strongly believe in for every newsystem written.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_immutability&#34;&gt;Immutability&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Like in Moonpig, we use immutable constructions all over the place. Wenever throw away data, but record it into the global event log forfuture replayability. This is also what we use when something goes wrongand we need to figure out what went wrong.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Immutability is also very powerful when one considers debugging. Sincewe have every transition recorded and full PITR-support, we canessentially always rerun the business rules of a contract and see whatwent on inside it.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Replayability has an interesting impact. When we upgrade our code innon-compatible ways, we also have to mention that upgrade in the eventlog. So old versions of the code still lives on, but is only used uptill a point. Then it is switched with new versions of the code base.Essentially the system switches between different contract versions overtime.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_floats_time_zones&#34;&gt;Floats / Time zones&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;No floats! Only integers. The system stores everything in centsinternally, but doesn’t do financial calculations. Our plan—​should weneed to do so—​was to store everything in picodollars and calculateexchange rates for other currencies. Much like all time is in UTC andare offset from there at the boundary.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;However, we do note that our billing provider expects floats, we have aboundary conversion going on…​ The mind baffles at times at thechoices made in software systems.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_what_we_skipped_on&#34;&gt;What we skipped on&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;We did not implement a DSL for writing contracts. Rather, we wrote thefew contracts we needed in (purely) functional Erlang code.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;We don’t have a lot of code in place to manage blame. This is due to thecontract simplicity currently in place. We don’t really need this.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;We could probably improve the model if we had to do it over. I believethis is &lt;em&gt;the&lt;/em&gt; way to do billing systems for the vast majority ofcompanies out there. The code is neat and modularized into contracts,agents and persisters of data. Each can be implemented with a naturalbacking into Erlang processes, proxies for foreign subsystems andRDBMs systems and so on. I also note that a system like&lt;a href=&#34;http://www.datomic.com/&#34;&gt;Datomic&lt;/a&gt; would be near-perfect to store thetransaction log. And would have a nice scalability curve to boot.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The choice of Erlang is rather nice for a system like this, wherecontracts, agents and so on can be modeled as processes. Other goodlanguages could be OCaml—​for its expressive type system, or Go—​forthe goroutines.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>The Erlang Shell</title>
       <link>https://jlouis.github.io/posts/the-erlang-shell/</link>
       <pubDate>Sun, 01 Dec 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/the-erlang-shell/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;(Front Line Assembly: Civilization, Eastern Sun: In Emptiness)&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;As an Erlang programmer I often claim that “You can’t pick parts ofErlang and then claim you have the same functionality. It all comestogether as a whole”. This is true for many programming environmentswhere the main components are built to be orthogonal from each other andthe parts form the cohesive whole. A good example of this approach wouldbe Go as well.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;A compelling way of deploying software is what supposedly originatedwith FLEX (Alan Kay). The program, the system and its data are all keptinside an &lt;em&gt;image&lt;/em&gt; which can be persisted to disk and restarted later. Inessence we specify which world we operate in by giving an image. ManySmalltalk systems utilize this notion of images. So do Common Lispsystems. And they even understand how to reconnect to networks andreopen files.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Erlang provides its own, weaker, mechanism for assembling softwarecalled a &lt;em&gt;release&lt;/em&gt;. A release consists of the runtime together with aset of Erlang applications. They are started as a whole—in a specificorder. The same release is usually booted across several machines if wewant to have resilience against hardware faults. The big shift comparedto images is that there are no on-disk persistence. The ideology isdifferent: the system should never stop, so even if one &lt;em&gt;node()&lt;/em&gt; in thecluster is stopped, the data is on other nodes as well and lives. Erlangsystems also allow for seamless upgrades from one release to anotherwhile they are running.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;But there are some resemblance from Common Lisp / Smalltalk images andErlang releases. While they don’t persist the data, Erlang images dodefine a separate enclosed system with no link to the original system.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The strength of these persistent models come apparent late in thedevelopment cycle. Software usually goes through several phases&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;\(\[\text{Analysis} \rightarrow\text{Design} \rightarrow\text{Implementation} \rightarrow\text{Test} \rightarrow\text{Deploy} \rightarrow\text{Maintenance}]\)&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;It is important to stress that development of software is a dynamicactivity. We repeatedly change the software in production by layeringmore and more complexity/features on top of the system. We alsodynamically fix bugs in the software while it is in production.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The recent years, development tends to so-called Agile methods—wherethere are many small dynamic iterations of the software constructionprocess running all at the same time. We have social tooling in placewhich tries to achieve this (Scrum, Kanban,…), and we have technicaltooling in place to reach the goal (git, Mercurial,…).&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The “Maintenance” part is very expensive. Maintaining running softwarehas periodic costs associated with it. In a world where everything is aservice, we have to pay operators, pay for hardware resources,developers, and so on.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When we program, we try to remove errors early. We employ static typesystems, we do extensive testing, we use static analysis. Perhaps weeven use probalistic model checkers like QuickCheck, exhaustive modelcheckers like SPIN or prove our software in Coq. We know, inherently,that eradicating bugs early on in the software life cycle means lesswork in the maintenance phase.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;But interestingly, all this only &lt;em&gt;raises&lt;/em&gt; the bar for errors. When wehave done all our hard work, the errors that do remain are all of thesubtle kind. These are errors which were not caught by our initialguardian systems. Most static type systems won’t capture the class offaults which has to do with slow algorithms or excessive memoryconsumption for instance. A proper benchmark suite will—but only if wecan envision the failure case up front.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The class of faults that tend to be &lt;em&gt;interesting&lt;/em&gt; is the class that cansurvive a static type check. The mere fact we could not capture it by astatic analysis in the compile phase makes the error much more subtle.Also, it often means they are much harder to trigger in productionsystems. If the fault furthermore survives the test suite it becomeseven more &lt;em&gt;interesting&lt;/em&gt;. The viral strain has a certain basic DNA whichmutated it so it could get past two barriers of correctness tests. Nowit becomes a latent bug in your software.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;&lt;em&gt;Aside:&lt;/em&gt; I tend to absolutely love static type systems. I enjoy them alot when I program in Go, Standard ML, OCaml or Haskell. I am all forthe richer description that comes with having a static type system.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;There is a great power in being able to say \(v \colon \tau\)rather than just \(v\)—exactly because the formerrepresentation is &lt;em&gt;richer&lt;/em&gt; in structure. Richer structure helpsdocumentation, makes it possible to pick better in-memoryrepresentations, makes the programs go faster and forces a more coherentprogramming model.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Yet, I also recognize that most of the errors caught by static typesystems are &lt;strong&gt;not&lt;/strong&gt; &lt;em&gt;interesting.&lt;/em&gt; They are of the kind where a simple runof the program will find them instantly.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;&lt;em&gt;End of Aside.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_concurrency_and_distribution_failures&#34;&gt;Concurrency and Distribution failures&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When systems have faults due to concurrency and distribution, debuggerswill not work. The problem is that you can’t stop the world and then goinspect it. A foreign system will inspect an answer in time or it willtime out. Many modern systems have large parts of which you have nodirect control anymore. Such is life in the Post-1991 era of computingwhere the internet defines the interface to your program and itscomponents. An Erlang system with two nodes is enough to be problematic.Even if I could snapshot one node, the other node will carry on.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The same is true for concurrency errors. They often incorporate raceconditions which must trigger. Attaching a debugger alters the executionschedule making the race condition disappear in the process. The onlyway to debug such systems is by analysing post-mortem traces of whatwent wrong—or by inspecting the systems online while they are running.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;To make matters worse, a lot of races only occur when data sizes areincreased to production system batches. Say you have a small writeconflict in the data store due to inappropriate transactionalserialization and isolation. If your test system has few users, thisconflict will never show up. And if it does, you will disregard it as aone-time fluke that will never happen again. Yet—on the productionsystem, as you increase capacity, this problem will start to occur. Thestatistical “Birthday Paradox” will come and rear its ugly head andyou will be hitting the conflict more and more often. Up until the pointwhere it occurs multiple times a day.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In conclusion, capturing these kinds of bugs up front is deceptivelyhard.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_the_erlangshell&#34;&gt;The Erlang Shell&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The Erlang shell is a necessary tool for producing correct software. Itsusefulness is mostly targeted at the maintenance phase, but it is alsouseful in the initial phases of development. A running Erlang system canbe connected to while it is running:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;literalblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre&gt;(qlglicko@127.0.0.1)3&amp;gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This provides a REPL so you can work with the software. But note thatthis is a REPL on the &lt;em&gt;running production system&lt;/em&gt;. If I run commands onthe system:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;literalblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre&gt;(qlglicko@127.0.0.1)3&amp;gt; qlg_db:players_to_refresh(1000). {ok,[]}(qlglicko@127.0.0.1)4&amp;gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I hook into running processes. In this case &lt;em&gt;qlg_db&lt;/em&gt; which doesconnection pooling towards the Postgres database. This allows me to goprobe the system while it is running to check for its correct operation.Any exported functionality can be probed from the shell.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I often keep a module around, named &lt;em&gt;z.erl&lt;/em&gt; which I can compile andinject into the running system:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;literalblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre&gt;(qlglicko@127.0.0.1)6&amp;gt; c(&amp;#34;../../z.erl&amp;#34;).{ok,z}(qlglicko@127.0.0.1)7&amp;gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This dynamically compiles and loads the &lt;em&gt;z&lt;/em&gt; module into the runningsystem. It makes the functions of the module available for systemintrospection and manipulation. When debugging hard-to-find bugs onsystems, you &lt;em&gt;need&lt;/em&gt; this functionality.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;And yes, if you want, Erlang nodes contains the &lt;em&gt;compiler&lt;/em&gt; applicationso they can compile modules.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In Erlang, linking is deliberately “as late as possible”. This meansyou can change software in the system while it is running. There is nolinker phase up front at compile time. Linkage is done when you callanother module. Yes, this costs performance. But on the other hand, itmeans you can always rely on the system calling the newest loadedversion of the module. The ability to hot-patch a system while it isrunning can help a lot. You don’t have to interrupt the system for smallfixes for instance. If you know that you only changed a single module inyour test build, you can opt to just push that compiled byte code toproduction and then inject it into that system. As long as yousystematically add the change to your standard deployment pipeline, thisworks.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The shell also provides a lot of nice tooling to help you when you arelooking for problems in a system:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;There is built-in job-control in the sense of the sh(1) shell. You canhave several shells open at the same time. You can reconnect to shells,either locally or remote. And you can kill shells which have hung forone reason or the other.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Erlang has built in trace capabilities. These provide DTrace-likebehaviour on the system directly without effort. Enabling tracing onlyimpacts the traced modules and it is generally non-intrusive (unless youmake a mistake when setting trace patterns, heh). You can mask events:only when this process calls. And only these two functions. And onlywhen the 3rd passed parameter is 37. The Erlang shell makes this allpossible dynamically on the running system.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Want to know what state a given process has? Fear not, you have onlineintrospection via the shell.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Want to know how many messages there is the inbox of a process? Fearnot…&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Want to insert a new log statement? Recompile the code and hot-deployit via the shell. Fear not…&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;And all this &lt;em&gt;without&lt;/em&gt; service interruption. And you get all this forfree, just because you picked Erlang as the implementation language.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Here is the thing: the first time you use the Erlang shell in productionto fix a hard-to-debug problem it becomes very very hard to live withoutit. I’d willingly give up static typing for the ability to look at therunning system. Problems that survive past the tests and into productiontend to be sinister and evil. And subtly elusive. You need a systemthere where you can go and inspect it, while the error is occuring inproduction.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;It is the same traits that made UNIX a success (and what makes Plan9alluring and appealing). Your system can be inspected and manipulatedwhile it is being developed and changed dynamically. Except that inErlang, we have much finer grained control over the running UNIX-processsince we can go inside it and inspect running processes inside the node.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>Glicko2 Benchmarking (1)</title>
       <link>https://jlouis.github.io/posts/glicko2-benchmarking-1/</link>
       <pubDate>Sat, 16 Nov 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/glicko2-benchmarking-1/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;One of my hobby projects is to run statistics on Quake Live Duelmatches. I began collecting data around 1st of Feb 2013 and now I havescraped around \(2.5\) Million duel matches. This allows me toplay with different ranking methods on the players and gauge theirranking.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The ranking system I use is called Glicko2, devised by Mark E. Glickman(&lt;a href=&#34;http://glicko.net/&#34;&gt;http://glicko.net&lt;/a&gt;). The system is like the chessrating system ELO, except that it is newer and avoids certain problemswith ELO.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When ELO was conceived, you had to be able to run the calculations byhand. Glicko2 can use a computer and thus carry out much hardercalculations. So it tend to deliver better results. Glicko2 tracks threevalues for each player. His rating R, starting at 1500. His ratingdeviance, RD, starting at 350 is a measure of how much we trust therating R. If the RD number is small, we have strong belief in the ratingof the player. If it is high, we don’t yet know a lot about that player.As the player plays more matches and we learn more about the player, weshrink RD towards 0. Finally a value, Sigma, measures how much a playeris fooling the rating system. This allows us to compensate for quicklyimproving players so they don’t get ``stuck&amp;#39;&amp;#39; on a certain rating.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When considering a new rating for a player, we consider a weeks worth ofduels for the player. We update his R, RD and Sigma values depending onthe values from the previous week and the opponents he played against.If the player has a high RD for instance, his rating is moved more perwin or loss since we know less about him yet. This means we quickly findthe skill level of a given player.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The system I have made is written in Erlang. This choice has been veryfruitful. First of all, I have a system which was easy to write andscales well, even though I don’t really need that. Second, the faulttolerance of Erlang has helped me a lot. The system has been very robustdue to the fault tolerance of Erlang. Usually I don’t care about thesystem. It takes care of the network being down or Quake Live beingupgraded by itself.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Storage is handled by Postgres. If you need a database that just works,then picking Postgres is rarely a problem. Furthermore, the completedata set is less than 6 gigabytes, so almost any kind of store wouldwork. But Postgres is a simple choice due to its reliability and featureset.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The Erlang system works well for the fetching of matches, and fordisplay of match scores and so on. But I need to carry out some tuningsof the Glicko2 parameters. This means I will run through my\(2.5\) million matches many many times and thus the speed atwhich I can run Glicko2 matter. I have an Erlang implementation for asimulated annealer and ranker. But since it is heavyweight numericalprocessing—not an Erlang strength—I need to find another language fordoing that.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;So there are three things I need to know:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;How fast can I run the Glicko2 ranking codes? That is, how quickly canI execute the main loop for a single simple ranking. This will be neededto understand how much I could hope to gain by going to another languagein the first place. If I can’t get enough speed, I can simply abort theprocess right here.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I have \(2.5\) million matches and need to process them all.Thus the problem is switching from being CPU-bound to being memorybound. I need to find out if this change affects the processing speed ofother languages. Again, if I can’t do it faster, then I need to abortthe task.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I need to run the \(2.5\) million ranking runs either in analgorithm running simulated annealing or a gradient search. This meanspotentially millions of runs times the \(2.5\) million rankingruns. This is the long-term goal I wish to reach. In this part I requirethe speed much more than in the other parts.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;A slightly smaller problem is that my current ranking runs requirememory proportional with the number of matches. When I had 400.000matches it was easy to fit in memory. But now, I am running up against abarrier of the machine doing the computations (it doesn’t have too muchmemory, it is an old machine).&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In the following I present some Timings. These are run on a Linux Laptopworkstation, where it is plugged into power and runs full processorspeed. The machine is a ``Intel® Core™ i7-3720QM CPU @ 2.60GHz&amp;#39;&amp;#39;which is an Ivy Bridge machine, 4 cores, two HTs per Core.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I intend to tune on this machine, so it is paramount the rankings arerunning fast on this machine.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Erlang Glicko2&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://github.com/jlouis/erl-glicko2&#34;&gt;erl-glicko2&lt;/a&gt; The Erlang systemitself can run a single Glicko2 round of one player against 3 players in22\(\mu{}\)s. The benchmark in Erlang is carried out byrunning the test 300 times and then averaging. This batch size seems tobe quite stable.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The speed figure of Erlang is with the standard BEAM bytecodeinterpreter. And the code is straightforward with no tuning whatsoever.With \(2.5\) million matches it takes just around a minute torun through them all, which is acceptable. But since I am to run fasterthan that, I wanted to know how much faster I could go.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Compiling with HiPE gives 8\(\mu{}\)s. This is much better andfar more in the area where I would like to be. But perhaps we can dobetter by switching the language.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Ocaml Glicko2&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://github.com/jlouis/o-glicko2&#34;&gt;o-glicko2&lt;/a&gt; One of my favoritelanguages when I need fast processing is OCaml. The language has a largenumber of beneficial properties—static typing, a native code generatorproducing fast executables, a good module system and a nice eco-system.So naturally, transcribing the code from Erlang to OCaml has to betried.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The code is quite straightforward to change from Erlang into OCaml.There are few places in the code base where we use anything but &lt;em&gt;float&lt;/em&gt;types, so it is easy. The only slight problem was a missing parenthesisgroup which made a subcomputation produce the wrong result. Luckily, Ihave extensive tests so it was caught quickly.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Note that the particular error is one of those which will not be caughtbe a type system. In numerical code, everything is of type &lt;em&gt;float&lt;/em&gt;anyway, so there is no way I can hope to catch this kind of errorstraight away. Type systems help a lot with symbolic processing, butthis task is not one which has that property.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The OCaml code is written in idiomatic style. Functional, closures, andso on. I could opt for a more imperative style—which Ocaml allows—butfor what purpose?&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I use the &lt;strong&gt;Core_Bench&lt;/strong&gt; module from Janes St. to do my benchmarking. Thenice thing is that this tool predicts the batch size to use and also hasprediction that avoids making the wrong conclusions. The OCaml bytecodeinterpreter clocks in at 28\(\mu{}\)s. This result somewhatsurprises me. I had expected the run to be faster than Erlang. But Iguess more time is spent optimizing the Erlang interpreter than theOCaml bytecode interpreter and code generator.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Running native yields a time around 2\(\mu{}\)s. This numberis really good. If we are to process \(2.5\) million matches,we can do so in \(2.5 \times 2\)\(\mu{}\)s (assumingno cache hierarchy) or \(5\) seconds. Much better than theminute it would require in Erlang.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Yet, the problem here is that the OCaml core is not parallel. I wouldneed to cut up the data set into pieces and then run an OCaml processper core. There is no need to do that in Erlang. So even though theresults will clock in faster, the problem is that I will need more workto fetch data in parallel later on. So parallelism might become aproblem going forward.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Go — Glocko2&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://github.com/jlouis/glocko2&#34;&gt;Glocko2&lt;/a&gt; Naturally, I had to try Golangnext. This language is interesting because it has nice semantics, fixingmost of the things I hate about C. It compiles to native code with astandard slightly optimizing compiler. And it supports multiple cores inits runtime, which is needed if I want to get parallelism inside asingle process later on.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Writing the code in Golang is a chore. Productivity is definitely slowerthan in Ocaml since you have to type more and waste precious timereframing the nice functional problem into imperative code. Even thoughthis was the last thing I implemented, it still took about twice as longas the OCaml implementation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;&lt;em&gt;Do note: My imperative skillset is there, but I don’t write muchimperative code nowadays. This could be a factor in the slower writingspeed. However, writing last should be a help, rather than ahinderance.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;What is so nice about Golang is the tooling. I set up &lt;em&gt;go test&lt;/em&gt; early onin my editor, so when I saved a file it would automatically compile andrun tests. See &lt;a href=&#34;http://github.com/eaburns/Watch&#34; class=&#34;bare&#34;&gt;http://github.com/eaburns/Watch&lt;/a&gt; for the tool I use inAcme to do this. This meant I could start by writing down all the testcases and then go work on the implementation afterwards. As more andmore of the code base began to work, I had fewer and fewer failing testcases.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Benchmarking can be done with the Go Testing tools as well. It alsocomputes a batch size and gives you predictive results, like in Ocaml.But in this case, it is built into the default tooling. I cannot&lt;em&gt;stress&lt;/em&gt; how important it is for a language to have nice access toprofiler tooling and so on inside the default language distribution. Thefact that the build tool does testing and benchmarking as well bydefault is just awesome.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Being Go, the compile times are faster—but this doesn’t matter for thisproblem as the compile times are ``not noticable&amp;#39;&amp;#39;. Go clocks in at1\(\mu{}\)s. About twice as fast as the OCaml solution. Thisis with the default compiler written by Ken Thompson initially andimproved by many other people.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Recap&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;So we have:&lt;/p&gt;&lt;/div&gt;&lt;table class=&#34;tableblock frame-all grid-all stretch&#34;&gt;&lt;caption class=&#34;title&#34;&gt;Table 1. Breakdown of the different implementations running speed&lt;/caption&gt;&lt;colgroup&gt;&lt;col style=&#34;width: 50%;&#34;/&gt;&lt;col style=&#34;width: 50%;&#34;/&gt;&lt;/colgroup&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class=&#34;tableblock halign-left valign-top&#34;&gt;Language&lt;/th&gt;&lt;th class=&#34;tableblock halign-left valign-top&#34;&gt;Efficiency (\(\mu{}\)s)&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Ocaml bytecode&lt;/p&gt;&lt;/td&gt;&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;28&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Erlang bytecode&lt;/p&gt;&lt;/td&gt;&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;22&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Erlang HiPE&lt;/p&gt;&lt;/td&gt;&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;8&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Ocaml native&lt;/p&gt;&lt;/td&gt;&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;2&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Go&lt;/p&gt;&lt;/td&gt;&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;There is no solution which totally aborts at this point. I already havean Erlang implementation, and the numbers may change around when we addthe next layer—processing 2.5 million matches. Before I add that andhave the option to do profiling, I’d rather not try to hand-optimizethese results too much right now.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Tuning Tricks&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When you revisit the same algorithm in multiple languages, you seepossibilities for optimizations all over the place. There are somesubcomputations, the &lt;em&gt;g&lt;/em&gt; and &lt;em&gt;e&lt;/em&gt; functions, which I don’t know if it isworth to compute once and then stash away in memory. I could probablylower write memory pressure and GC by recomputing them when I need them.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Also, all of Glicko2 runs on a scaling factor of &lt;em&gt;173.7178.&lt;/em&gt; This meansthat before doing anything with the given R and RD values, you scalethem down by this factor. All computation are carried out on thedownscaled numbers. The final step is to upscale everything again. Atrick which I am seriously considering is to scale down everythingbefore starting my runs. This avoids a down scale and an upscale in eachloop and this would help a &lt;em&gt;lot&lt;/em&gt; for the larger computations where manyruns are needed.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;One of the major Glicko2 steps is to find a root of a function. I amcurrently using a root-finder, called Ridder’s method. This finder isquite fast, but it is also the major slowdown in the runs. When I firstimplemented the OCaml variant, I picked a different root-finder bymistake. This meant that it ran in 0.6\(\mu{}\)s, sodefinitely this part of the code base is the contending one. It alsosuggests that the Golang implementation is handling this partdifferently than the OCaml code and there is definitely room forimprovement in the OCaml code.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Parting words&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;In the next phase, the code to read, parse and compute on 2.5 millionlines of code has to be written. I have no time frame for doing so, as Iam mostly doing this ``for fun and entertainment&amp;#39;&amp;#39;. I am pretty sure youcan optimize the code bases like mad, but there is little reason to doso before the other parts have been implemented. The problem willquickly be memory bound, so the interesting things in speeding it upwill be in-memory representation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;My initial ideas is to store data in a vector-like format. In Erlang Iuse an ETS-table, but this incurs a hash-table lookup a large number oftimes. My profiling shows I spend 50% time in &lt;em&gt;ets:lookup_element/3&lt;/em&gt; inErlang. So to go faster, I need to pack these data better in memory. Itmight very well be that the numerical code is not the hottest path inthis program at all. So I hesitate to optimize it.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;This is also the reason why I considered BER MetaOCaml, but lostinterest in using it again before I know that I can get decent speed onthe other parts. There are ways to make this parallel even thought theOCaml runtime is not. Perhaps I can work around that, but I will notethe extra cost in time to do so.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I also considered Haskell. Given Repa or Accelerate, you can probablespeed up the computation and move it to the GPU. It is an interestingproject, but it requires a completely different approach to the problemat hand. One could also use the Erlang OpenCL bindings to achievesomething like this.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Finally, if you were a company, &lt;strong&gt;none&lt;/strong&gt; of this would have been needed. Ialready had the Erlang code for tuning. I would just have had to leasethe next machine size in Amazon Web Services for 24 hours. I don’t needto run tuning that often. Once a year or so is perfect. And I can runweekly updates in a minute. If I cut the dataset into 10 pieces, andload it from Postgres a little bit at a time, then I could definitely dothis inside a 3 minute window. This is hardly a problem. It is not worthdoing this from a Cost/Benefit perspective. And frankly, writing thecode in Erlang is probably faster than writing it in OCaml or Go for me.&lt;/p&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>On Logbooks</title>
       <link>https://jlouis.github.io/posts/on-logbooks/</link>
       <pubDate>Mon, 11 Nov 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/on-logbooks/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;My friend, Michael T. Richter, presented me with a nice concept fromengineering. The &lt;em&gt;logbook&lt;/em&gt;. The concept is extremely simple: you keep alog of your work, so you can refer back to it later. Yet, there arerelatively few in Computer Science who does that, which is a sad stateof affairs.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The odd thing is that most computer scientists do know the importance oflogging in an application. You see these elaborate logging frameworksthat can log at different log levels, can forward logs between machinesand so on. Yet—it looks like the CS people forgot that the same loggingcould apply to your own work.&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;My Log comprises two files. One for work and one for personal projects.In each file, I keep track of dates. The file is pure text, though I useutf-8 encoding, so I have access to full Unicode, which I exploit fully.I have the following in the file in the acme(1) editor:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;literalblock&#34;&gt;&lt;div class=&#34;content&#34;&gt;&lt;pre&gt;&amp;lt;date +%Y-%m-%d&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;which can be run to enter the current date at the cursor position. Itend to jot down the projects that are &lt;em&gt;in progress&lt;/em&gt;. My log is not aTODO list! I’d rather track stuff I have done than stuff I don’t havetime to do. Having a log gives me some immediate benefits:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;I can run &lt;em&gt;grep&lt;/em&gt; on old entries. This is tremendously efficient. Ioften write down shell-oneliners, R scripts, hostnames too volatilefor &lt;em&gt;.ssh/config&lt;/em&gt;, results from benchmarks, test failures, meetingoutcomes and so on. I can find old stuff as long as I remember that Iwrote it down at some point in time. I also keep links to papers, IssuesI am working on, source files and so on. My editor of choice, acme(1),allows one to write &lt;em&gt;file:/REGEX&lt;/em&gt; to open a file and then perform asearch within that file based on the regular expression I give. Ineffect, I have full history tracking.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I can answer the question ``What did you do two weeks ago?&amp;#39;&amp;#39; withease. It also means I can gather knowledge about what kind of work I amcurrently doing and for what purpose.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The log acts as a tool for improving the process. By keeping track ofwhat is being done, I can look back and see what can be done better.This allows me to run an iterative quality improvement process on mydevelopment.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The log allows me to use the “Hemmingway trick”, which is leaving asentence before it is done and finished. It is then easier to go backand pick up from where you left. By tracking what is currently inprogress, I have an easier time entering flow again on the piece of codeI am working on. Switching ``context&amp;#39;&amp;#39; is also way easier. Since I canwrite down where I am currently on one part and then switch to anotherpart.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Since the log tracks stuff in progress, I can quickly figure out if Iam starting too many new projects and not finishing any of them.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The log allows me to clear my brain once in a while since it has beendocumented elsewhere.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It is way easier to have &lt;em&gt;focus&lt;/em&gt; with a log of what is being done,vastly improving efficiency and output.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Personally, I think the most important part is that this has vastlyimproved my process. Especially when hunting for bugs. I tend to writedown what I know and what hypothesis I have. Then I try to devise someexperiment that can cut through the hypothesis and cleave up thepossibilities. Bug finding becomes much faster when you approach it likethis.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Another part of the process which also has improved is the approach towriting new code:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;I try to document the purpose of the new piece of code. That way, Imake sure I know why it is important to implement this part—and Idocument that for future reference.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I often write down how hard I think the code is to complete. Thisgives me a benefit later when I can go back and see if I was right orwrong with the estimate.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;If we had multiple solutions, that is documented.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;If a test comes up with a surprising result, that is documented.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;As a consequence, you do less work and better quality. The concept ofthe &lt;em&gt;logbook&lt;/em&gt; is hereby passed on to the reader.&lt;/p&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>Eventi</title>
       <link>https://jlouis.github.io/posts/eventi/</link>
       <pubDate>Wed, 30 Oct 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/eventi/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;So, listening a bit to “The Civil Wars” this afternoon cooked up therest of eVenti. This blog post is brought to you by Maurice Ravel, andMorcheeba however.&lt;sup class=&#34;footnote&#34;&gt;[&lt;a id=&#34;_footnoteref_1&#34; class=&#34;footnote&#34; href=&#34;#_footnotedef_1&#34; title=&#34;View footnote.&#34;&gt;1&lt;/a&gt;]&lt;/sup&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The eVenti system is a simple Erlang-implementation of the venti(8)system famous from Plan9. The idea is very simple: We can store data inVenti and the data becomes addressed by its SHA1 checksum.footenote:[Ishould probably change this later, but for compatibility reasons westick to it…] This is called a Content Adressable Storage (CAS) becauseContent is—you guessed it—addressed by the checksum of the content.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;div class=&#34;title&#34;&gt;Immediate effects are:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Storing the same data twice has no effect, deduplication is automatic.You can’t accidentally destroy data in a Venti-store, because writes areidempotent and happens at most once.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Data storage is forever. And it is excellent for archival storage andbackups.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Security is peculiar. I can give almost everyone in the world readaccess—and yet they will be unable to guess a key (called a &lt;em&gt;score&lt;/em&gt; inventi-speak). This makes it possible to use the store as a dead-drop formessages and have others retrieve them at a later stage. Write access ismore problematic. While nobody can destroy my data in venti, I can’tprotect against an enemy adversary filling up my store with junk. Yet,the properties of implicit integrity is quite nice to have.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The Erlang implementation is very simple. First, we employ the &lt;em&gt;ranch&lt;/em&gt;acceptor pool to handle many simultaneous TCP connections. The protocolit binary, but we can use Erlangs ability to match on binary patterns tohandle that easily. To handle the backend storage, we employ &lt;em&gt;eleveldb&lt;/em&gt;which is LevelDB bindings to Erlang.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Whenever a client connects, we spawn a process and loop over standardrequest/reply patterns for that client. A single &lt;code&gt;gen_server&lt;/code&gt; instannceruns the calls to and from the database. All code we wrote, includingsource, empty lines and comments are 435 lines of code. Erlang tends tobe wonderfully succinct.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;An interesting notion is that all commands in the protocol have &lt;em&gt;tags&lt;/em&gt;which identifies the message. A tag in a request is reflected in theresponse. It is the same as correlation id’s in the AMQP protocol forinstance. And it allows for aggressive pipelining of requests. If onlymore protocols had this nice construction built in.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;What I &lt;em&gt;love&lt;/em&gt; about the model is that venti(8) is a very simple storageendpoint—yet it plugs so well into other subsystems. There is aunix-feeling to Plan9 tools, except they are one-level-up in thedistribution chain. The key insight is that with venti, you have aself-contained system you can use to build other systems on top of. Andby picking a system that already exists, you leverage the advantage thatthere are already tooling out there which can read and write from thestore.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;There are some obvious extensions to eVenti. First, we can triviallyexchange leveldb for riak. This will provide proper secure backup ofdata by running a cluster of machines and by copying data out tomultiple machines. Note that the fact that Riak is a AP store is noproblem to us: We store immutable data with idempotent writes. Conflictresolution is simply “pick one at random since they are equivalent byconstruction”.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;My intention is to use eVenti as a building block. I have a weakness forMerkle-tree constructions and immutability in general. Plugs to systemslike Datomic, Dropbox, and Bitcoin. Note that you can run an event-logas a Merkle tree, in the same sense as a Bitcoin block-chain.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Suppose I and a friend run eVenti servers. If I have write access to hisserver, I can make encrypted backups at his place, not entirely unlikeColin Percivals tarsnap project. Co-incidentally, it will also provide anice foundation for a secure encrypted chat service with long-termstorage. It will be so simple to link attachments into the chat. OrChess games. If I know the SHA1 of our game, I can extend it with a moveand send the new SHA1 to you. Nobody else knows our game. But if I sendyou a SHA1 of another game, you can walk the chain and get at all moves.Over time the DAG in venti will form a nice opening book as well.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;A system like venti is a necessary tool nowadays. The pendulum has swungtotally to the point where every service we use is centralized. Tenyears ago, we were running lots of P2P systems: Bittorrent for instance.It is time we—the internet—push the pendulum in the other direction.This means we need to be the arbiters of our own data again. Not pushthe data to some irritating insane third party company who will like tosell the data for money&lt;sup class=&#34;footnote&#34;&gt;[&lt;a id=&#34;_footnoteref_2&#34; class=&#34;footnote&#34; href=&#34;#_footnotedef_2&#34; title=&#34;View footnote.&#34;&gt;2&lt;/a&gt;]&lt;/sup&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;No company will build the decentralized structure, unless they have abusiness plan for it. And it seems very few companies in this space haveany other business plan than to sell your data back to you for money.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Next, I want to see how I can leverage the Plan9 9p protocol and FUSE toturn data into a filesystem I can mount. Imagine having a chatconversation where you can cd into a directory in the filesystem andautomatically have access to all the attachments of that chat.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;But I do think I need more than 435 lines to do that. Perhaps 1000.Embrace Erlang :)&lt;/p&gt;&lt;/div&gt;&lt;div id=&#34;footnotes&#34;&gt;&lt;hr/&gt;&lt;div class=&#34;footnote&#34; id=&#34;_footnotedef_1&#34;&gt;&lt;a href=&#34;#_footnoteref_1&#34;&gt;1&lt;/a&gt;. I have a weakness for Gaspard de la nuit :)&lt;/div&gt;&lt;div class=&#34;footnote&#34; id=&#34;_footnotedef_2&#34;&gt;&lt;a href=&#34;#_footnoteref_2&#34;&gt;2&lt;/a&gt;. Hello every company in existence.&lt;/div&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>Glicko 2 Benchmarking</title>
       <link>https://jlouis.github.io/posts/glicko2-benchmarking-2/</link>
       <pubDate>Wed, 30 Oct 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/glicko2-benchmarking-2/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Glicko2 is a ranking system for duel games. I use it to rank Quake Liveduels. The idea is to find a value, the &lt;em&gt;strength&lt;/em&gt; of a player, called Rin the system. The higher the R value, the better the player.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;How does Glicko2 estimate R? It looks at historical data and usesbayesian methods to estimate the current strength of a player. Like allother systems, there are parameters we can tune for a set of players anda set of duels:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;What initial R value should we pick for new players? We could pick1500 as the base, but it may be that there are better initial valuesthan this.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;What initial RD value should we pick for new players? The RD valuemeasures a &lt;em&gt;belief&lt;/em&gt; in a given R-value. A large RD means we haverelatively little information and hence can’t trust the R value as muchfor rathing purposes.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;What about the initial Sigma-value? The Sigma-value is used to adjustratings for players which are consistently fooling the rating system. Itaccounts for the situation where a player has been ``locked&amp;#39;&amp;#39; to a givenrating and then suddenly improves. In other rating systems, it wouldtake a long time to move that players R value to the correct position.But Glicko2 will detect this and adjust the Sigma for the player,allowing for greater R-strides.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;What about the value of Tau? Tau is a global value which controls howmuch power Sigma has. Games with high random variability needs a low Tauaround 0.2 to account for randomness in games. Games with lowervariability can run with higher Tau-values. Perhaps as high as 1.2 atmaximum. In game types with high Tau-scores, there is very little randombehaviour. Hence a win or a loss is more decisive and Sigma shouldadjust with a greater factor.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The 4 different values spans a 4-dimensional space. We can try to tunethe values for the game type we are looking at. By doing so, we can hopeto find good values which optimize the ranking system to the game type.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_nelder_mead_numerical_optimization&#34;&gt;Nelder-Mead numerical optimization&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;There are many optimization algorithms. The original algorithm when Ioperated in pure Erlang was quite computationally intensive. I used theconcept of &lt;em&gt;Simulated Annealing&lt;/em&gt; as an optimization heuristic. Thisalgorithm works well, but requires many computations in order to findgood values.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I had experiments of Glicko2 computations in Erlang, Go &amp;amp; OCaml. Giventhat the fastest Erlang code runs a round in 8us, OCaml in 2us and Go in1us, I decided to focus on Go for the next round of work.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I want a more intelligent search for an optimum. One algorithm isNelder-Mead from 1965. This algorithm has some trouble in certainsituations. And it may converge to a wrong point. But it often workswell in practice. So I set out to implement the algorithm for Go. Theefforts are here, including tests and benchmarks:&lt;a href=&#34;http://github.com/jlouis/nmoptim&#34; class=&#34;bare&#34;&gt;http://github.com/jlouis/nmoptim&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;NM is nice for our ranking work since it does not need numericalderivatives of the function being computed. Rather, you start with a&lt;em&gt;simplex&lt;/em&gt; which you then iteratively move around. You can imagine afishing net spanning the whole sea. NM proceeds by moving the fishingnet according to some rules in order to find the fish you are searchingfor. In this case the minimum of the function at hand.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Nelder-Mead by itself is not easy to make parallel. But the rankingfunction is trivially parallelizable. So I opted to do operations inparallel and then speed up the ranking code. By using sync.WaitGroup inGo, I immediately got to around 500% CPU usage on an 8 core machine. Sonow I am blocked on speedup. Getting 5/8 of the cores to do meaningfulwork and a factor of around 5 in speedup is nice. My ranking runs areabout 5 times faster in wall-clock as well. And that is disregardingother possible optimizations.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Furthermore, we find a good value in 22 iterations of Nelder-Mead with45 function evaluations. I guess it was not that important to speed upthe computations after all since Erlang would have been able to runthis, albeit in hours rather than minutes. Go completes the run in inabout 3 minutes on my current Ivy Bridge Core-i7 laptop, which is a finespeed for 2.5 million quake matches. It also ranks in around 925ns permatch which is around the numbers I got in my Glicko2 benchmarks for asingle test match.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;sect1&#34;&gt;&lt;h2 id=&#34;_the_nextsteps&#34;&gt;The next steps&lt;/h2&gt;&lt;div class=&#34;sectionbody&#34;&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I can now optimize in Go, but there are still more work to be donebefore it is on par with the Erlang code:&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;ulist&#34;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;We need to be able to rank pairs of \{Player, Map}. This is rathereasy.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The prediction code only runs on the last round out of 99. It shouldpreferably run prediction on the last 4-5 rounds instead so thepredictions even out over a larger area. This will account for a singleround of matches becoming too crazy.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ranking expected scores need some clamping which I am not doingcurrently, but that should be easy to add as well.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>Why I use erlang.mk</title>
       <link>https://jlouis.github.io/posts/why-erlang-mk/</link>
       <pubDate>Mon, 28 Oct 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/why-erlang-mk/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Here is our typical Erlang project. And note we are on a pretty slow MacOSX filesystem and a 5400 RPM disk. Not the fastest in the world. If Irun a rebar-compile from cold, we get the following a timing of 26seconds. Doing the same with erlang.mk is 24 seconds. Note thaterlang.mk only uses one thread, whereas rebar is parallelizing the buildand is using all 4 cores in the machine. But erlang.mk only spawns theerlc compiler once per directory, and only if it needs to—no changemeans no spawn.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;But if we have already compiled the code, the numbers are muchdifferent. When compiling from warm, it takes rebar 9 seconds to figureout that there is nothing to do in the project. erlang.mk does the samething in 0.2 seconds.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;When developing, I don’t want to wait on the compile to finish all thetime. I want it to be proportional to the amount of change in myrepository, not on the complexity of the software project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The other reason is that make(1) is the right tool for the job. Most ofthese other tools are reinventions of the thing make(1) does. And it isvery hard to even contend with a tool that has survived so many yearsand is so archaic.&lt;/p&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>An Evil Postgres Bug</title>
       <link>https://jlouis.github.io/posts/evil-postgres-bug/</link>
       <pubDate>Mon, 07 Oct 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/evil-postgres-bug/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;So, I have this QLGlicko project. It consists of a web scraper whichtakes in duel matches played in the game of Quake Live—and stores themin a Postgres database. These duels are then analyzed and I run theGlicko 2 (see &lt;a href=&#34;http://glicko.net/&#34; class=&#34;bare&#34;&gt;http://glicko.net/&lt;/a&gt;) ranking system on them to tell peoplewho are currently the best player on a given map.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The system works well, but I was tired of maintaining it on a Linuxmachine for several reasons. One, Linux is hard to maintain and thingschange underneath faster than I like. Two, I have much more experiencemaintaining FreeBSD machines. Three, I can get proper built-in ZFSsupport on FreeBSD. Hence I decided to move the database onto FreeBSD.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Most of the migration went well. I dumped the database, installedFreeBSD, installed Postgres 9.3 (to avoid having to toy with SysV sharedmemory). Tuned the database. And tried to import. First problem is thatLinux used the fake locale called “en_dk.utf-8”—so I had to fake itand install that. Next problem was that I used the “uuid-ossp”EXTENSION in Linux. This one has several problems on FreeBSD, mostlyrelated to PIC code and the fact that it will crash the database.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;So I changed the code to &lt;em&gt;inject&lt;/em&gt; the UUID data rather than producing iton the database side. And then I suddenly had duplicate key constraintproblems on an UNIQUE INDEX. Running SELECT queries showed no suchtrouble with the index and there were no entries with more than a singleentry. This is to be expected due to the index being UNIQUE. But theinsertion or update code would soundly fail. I was wondering what wentwrong and began digging.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Here is what happened: the “uuid-ossp” code had managed to insert arow into the database before it crashed. So this went under the radar ofthe index and now we had trouble! There is an extra entry in thedatabase—violating the index—but it does not detect that.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Worse, when we query, the data can be served from the index alone, sincemost data in the table are frozen. This means we begin getting reallyevil and odd violations.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;Running a DROP on the index and then trying to recreate the index againmakes the error show up. And now I understood what went wrong.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;The solution was pretty simple: Restore the database from a backup.Remove any trace of “uuid-ossp” and then start the database again. Nowthe index works as expected and the database doesn’t crash.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;TL;DR—Beware of extensions that doesn’t work on your platform of choice!&lt;/p&gt;&lt;/div&gt;</description>
     </item>
   
     <item>
       <title>An Initial Post</title>
       <link>https://jlouis.github.io/posts/an-initial-post/</link>
       <pubDate>Wed, 02 Oct 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/an-initial-post/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;I tend to stir up things over on blogger, mostly writing the blog&lt;a href=&#34;http://jlouisramblings.blogspot.com/&#34; class=&#34;bare&#34;&gt;http://jlouisramblings.blogspot.com/&lt;/a&gt; —but I am considering writing andusing Medium instead to provide stuff, since the platform just seemsnicer. My Ramblings are mostly-technical and they tend to contain a lotof code in them, but the way I tend to add new blog posts is somewhatindirect. I write the post itself in my trusty Acme editor—asmarkdown—and then I convert that into HTML which I then push in on topof Blogger. I almost never use the editor in Blogger because I hate it.So writing on Medium is an attempt. An attempt to see if the platformwould be a nicer way to write posts and if I would prefer it to writingin the Editor.&lt;/p&gt;&lt;/div&gt;&lt;div class=&#34;paragraph&#34;&gt;&lt;p&gt;&lt;em&gt;Aside from 2018:&lt;/em&gt; In 2013, Medium was a quite nice platform. But overthe years, they destroyed the platform totally, making it a platformwhere you have to pay in order to read posts and entries. It was freeoriginally.&lt;/p&gt;&lt;/div&gt;</description>
     </item>
   
 </channel>
</rss>
