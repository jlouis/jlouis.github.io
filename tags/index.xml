
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
 <channel>
   <title>Tags on jlouis&#39; Ramblings</title>
   <link>https://jlouis.github.io/tags/</link>
   <description>Recent content in Tags on jlouis&#39; Ramblings</description>
   <generator>Hugo -- gohugo.io</generator>
   
       <atom:link href="https://jlouis.github.io/tags/index.xml" rel="self" type="application/rss+xml" />
   
   
     <item>
       <title>On Observability</title>
       <link>https://jlouis.github.io/posts/observability/</link>
       <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/observability/</guid>
       <description>&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The hard part is not debugging the code. The hard part is figuring out where the bug is. This is what observability is.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;attribution&#34;&gt;
&amp;#8212; Charity Majors
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I really like the notion of &amp;#8220;observability&amp;#8221;, which stems from Control Theory. The idea is that we have some system, with inputs, some internal state and some outputs. A system is observable if we can determine its internal state, solely from a finite set of outputs (in finite time).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The contrast, a non-observable system, has some internal state we cannot infer just by looking at the outputs over some time frame.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Credit should be given to Charity Majors for transplanting this idea into tech (thank you!), and also creating a whole company around the idea (see &lt;a href=&#34;http://honeycomb.io&#34; class=&#34;bare&#34;&gt;http://honeycomb.io&lt;/a&gt; if you are interested).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When we look at program output, we need to take a (w)holistic approach. There are the immediate replies to user requests; but there are also log lines, trace probes, metrics and so on. Everything can be considered an output, even if it is a side-effect of the primary computation. And that set is what we look at when we try to determine what is happening inside a running system.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Most computer systems are strictly non-observable. We don&amp;#8217;t log the relevant information, we don&amp;#8217;t have the relevant metrics, and we don&amp;#8217;t have the ability to trace arbitrarily in most systems. As a result, we have no chance when a system misbehaves. In many cases we won&amp;#8217;t even know that the system misbehaved in some way.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Logs, Metrics and Tracing are &lt;em&gt;necessary&lt;/em&gt; but certainly not &lt;em&gt;sufficient&lt;/em&gt; properties needed to achieve observability in a system. People will do all kinds of aggregations, filters, reductions and so on to their data in order to cut down on it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Logs tend to have all kinds of problems associated with them. The good old syslog system has the problem it treats each line as a separate event. It also has no structure in the log lines. Asking questions in these are hell. A little better is if the log lines has structure, where the structure is flat. But the best situation is if you just log an Erlang term, and S-expression or the like, so you have all relevant information in the log line.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Metrics tend to aggregate. You know you had an error, but you don&amp;#8217;t know any context. You also tend to have a temporal problem, in which you take 30 seconds of errors and store in one value. This makes spikes impossible to detect.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When people say tracing, they often mean &amp;#8220;We added this static set of probe points to our code base, and we want to output all of those when we increase the log level.&amp;#8221; People don&amp;#8217;t enable this because it kills their production servers with on-disk log writes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;How we transplant the notion from control theory is a bit vague:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We could treat the notion as a continous axis where systems can converge toward being (fully) observable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We could treat the notion as a discrete property. Either you have a system which is, or you have a system which isn&amp;#8217;t.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We could accept a discrete notion, but with partiality. In some cases our system is observable, but not in others. Then define a fully observable system as one which is observable in all cases.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Personally, I lean toward the latter of these. Suppose you have a fault in your software. If the fault can be found and fixed by looking at your systems output only, then the system was observable in this case. If, on the other hand, you need to reproduce the error in a development environment, attach a debugger, step through the program and scratch your head for several hours, the system was not observable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I stress this is on a case-by-case basis. A system is 80% fault-observable if 80% of all faults are observable according to the above notion.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_crash_logs&#34;&gt;Crash Logs&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In Erlang systems, faults generate crashes. A crash log contains:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The current stack trace of the failing process&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The last event the process received&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The state of the process &lt;em&gt;before&lt;/em&gt; processing said event&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;My experience is that often, this is enough to provide observability in a fault scenario. You can work from the state and figure out how the event might have lead to the stack trace. In particular you can often figure out what code path was taken and how that would lead to the faulty situation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Most other systems has a state space which are several gigabytes in size. So small dumps like these are &lt;em&gt;impossible&lt;/em&gt; since we cannot find the relevant piece of information. In contrast, process isolation in Erlang can often limit us to the core state for the fault.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What you &lt;em&gt;can&lt;/em&gt; and should do, however, is to take all coredumps and move these into persistent storage. If your core dump dies with your container, you have no post-mortem debugging and you will not be wiser. In some situations, if you can detect the fault, you can force the core-dump so you have a state you can inspect.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_assertions&#34;&gt;Assertions&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If you assert your invariants in your code, then Erlang systems will crash if an invariant is broken, which leads to crash logs for the faulty process. Erlang systems often assert processing as they are executing. This vastly increases cases where the system is observable. As an example, suppose you open a file on disk. You assert that you successfully open the file. If any error occurs, this produces output which allows you to observe the fault.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The key insight is that you don&amp;#8217;t know which kind of fault is occurring. It could be that the file is not existent. Or you don&amp;#8217;t have access to the file. So by asserting on any non-successful return, you get to learn important information necessary for internal-state-reconstruction. This information is added to the context of the crash log. In erlang systems you often see &lt;code&gt;{ok, _} = file:open(FName)&lt;/code&gt; which asserts the intended operation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_dynamic_tracing&#34;&gt;Dynamic Tracing&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Tools such as dTrace, eBPF, and the built-in Erlang tracer are tools which can make a system observable. If a fault is detected, you can trace the fault in detail and capture enough information about the fault such that it becomes observable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Note that the system doesn&amp;#8217;t start out as being observable. You often encounter the fault, and scratch your head. Then you add tracing which is specific to a user-id, or a type of request. This trace is what changes the system, dynamically, from a non-observable system to one that is. Once the fault has been dealt with, you can go back and disable tracing.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Tracing is dynamic though. You cannot just add some extra lines to the code and then redeploy to capture the problem. You need to be able to change the system while it is in operation, and without having an impact on the system. The reason this is important is because the system might reset itself under a redeploy. Suppose you have a data structure which some times ends up in a pathological state making your system slow. If you redeploy, you reset this data structure, so now you cannot figure out why it is slow. This is why you need to be able to query the system dynamically.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Also, the impact of adding tracing must be proportional to the haystack/needle problem you have. If you add tracing for a specific customer, we cannot have this affecting any other customer in the system. It might take weeks before we hit the fault again, so we need to have this enabled for a while. If tracing impacts the system efficiency, people won&amp;#8217;t enable it in production. And all really interesting errors occur in production.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_cardinality&#34;&gt;Cardinality&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Consider the following:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I know a web request happened&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I know a web request happened, and I know if it was &lt;code&gt;2xx&lt;/code&gt;, &lt;code&gt;4xx&lt;/code&gt;, &lt;code&gt;5xx&lt;/code&gt; or something else&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I know a web request happened, and I know the exact status code&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The last case of these can be used to derive the other two. But not vice versa. The last case also needs to store more information, because it needs to discriminate the exact status code. Now consider:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I know the user id of the web request&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If we have a million users, the space of possible values has a cardinality of a million. Storing this efficiently is non-trivial in most current systems. However, it is paramount to get a scenario where we can observe the system.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>Experience Report: Bidirectional type checking of GraphQL</title>
       <link>https://jlouis.github.io/posts/graphql-bidir-type-check/</link>
       <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/graphql-bidir-type-check/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The core idea of GraphQL is this: let clients have a small, typed,
total, functional (declarative) language where they can push programs to
the server side. The server then interprets these programs and
provides data to the client. The natural core for this is a lambda
calculus: a GraphQL &lt;em&gt;fragment&lt;/em&gt; is a lambda over the free variables of
that fragment, for instance. A &lt;em&gt;query&lt;/em&gt; is also a lambda, but no
variables are free, and it is &amp;#8220;exported&amp;#8221; for others to use. The only
reason it &lt;em&gt;isn&amp;#8217;t&lt;/em&gt; a full functional core is because the current
language is more familiar to typical client programmers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sidebarblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Aside:&lt;/em&gt; GraphQL is the ultimate function-as-a-service implementation.
In typical &lt;em&gt;serverless&lt;/em&gt; implementations of the FaaS scheme a client
can execute a singular function on the server side at a time, without
caring about the underlying server infrastrucutre and its maintenance.
GraphQL amends this by having the client push a program to the server
side, so part of the client runs server-side, using the predetermined
functions in the GraphQL Schema. How the functions are implemented,
executed and maintained is ignored by the client. It only knows of the
GraphQL endpoint as a factor.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This empowers clients and makes software be driven by client code. It
also improves latency since the program is executed server-side with
&lt;em&gt;locality&lt;/em&gt;. And it empowers clients with flexibility insofar the
server can evolve and adapt without clients having to change. &lt;em&gt;End of Aside&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Because we are working with a language, the best way to approach the
problem is to treat it as such. Processing GraphQL requests runs the
normal gauntlet of a interpreter:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Scan incoming byte stream into tokens&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parse tokens into an abstract syntax tree&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Elaborate the tree and type check it as well&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Execute: use an interpreter to execute the request&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;It is important to stress interpretation is often enough. In a typical
implementation, the work done in the execution phase is not where time
is spent. Usually, we measure the time in μs for the interpretation
step, whereas reading data is usually more costly in the ms-range. If
you have any distributed access in the query, that is going to be
where time is spent. The only counter-example is when you have all
data in memory on the Erlang node, readily available. In principle,
you could pre-compile an execution to Erlang code, and then directly
execute said code if this proved to be too slow. But we aren&amp;#8217;t there
yet in the current implementation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The Erlang implementation currently uses interpretation directly on
the AST and doesn&amp;#8217;t compile via a Lambda calculus core. This, I think,
is mostly a mistake to be fixed at a later point in time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_type_checking&#34;&gt;Type checking&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In the GraphQL &lt;a href=&#34;https://graphql.github.io/graphql-spec/&#34;&gt;specification&lt;/a&gt;,
there are two sections of interest: &lt;em&gt;Type System&lt;/em&gt; and &lt;em&gt;Validation&lt;/em&gt;.
Where you &lt;em&gt;can&lt;/em&gt; execute a GraphQL request without worrying about its
well-typedness, it seems rather futile to do so. So we decided to bake
the validation into a proper checking phase in the engine.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In hindsight, we think this has been the correct choice. The language
is quite amenable to a classic operational semantics on its types. The
transformation into a proper logic uncovered many corner cases in the
specification which needed clarification. Also, we&amp;#8217;ve given opinions
from time to time on the specification based on what is possible in a
logic, and also what is easy to implement in a logic. This helps
coherence of the language quite a bit.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The first type checker we wrote were based on a classic algorithm. It
had many bugs, mostly because it was built and extended as we went
along implementing more and more language features. So with that
experiment behind us, we embarked on the idea to rewrite it using a
more modern style, hopefully simplifying and squashing further bugs in
the process. At this point, we had a sizable test suite, so a rewrite
would not introduce too many futher faults.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I&amp;#8217;m pretty sure bidirectional type checking is part of the folk-lore,
but there are some really good expositions on them. One is written by
David R. Christensen, and another by Frank Pfenning:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://davidchristiansen.dk/tutorials/bidirectional.pdf&#34; class=&#34;bare&#34;&gt;http://davidchristiansen.dk/tutorials/bidirectional.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~fp/courses/15312-f04/handouts/15-bidirectional.pdf&#34; class=&#34;bare&#34;&gt;https://www.cs.cmu.edu/~fp/courses/15312-f04/handouts/15-bidirectional.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Once you start using this style of type checker, you will want to
write every type checker in this style.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_the_core_idea&#34;&gt;The core idea&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The key observation is that type checking can be split into a couple
of different building blocks. Once these blocks are established, we
can recombine them, as you would in typical algebraic fashion. There
are obvious similarities to attribute grammars, as we will see.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We split type checking into three building blocks. We annotate each
entry with a &lt;code&gt;+&lt;/code&gt; if they are given (have positive mode in the
relation), and &lt;code&gt;-&lt;/code&gt; if they are returned by the algorithm (have
negative mode):&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Synthesis/Inference: &lt;code&gt;G+ |- e+ &amp;#8658; t-&lt;/code&gt; given an environment &lt;code&gt;G&lt;/code&gt; and an
expression &lt;code&gt;e&lt;/code&gt;, we figure out a type for it, &lt;code&gt;t&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Checking: &lt;code&gt;G+ |- e+ &amp;#8656; t+&lt;/code&gt; check that the expression has given type
&lt;code&gt;t&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Subsumption: &lt;code&gt;sub t+ s+&lt;/code&gt; check that the type &lt;code&gt;t&lt;/code&gt; is a subtype of
&lt;code&gt;s&lt;/code&gt;. That is that &lt;code&gt;t&lt;/code&gt; &amp;#8220;fits inside&amp;#8221; &lt;code&gt;s&lt;/code&gt; in an obvious fashion.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The reason one wants to split into these building blocks are that the
type checker becomes simpler. You so-to-speak use checking to push
down information you have into subexpressions, and then use synthesis
on the way to switch judgement mode and gather knowledge about types.
This pendulum of back-and forth between the two building blocks makes
a lot of type checking rules simple. The subtype relation is used to
verify you don&amp;#8217;t break rules along the way.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Example:&lt;/em&gt; If we have a type which is non-nullable in GraphQL: &lt;code&gt;t!&lt;/code&gt;
and we are checking it against a type &lt;code&gt;s&lt;/code&gt; which is nullable. Then this
amounts to ignoring the non-nullability and check &lt;code&gt;t&lt;/code&gt; against &lt;code&gt;s&lt;/code&gt;.
This is because a non-nullable value is &amp;#8220;stricter&amp;#8221; than a nullable
one and fits nicely inside it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A typical pendulum operation when checking a request is that of a
schema-lookup. To check against a given type we synthesize a
schema-lookup, hence obtaining a proper type for the subexpression,
which we then proceed to check.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What is omitted in the above, compared to the real checker, is that we
also &lt;em&gt;elaborate&lt;/em&gt; the AST. We annotate the tree with the types we
found. This eliminates a lot of later hash-table lookups because the
needed type information is already in the tree.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Also, literal values are input-coerced in the type checker. This is
done as a partial execution of the query for the parts which are
constant.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_flow_polarity&#34;&gt;Flow Polarity&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The second observation is that in GraphQL, there are two major flows:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Input: Client &amp;#8594; Server (positive flow)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Output: Server &amp;#8594; Client (negative flow)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In turn, every GraphQL term is either present in one or both of these
flows. For instance, an &lt;em&gt;input type&lt;/em&gt; has positive flow, whereas an
object type returned has negative flow. There are also nonpolar flows
in scalars and enums.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The flows guide how one should check against types. In the positive
flow direction, we cannot trust the client, but the GraphQL schema on
the server side can be trusted. Hence, we should recurse over the types
of the schema, not what the client provided. This guards against the
client omitting a required argument for instance.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In contrast, the negative flow reverses the recursor: here, we are
only interested in what the client wants, so we only check those
values. If the schema/server provides more values but they are
illegal, they are ignored since the client did not request them.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Using these observations, it is possible to figure out many questions
one might have when writing the type checker. Most loops write
themselves based on the flow rules. And most checking rules writes
themselves via the three bidirectional building blocks. The
consequence is a small and lean type checker for GraphQL.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_results&#34;&gt;Results&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_code_size&#34;&gt;Code size&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The approach used here currently amounts to about 1000 LOC, including
comments. The reference implementation uses around 3500 LOC on the
same thing, also including comments.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In addition, our code reads as typical operational semantics, which
makes it far easier to validate and verify. Many bugs have been fixed
by addition of a simple rule, or rearrangement of the rule checking
order.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If one wanted to translate GraphQL type rules into a logical framework
such as Twelf, or into a proof assistant such as Agda, it should be
fairly straightforward. Also, the static semantics in operational form
should be easier to write down if one wanted a more formal approach to
the type checking of GraphQL.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_speed&#34;&gt;Speed&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The type checker usually runs much faster than the interpreter phase.
A query is static, and not executed per fetched node, whereas the
interpreter has to walk over data returned. Factors of 1000:1 in favor
of the type checker is not unheard of. This argues one should write
the type checker for simplicity rather than speed.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>{&#39;EXIT&#39;, joe, goodbye}</title>
       <link>https://jlouis.github.io/posts/joe-goodbye/</link>
       <pubDate>Sun, 21 Apr 2019 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/joe-goodbye/</guid>
       <description>&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Jesper, I have this idea in which we&amp;#8217;ll connect &lt;em&gt;all&lt;/em&gt; of the worlds
Erlang systems to each other, imagine if every process could talk to
every other process, world-wide!&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;attribution&#34;&gt;
&amp;#8212; Joe Armstrong
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Joe was never short on ideas when you spoke to him. At conferences, he
would engage people with his newest idea, or he would find people
across the room and connect them. This often resulted in new
acquaintances, interesting conversations, and new insights. Joe acted
as the fountain from which insights sprang. He always had a new
project going, and was keen to tell about it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Joe would speak to everyone. It didn&amp;#8217;t matter if they were new to the
world of Erlang, or computers, or if you had 20 years of experience.
He would quickly find your level, and then discuss at that level.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In my mind, three rules embodied the ideas of Joe:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;They were always practical and wanted to solve a grand problem with
computers. Most often, the limitations of physics played a role.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They always felt a little bit crazy, mainly due to the novelty of
the idea.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They were going to restructure your brain, and how you thought about
stuff.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When I was writing a BitTorrent client for Erlang, Joe was quick to
comment on the code &amp;#8220;This part uses defensive code style, you can
probably just let it crash.&amp;#8221; It took some years for that lesson to
fully sink in, as it did with most of Joes stuff. He would gently
nudge you in a direction, and by following his trajectory, you
landed perfectly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Most people reading this will know Joe for his work on Erlang. But he
had lots of ideas, and not all of them pertained directly to Erlang
itself, though it was often the vehicle. He had a keen interest in
music and did collaboration on the Sonic Pi with Sam Aaron. Up until
recently, Joe was working on improving wiki tooling. In particular,
he&amp;#8217;d realized how he needed a quine,&lt;sup class=&#34;footnote&#34;&gt;[&lt;a id=&#34;_footnoteref_1&#34; class=&#34;footnote&#34; href=&#34;#_footnotedef_1&#34; title=&#34;View footnote.&#34;&gt;1&lt;/a&gt;]&lt;/sup&gt; the wiki should contain its own source code
so it could reproduce itself. This would ensure the longevity of the
wiki. This work was in April 2019, so he was working on stuff up until
his untimely death.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Joe liked to find minimal solutions to problems. He would strip layer
upon layer off a problem until he had the core. He created a stack of
universal binary formats, UBF. The ingenious part of this was that to
transfer a term, one would transfer a &lt;em&gt;program&lt;/em&gt; which when executed on
a small stack-based virtual machine would yield said term. And the
commands were chosen from the printable ASCII alphabet.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The higher layers in the stack was the basis for a lot of discussions
I had with Joe. Both of us agreed that what happens &amp;#8220;inside&amp;#8221; an
Erlang process wasn&amp;#8217;t that interesting in the grand scale of things.
It was the communication which was important, and it should have a
contract system. Joe had certainly invented most of this before I
even started looking at Erlang as a language. And I still&amp;#8212;&amp;#8203;to this
day&amp;#8212;&amp;#8203;believe that this is future of protocol communication.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;To see how visionary Joe was, his idea was to use such a contract
system to get any Erlang process on any node to talk to another Erlang
process, somewhere out in the universe. Essentially, this gives you
&amp;#8220;Serverless&amp;#8221; operation, so he was a couple of years ahead of the
pack on that.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Joe also wanted to mix this with a content addressable storage
spanning the internet. He would speak fondly of IPFS which to a large
extent was this vision. The main idea is to generate the reference key
for data from the data itself, usually a cryptographic hash over the
data. This in turn provides integrity: if the data changes, so does
its key. Now, if you refer to data by its key, then you can verify you
got the right data. Joe wanted to use this as a basis for software:
&amp;#8220;I can send you the hash, and you can fetch the library if you don&amp;#8217;t
have it.&amp;#8221; he told me. He also wanted to use this idea to protect old
software so &amp;#8220;It could still run after many years.&amp;#8221;--another reason
Joe preferred minimalistic approaches to software. &amp;#8220;You see, a
package version is the hash of its source code, not a version number,
that would be silly.&amp;#8221;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;He was adamant on making computers useful.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The greatest brain restructure, however, was always in the idea that
your abstract logic of a program &lt;em&gt;has&lt;/em&gt; to execute in the physical
environment. This meant coping with failure when it happened as the
only way to build robust software. Programming without this profound
insight&amp;#8212;&amp;#8203;software cannot proactively remove all error&amp;#8212;&amp;#8203;is as silly as
it is dangerous in hindsight.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Once you embrace fault tolerance, then you have the feeling of a burden
released, and programs gets far easier to write. Of course, the more
seasoned programmer knows when you can be proactive and when you have
to be reactive. But if there one thought which has shaped the way I
think about programming the most, it is this.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The second greatest brain restructure was Joe&amp;#8217;s dismissal of
performance in software. In a post to the Erlang mailing list, Joe
would come up with the following table:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre&gt;This is what we do: (We = ///)

    1) hack it in erlang
    2) fast enough - ship it
    3) tweak the erlang
    4) fast enough? - ship it
    5) hack it in C?
    6) fast enough - ship it
    7) tweak the C
    8) fast enough? - ship it
    9) make an FPGA
    10) fast enough - ship it
    11) make an ASIC
    12) fast enough - ship it

As you go down this list things cost more and more - step 11 costs
1M$/try - to pass step 9
you need to have a high volume product (10&#39;s to hundreds of thousands of units)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The core idea is that if you want to go really fast, you need to
implement hardware specific to the problem, and you can only hope to
tweak the software so far in performance. And he would make a point
about setting up a specified target before starting the tweakery, so
you&amp;#8217;d know when to stop. Over the years, I&amp;#8217;ve veered in the same
general direction as Joe.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One thing I liked about Joe was his fearless approach to computing and
to life. He&amp;#8217;d never bow to authority. He&amp;#8217;d would never be afraid to
provoke if it was necessary. He never ever stopped R&amp;amp;D. He would
tinker with things until he understood them, then find something new
to look at. But only after he told you about his findings. Sharing was
his modus operandi.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;At conferences&amp;#8212;&amp;#8203;in which Joe was an attendant&amp;#8212;&amp;#8203;there would be this
hallway track going on where people would talk with Joe. A slot would be
skipped here and there. But some interesting conversation would be
had, and people would convene around him in a circle that grew ever
larger. I&amp;#8217;ve watched more than once when a &amp;#8220;innocent bystander&amp;#8221; was
drawn into his web of stories, findings, and insights.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Being a speaker with Joe in the audience was always a blast. Once he
sensed he was allowed to interact, you could be sure he would
&amp;#8220;heckle&amp;#8221; your talk in the most awesome way. It only took a smirk and
you saying &lt;code&gt;{hello, joe}&lt;/code&gt; and that would be his cue. We should have
mic&amp;#8217;ed him up at times.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When he did speak up, he would often frame a question such that it put
a speaker in a position where they could really show their work. Never
have I heard a bad question by Joe.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This was the Joe I knew. I think we owe him a lot with regard to
pushing software and computer science ahead. The best we can do is to
make sure his grand ideas are not lost upon us, and that they are
implemented in the future to come.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;And then perhaps, we will reach a point where Joe&amp;#8217;s prediction from
this Month will ring true:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One day computers might become useful.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;attribution&#34;&gt;
&amp;#8212; Joe Armstrong
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;footnotes&#34;&gt;
&lt;hr&gt;
&lt;div class=&#34;footnote&#34; id=&#34;_footnotedef_1&#34;&gt;
&lt;a href=&#34;#_footnoteref_1&#34;&gt;1&lt;/a&gt;. A quine is a self-reproducing program
&lt;/div&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>A moonpig-like system</title>
       <link>https://jlouis.github.io/posts/a-moonpig-like-system/</link>
       <pubDate>Sun, 29 Dec 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/a-moonpig-like-system/</guid>
       <description>&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The Raven that used to sing&amp;#8212;&amp;#8203;and other stories&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Mark Jason Dominus wrote about &lt;code&gt;&#34;Moonpig&#34;&lt;/code&gt;, which is his and Rik Signes
work on building a billing system in Perl. He wrote up his story over on
his &lt;a href=&#34;http://blog.plover.com/prog/Moonpig.html&#34;&gt;blog&lt;/a&gt;. At
&lt;a href=&#34;http://www.issuu.com/&#34;&gt;Issuu&lt;/a&gt;, Francesco Zanitti, Anders Fugmann,
and I wrote a system which has some similarities to Moonpig. This is a
hash through that system. Currently, we mostly handle post-paid
services.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Billing mostly sucks. It is one of those areas of software where the
realities of the world clashes with your nice logically structured code
base. This clash often produces problematic complications in systems for
one reason or the other. Furthermore, to rub salt into the wound, most
billing solutions out there sucks even more. So we decided, like Mark
and Rik, to write our own.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In hindsight, there are things we should probably have done differently
in the structure of the system. And there are things we should perhaps
have treated in other ways. But the system is in production and runs. It
rarely gets updates.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_inspiration&#34;&gt;Inspiration&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When we wrote the system, two papers inspired us.
&lt;a href=&#34;http://research.microsoft.com/en-us/um/people/simonpj/papers/financial-contracts/contracts-icfp.htm&#34;&gt;Composing
Contracts&lt;/a&gt; by Peyton Jones, Seward and Eber describes a small contract
language for financial transactions. And this language is compiled with
several compilers to produce different interpretations of the same
syntax.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The other source of inspiration was the 3gERP project at
&lt;a href=&#34;http://www.diku.dk/&#34;&gt;DIKU&lt;/a&gt; lead by Fritz Henglein. Of interest is
&lt;a href=&#34;http://www.diku.dk/~hvitved/&#34;&gt;Tom Hvitved&lt;/a&gt;&#39;s Phd dissertation,
which describes an ERP system based on &lt;em&gt;contracts&lt;/em&gt; and &lt;em&gt;event
logs&lt;/em&gt;. Roughly the idea is that events in the system is sent to a
persistent log which is never deleted. Code in contracts read events
from the log and proceed to execute. A central aspect is the concept of
&lt;em&gt;replay&lt;/em&gt; where a contracts state can be replayed from the start of
time. This provides Point-in-time-recovery (PITR) of any contract at any
point, as well as an audit log. Current contract state is kept
&lt;em&gt;in-memory&lt;/em&gt; and is never persisted. Only the events that will lead
to that state.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Our system&amp;#8212;&amp;#8203;and the 3gERP model&amp;#8212;&amp;#8203;consist of contract processes and
agent processes. A contract poses &lt;em&gt;obligations&lt;/em&gt; which are read by
agents. Once agents fulfill the obligation they send back
&lt;em&gt;transactions&lt;/em&gt; to the event log&amp;#8212;&amp;#8203;and transactions are subsequently
picked up by the contracts. A powerful concept in the model is that of
&lt;em&gt;blame.&lt;/em&gt; If we can&amp;#8217;t proceed in a contract due to a time constraint
being hit, we can see which party had the obligation of an action. This
means we can identify if it is the customer or the company which made
the error, and handle it accordingly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Since our system is written in Erlang, agents are separate
(Erlang-)process groups. This allows our system to handle events
concurrently, and allows multiple subsystems to proceed. We can also
replace standard contracts and agents with mock variants for testing.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Currently we handle all contracts in a single Erlang-process, but this
is clearly a design mistake. We could get better isolation properties by
splitting each contract into a process of its own and then let contracts
run in a truly concurrent fashion.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Another mistake is that we route obligations and transactions over
&lt;em&gt;buses&lt;/em&gt; inside the system. But it would probably have been better
to make contracts to direct-calls through a routing/proxy layer to a
target process. The current bus-model is not very Erlang-idiomatic.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_the_key_observations_aboutbilling&#34;&gt;The key observations about~billing&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Here is the primary key observation about billing:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Profit scales proportionally with the billing system load&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Modern computers are incredibly beefy. We can run a gigantic billing
system in memory on a 7.5 or 15 Gigabyte instance on Amazon EC2. Even if
we outscale it and need a 244 Gigabyte machine at almost \$7 per hour,
chances are our profits are such that this amount of money is peanuts.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Hence, worrying about system performance is&amp;#8212;&amp;#8203;for most companies&amp;#8212;&amp;#8203;going
to be premature optimization. Much more important is correctness,
durability and resilience. Thus, the focus should be on that and not
&lt;em&gt;lolspeed&lt;/em&gt;. This is a welcome change of pace.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This key principle is an efficient driving force behind design
decisions. You can opt for the simple and verifiable algorithms and data
structures over the fast ones. If you ever need to go back and tune the
system for scale, you will be making so high a profit it will be a
problem of luxury.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Some napkin math: A typical customer account runs a single contract. A
contract is around 2 Kilobytes of memory in Erlang. I have 244 Gigabytes
of memory. We will run out around 128 million paying customers. Assume
profits of $1 per customer and this is not a problem.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The second key observation is this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We can arrange the system such that we take all the blame for errors&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;That is, whenever we are in doubt, we give the benefit to the customer.
Mark wrote about this when he decided to handle rounding errors by
giving customers the fraction which cannot be divided.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;But there are many places where this principle can be used to simplify
the code base. If a given feature costs $30,000 to implement but only
yields you $50 a year, then the effort of implementation is clearly not
worth it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This principle gives us more freedom and flexibility in the
implementation because we can handle certain problematic areas by just
ignoring them while measuring their impact.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Finally:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The world is not perfect and faults will happen&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Our system is systematically built to acknowledge certain subsystems
will fail. And the approach is to regard that we are always in a state
where the subsystem failed. More on that later.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_storage&#34;&gt;Storage&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We store all data in a flat file on disk. Data are stored as Erlang
terms in a pseudo-human-readable format (think XML, S-expressions or
JSON). This is deliberate. It is much easier to read and verify.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The &lt;em&gt;current&lt;/em&gt; state is handled by a built-in database in Erlang
called &lt;em&gt;mnesia&lt;/em&gt;. This database stores an in-memory current view.
Provides a transactional store loced to the on-disk log and so on. It
provides a cache of what is in the flat file on disk. We can always
throw away the database and replay the log from the dawn of time (which
is somewhere around Nov. 2011 for this system). In principle Mnesia can
also bootstrap the system faster since we can skip over large parts of
the log, but we have not had the reason to implement that optimization
yet. A reboot just replays from the start.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The Mnesia part also explains how we can do reporting. We have a
database, almost Relational in nature, which we can query to extract
reports. The PITR-property of the event log also lets us answer
questions back in time. But for simplicity, we just store all data
persistently in Mnesia in classic OLTP-manner.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_other_storage_options&#34;&gt;Other storage-options&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One option we have thought of is to keep a flat file per contract and
one global file. The advantage is we can then boot contracts on demand
when we need them. The disadvantage is we loose an important property of
the current system: linear time ordering.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The current system forces an ordering on all events and only forwards
events in that order. This simplifies almost all of the code base.
Distribution afficianados might claim that this will be a problem for
performance. But due to the primary key observation, we can ignore it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The other option is to introduce a database to run the event log.
Postgres is an obvious candidate. We have not given this much thought,
but it may be an option and simplify some parts of the system.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_handling_time&#34;&gt;Handling time&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Time in our system is handled roughly like time is handled in Moonpig.
Time is &lt;em&gt;injected&lt;/em&gt; or &lt;em&gt;pushed&lt;/em&gt; into the system. It is never
pulled by the system. Whenever an event happens, there is a time
parameter which is sent into the system and tells us what time it is.
Functions inside the system pass on the &lt;code&gt;&#34;current time&#34;&lt;/code&gt; and we never
call &lt;code&gt;erlang:now()&lt;/code&gt; nor &lt;code&gt;os:timestamp()&lt;/code&gt; inside the code
base.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The consequence is that testing is now suddenly possible. We can quickly
play out scenarios where time is forwarded a couple of years. The test
system controls the time fully, so it is easy to play out
what-would-have-happened scenarios.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When running normally, we inject time at the boundary of the system when
some event happens. In effect, other users do not have to cope with the
fact that time is injected into the model. But from a testing
perspective, we can just pick the variant of the call where time can be
overridden.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_current_time_contract_time&#34;&gt;Current time &amp;amp; contract-time&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A distinction from Moonpig is how we handle time in contracts. In
Moonpig, time is handled by heartbeats and it is the responsibility of
subsystems to ignore heartbeats which were duplicated etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In our system, contracts have an internal time which we can call &lt;code&gt;C&lt;/code&gt;. If &lt;code&gt;T&lt;/code&gt;
denotes current time, we always have the property that &lt;code&gt;C &amp;lt; T&lt;/code&gt;.
That is, the contracts time is always behind the current time by some
small epsilon value. The scheme where the contract always lags behind
real time allows us to handle heartbeats in a slightly different manner.
When an event is injected into the contract, a timestamp T is also sent.
The contract now &lt;em&gt;forwards&lt;/em&gt; itself to the next point in time where
something interesting happens on the contract. This makes sure duplicate
injections of time and events are ignored by the contract.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This model also describes how we handle problems where the system fails.
We have backup procedures. We can just restart the system a couple of
days later, and it will forward time and do things correctly. If
anything important should have happened on the days in between, they
will be handled at this point.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Note the implication: our system is always in a catch-up mode. It always
thinks the state of affairs is that it is behind and need to do
something to catch up to the current situation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_quickcheck&#34;&gt;QuickCheck&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We never got around to do QuickCheck models for contracts, but there is
an interesting property of contracts which is worth mentioning: A
contracts state is derivable from a stream of transactions. Such a
contract should be indifferent to heartbeat-events and other events
types that happens in between the transactions. This can be
probalisitically verified by an &lt;a href=&#34;http://quviq.com/&#34;&gt;Erlang
QuickCheck model&lt;/a&gt;. But we did not get to do that.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_idempotence&#34;&gt;Idempotence&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A very important aspect of our system is idempotent &lt;code&gt;&#34;best effort&#34;&lt;/code&gt;
delivery. When contracts want to have something done, they send out an
&lt;em&gt;obligation.&lt;/em&gt; These are picked up by agents and then handled.
Obligations may get lost. They are periodically restated by the
contract. If an Agent crashes, it doesn&amp;#8217;t matter that it did not handle
all the obligations. We will catch up eventually.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Agents track which obligations they have already fulfilled. If so, they
idempotently produce the same answer as before as a &lt;em&gt;transaction&lt;/em&gt;
which is then sent back to the contract. Thus, if our event log system
crashes, the agent can just send in the transaction again.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Charging works on this system as well. A charge contains a unique
reference and it handles transactions idempotently. So it doesn&amp;#8217;t matter
if the charging system sits in the other end of the world and we lose
the network connection. We will just retry the charge with the same
reference. Since our end handles the unique reference persistenly on
disk, we can&amp;#8217;t generate another reference for the charge. And the other
end can safely store a transaction in their database.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Many areas can be handled with a fire-and-forget type of message. We
only try to send mails once. If the underlying system accepts the mail,
we idempotently mark it as &lt;code&gt;&#34;done and sent&#34;&lt;/code&gt;. This minimizes annoyances
on customers, should we have to try to resend mails.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Note that each agent is usually very simple. Often they are less than 40
lines of code. And they can be checked individually, without the rest of
the system.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We only have to worry about progress, but that can be measured. Our
system extensively uses the
&lt;a href=&#34;http://github.com/boundary/folsom&#34;&gt;folsom&lt;/a&gt; system in Erlang to
track counters and gauges so we can see what is happening inside the
node. In fact, we track almost everything with probes in the system.
Full instrumentation is something we strongly believe in for every new
system written.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_immutability&#34;&gt;Immutability&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Like in Moonpig, we use immutable constructions all over the place. We
never throw away data, but record it into the global event log for
future replayability. This is also what we use when something goes wrong
and we need to figure out what went wrong.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Immutability is also very powerful when one considers debugging. Since
we have every transition recorded and full PITR-support, we can
essentially always rerun the business rules of a contract and see what
went on inside it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Replayability has an interesting impact. When we upgrade our code in
non-compatible ways, we also have to mention that upgrade in the event
log. So old versions of the code still lives on, but is only used up
till a point. Then it is switched with new versions of the code base.
Essentially the system switches between different contract versions over
time.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_floats_time_zones&#34;&gt;Floats / Time zones&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;No floats! Only integers. The system stores everything in cents
internally, but doesn&amp;#8217;t do financial calculations. Our plan&amp;#8212;&amp;#8203;should we
need to do so&amp;#8212;&amp;#8203;was to store everything in picodollars and calculate
exchange rates for other currencies. Much like all time is in UTC and
are offset from there at the boundary.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;However, we do note that our billing provider expects floats, we have a
boundary conversion going on&amp;#8230;&amp;#8203; The mind baffles at times at the
choices made in software systems.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_what_we_skipped_on&#34;&gt;What we skipped on&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We did not implement a DSL for writing contracts. Rather, we wrote the
few contracts we needed in (purely) functional Erlang code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We don&amp;#8217;t have a lot of code in place to manage blame. This is due to the
contract simplicity currently in place. We don&amp;#8217;t really need this.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We could probably improve the model if we had to do it over. I believe
this is &lt;em&gt;the&lt;/em&gt; way to do billing systems for the vast majority of
companies out there. The code is neat and modularized into contracts,
agents and persisters of data. Each can be implemented with a natural
backing into Erlang processes, proxies for foreign subsystems and
RDBMs systems and so on. I also note that a system like
&lt;a href=&#34;http://www.datomic.com/&#34;&gt;Datomic&lt;/a&gt; would be near-perfect to store the
transaction log. And would have a nice scalability curve to boot.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The choice of Erlang is rather nice for a system like this, where
contracts, agents and so on can be modeled as processes. Other good
languages could be OCaml&amp;#8212;&amp;#8203;for its expressive type system, or Go&amp;#8212;&amp;#8203;for
the goroutines.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>The Erlang Shell</title>
       <link>https://jlouis.github.io/posts/the-erlang-shell/</link>
       <pubDate>Sun, 01 Dec 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/the-erlang-shell/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;(Front Line Assembly: Civilization, Eastern Sun: In Emptiness)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As an Erlang programmer I often claim that &amp;#8220;You can’t pick parts of
Erlang and then claim you have the same functionality. It all comes
together as a whole&amp;#8221;. This is true for many programming environments
where the main components are built to be orthogonal from each other and
the parts form the cohesive whole. A good example of this approach would
be Go as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A compelling way of deploying software is what supposedly originated
with FLEX (Alan Kay). The program, the system and its data are all kept
inside an &lt;em&gt;image&lt;/em&gt; which can be persisted to disk and restarted later. In
essence we specify which world we operate in by giving an image. Many
Smalltalk systems utilize this notion of images. So do Common Lisp
systems. And they even understand how to reconnect to networks and
reopen files.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Erlang provides its own, weaker, mechanism for assembling software
called a &lt;em&gt;release&lt;/em&gt;. A release consists of the runtime together with a
set of Erlang applications. They are started as a whole—in a specific
order. The same release is usually booted across several machines if we
want to have resilience against hardware faults. The big shift compared
to images is that there are no on-disk persistence. The ideology is
different: the system should never stop, so even if one &lt;em&gt;node()&lt;/em&gt; in the
cluster is stopped, the data is on other nodes as well and lives. Erlang
systems also allow for seamless upgrades from one release to another
while they are running.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;But there are some resemblance from Common Lisp / Smalltalk images and
Erlang releases. While they don’t persist the data, Erlang images do
define a separate enclosed system with no link to the original system.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The strength of these persistent models come apparent late in the
development cycle. Software usually goes through several phases&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;\(\[\text{Analysis} \rightarrow
\text{Design} \rightarrow
\text{Implementation} \rightarrow
\text{Test} \rightarrow
\text{Deploy} \rightarrow
\text{Maintenance}]\)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;It is important to stress that development of software is a dynamic
activity. We repeatedly change the software in production by layering
more and more complexity/features on top of the system. We also
dynamically fix bugs in the software while it is in production.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The recent years, development tends to so-called Agile methods—where
there are many small dynamic iterations of the software construction
process running all at the same time. We have social tooling in place
which tries to achieve this (Scrum, Kanban,…), and we have technical
tooling in place to reach the goal (git, Mercurial,…).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The &amp;#8220;Maintenance&amp;#8221; part is very expensive. Maintaining running software
has periodic costs associated with it. In a world where everything is a
service, we have to pay operators, pay for hardware resources,
developers, and so on.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When we program, we try to remove errors early. We employ static type
systems, we do extensive testing, we use static analysis. Perhaps we
even use probalistic model checkers like QuickCheck, exhaustive model
checkers like SPIN or prove our software in Coq. We know, inherently,
that eradicating bugs early on in the software life cycle means less
work in the maintenance phase.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;But interestingly, all this only &lt;em&gt;raises&lt;/em&gt; the bar for errors. When we
have done all our hard work, the errors that do remain are all of the
subtle kind. These are errors which were not caught by our initial
guardian systems. Most static type systems won’t capture the class of
faults which has to do with slow algorithms or excessive memory
consumption for instance. A proper benchmark suite will—but only if we
can envision the failure case up front.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The class of faults that tend to be &lt;em&gt;interesting&lt;/em&gt; is the class that can
survive a static type check. The mere fact we could not capture it by a
static analysis in the compile phase makes the error much more subtle.
Also, it often means they are much harder to trigger in production
systems. If the fault furthermore survives the test suite it becomes
even more &lt;em&gt;interesting&lt;/em&gt;. The viral strain has a certain basic DNA which
mutated it so it could get past two barriers of correctness tests. Now
it becomes a latent bug in your software.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Aside:&lt;/em&gt; I tend to absolutely love static type systems. I enjoy them a
lot when I program in Go, Standard ML, OCaml or Haskell. I am all for
the richer description that comes with having a static type system.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There is a great power in being able to say \(v \colon \tau\)
rather than just \(v\)—exactly because the former
representation is &lt;em&gt;richer&lt;/em&gt; in structure. Richer structure helps
documentation, makes it possible to pick better in-memory
representations, makes the programs go faster and forces a more coherent
programming model.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Yet, I also recognize that most of the errors caught by static type
systems are &lt;strong&gt;not&lt;/strong&gt; &lt;em&gt;interesting.&lt;/em&gt; They are of the kind where a simple run
of the program will find them instantly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;End of Aside.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_concurrency_and_distribution_failures&#34;&gt;Concurrency and Distribution failures&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When systems have faults due to concurrency and distribution, debuggers
will not work. The problem is that you can’t stop the world and then go
inspect it. A foreign system will inspect an answer in time or it will
time out. Many modern systems have large parts of which you have no
direct control anymore. Such is life in the Post-1991 era of computing
where the internet defines the interface to your program and its
components. An Erlang system with two nodes is enough to be problematic.
Even if I could snapshot one node, the other node will carry on.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The same is true for concurrency errors. They often incorporate race
conditions which must trigger. Attaching a debugger alters the execution
schedule making the race condition disappear in the process. The only
way to debug such systems is by analysing post-mortem traces of what
went wrong—or by inspecting the systems online while they are running.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;To make matters worse, a lot of races only occur when data sizes are
increased to production system batches. Say you have a small write
conflict in the data store due to inappropriate transactional
serialization and isolation. If your test system has few users, this
conflict will never show up. And if it does, you will disregard it as a
one-time fluke that will never happen again. Yet—on the production
system, as you increase capacity, this problem will start to occur. The
statistical &amp;#8220;Birthday Paradox&amp;#8221; will come and rear its ugly head and
you will be hitting the conflict more and more often. Up until the point
where it occurs multiple times a day.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In conclusion, capturing these kinds of bugs up front is deceptively
hard.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_the_erlangshell&#34;&gt;The Erlang Shell&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The Erlang shell is a necessary tool for producing correct software. Its
usefulness is mostly targeted at the maintenance phase, but it is also
useful in the initial phases of development. A running Erlang system can
be connected to while it is running:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;literalblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre&gt;(qlglicko@127.0.0.1)3&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This provides a REPL so you can work with the software. But note that
this is a REPL on the &lt;em&gt;running production system&lt;/em&gt;. If I run commands on
the system:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;literalblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre&gt;(qlglicko@127.0.0.1)3&amp;gt; qlg_db:players_to_refresh(1000). {ok,[]}
(qlglicko@127.0.0.1)4&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I hook into running processes. In this case &lt;em&gt;qlg_db&lt;/em&gt; which does
connection pooling towards the Postgres database. This allows me to go
probe the system while it is running to check for its correct operation.
Any exported functionality can be probed from the shell.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I often keep a module around, named &lt;em&gt;z.erl&lt;/em&gt; which I can compile and
inject into the running system:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;literalblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre&gt;(qlglicko@127.0.0.1)6&amp;gt; c(&#34;../../z.erl&#34;).
{ok,z}
(qlglicko@127.0.0.1)7&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This dynamically compiles and loads the &lt;em&gt;z&lt;/em&gt; module into the running
system. It makes the functions of the module available for system
introspection and manipulation. When debugging hard-to-find bugs on
systems, you &lt;em&gt;need&lt;/em&gt; this functionality.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;And yes, if you want, Erlang nodes contains the &lt;em&gt;compiler&lt;/em&gt; application
so they can compile modules.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In Erlang, linking is deliberately &amp;#8220;as late as possible&amp;#8221;. This means
you can change software in the system while it is running. There is no
linker phase up front at compile time. Linkage is done when you call
another module. Yes, this costs performance. But on the other hand, it
means you can always rely on the system calling the newest loaded
version of the module. The ability to hot-patch a system while it is
running can help a lot. You don’t have to interrupt the system for small
fixes for instance. If you know that you only changed a single module in
your test build, you can opt to just push that compiled byte code to
production and then inject it into that system. As long as you
systematically add the change to your standard deployment pipeline, this
works.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The shell also provides a lot of nice tooling to help you when you are
looking for problems in a system:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;There is built-in job-control in the sense of the sh(1) shell. You can
have several shells open at the same time. You can reconnect to shells,
either locally or remote. And you can kill shells which have hung for
one reason or the other.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Erlang has built in trace capabilities. These provide DTrace-like
behaviour on the system directly without effort. Enabling tracing only
impacts the traced modules and it is generally non-intrusive (unless you
make a mistake when setting trace patterns, heh). You can mask events:
only when this process calls. And only these two functions. And only
when the 3rd passed parameter is 37. The Erlang shell makes this all
possible dynamically on the running system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Want to know what state a given process has? Fear not, you have online
introspection via the shell.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Want to know how many messages there is the inbox of a process? Fear
not…&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Want to insert a new log statement? Recompile the code and hot-deploy
it via the shell. Fear not…&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;And all this &lt;em&gt;without&lt;/em&gt; service interruption. And you get all this for
free, just because you picked Erlang as the implementation language.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Here is the thing: the first time you use the Erlang shell in production
to fix a hard-to-debug problem it becomes very very hard to live without
it. I’d willingly give up static typing for the ability to look at the
running system. Problems that survive past the tests and into production
tend to be sinister and evil. And subtly elusive. You need a system
there where you can go and inspect it, while the error is occuring in
production.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;It is the same traits that made UNIX a success (and what makes Plan9
alluring and appealing). Your system can be inspected and manipulated
while it is being developed and changed dynamically. Except that in
Erlang, we have much finer grained control over the running UNIX-process
since we can go inside it and inspect running processes inside the node.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>Glicko2 Benchmarking (1)</title>
       <link>https://jlouis.github.io/posts/glicko2-benchmarking-1/</link>
       <pubDate>Sat, 16 Nov 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/glicko2-benchmarking-1/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One of my hobby projects is to run statistics on Quake Live Duel
matches. I began collecting data around 1st of Feb 2013 and now I have
scraped around \(2.5\) Million duel matches. This allows me to
play with different ranking methods on the players and gauge their
ranking.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The ranking system I use is called Glicko2, devised by Mark E. Glickman
(&lt;a href=&#34;http://glicko.net/&#34;&gt;http://glicko.net&lt;/a&gt;). The system is like the chess
rating system ELO, except that it is newer and avoids certain problems
with ELO.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When ELO was conceived, you had to be able to run the calculations by
hand. Glicko2 can use a computer and thus carry out much harder
calculations. So it tend to deliver better results. Glicko2 tracks three
values for each player. His rating R, starting at 1500. His rating
deviance, RD, starting at 350 is a measure of how much we trust the
rating R. If the RD number is small, we have strong belief in the rating
of the player. If it is high, we don’t yet know a lot about that player.
As the player plays more matches and we learn more about the player, we
shrink RD towards 0. Finally a value, Sigma, measures how much a player
is fooling the rating system. This allows us to compensate for quickly
improving players so they don’t get ``stuck&#39;&#39; on a certain rating.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When considering a new rating for a player, we consider a weeks worth of
duels for the player. We update his R, RD and Sigma values depending on
the values from the previous week and the opponents he played against.
If the player has a high RD for instance, his rating is moved more per
win or loss since we know less about him yet. This means we quickly find
the skill level of a given player.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The system I have made is written in Erlang. This choice has been very
fruitful. First of all, I have a system which was easy to write and
scales well, even though I don’t really need that. Second, the fault
tolerance of Erlang has helped me a lot. The system has been very robust
due to the fault tolerance of Erlang. Usually I don’t care about the
system. It takes care of the network being down or Quake Live being
upgraded by itself.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Storage is handled by Postgres. If you need a database that just works,
then picking Postgres is rarely a problem. Furthermore, the complete
data set is less than 6 gigabytes, so almost any kind of store would
work. But Postgres is a simple choice due to its reliability and feature
set.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The Erlang system works well for the fetching of matches, and for
display of match scores and so on. But I need to carry out some tunings
of the Glicko2 parameters. This means I will run through my
\(2.5\) million matches many many times and thus the speed at
which I can run Glicko2 matter. I have an Erlang implementation for a
simulated annealer and ranker. But since it is heavyweight numerical
processing—not an Erlang strength—I need to find another language for
doing that.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So there are three things I need to know:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;How fast can I run the Glicko2 ranking codes? That is, how quickly can
I execute the main loop for a single simple ranking. This will be needed
to understand how much I could hope to gain by going to another language
in the first place. If I can’t get enough speed, I can simply abort the
process right here.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I have \(2.5\) million matches and need to process them all.
Thus the problem is switching from being CPU-bound to being memory
bound. I need to find out if this change affects the processing speed of
other languages. Again, if I can’t do it faster, then I need to abort
the task.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I need to run the \(2.5\) million ranking runs either in an
algorithm running simulated annealing or a gradient search. This means
potentially millions of runs times the \(2.5\) million ranking
runs. This is the long-term goal I wish to reach. In this part I require
the speed much more than in the other parts.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A slightly smaller problem is that my current ranking runs require
memory proportional with the number of matches. When I had 400.000
matches it was easy to fit in memory. But now, I am running up against a
barrier of the machine doing the computations (it doesn’t have too much
memory, it is an old machine).&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In the following I present some Timings. These are run on a Linux Laptop
workstation, where it is plugged into power and runs full processor
speed. The machine is a ``Intel&amp;#174; Core&amp;#8482; i7-3720QM CPU @ 2.60GHz&#39;&#39;
which is an Ivy Bridge machine, 4 cores, two HTs per Core.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I intend to tune on this machine, so it is paramount the rankings are
running fast on this machine.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Erlang Glicko2&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://github.com/jlouis/erl-glicko2&#34;&gt;erl-glicko2&lt;/a&gt; The Erlang system
itself can run a single Glicko2 round of one player against 3 players in
22\(\mu{}\)s. The benchmark in Erlang is carried out by
running the test 300 times and then averaging. This batch size seems to
be quite stable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The speed figure of Erlang is with the standard BEAM bytecode
interpreter. And the code is straightforward with no tuning whatsoever.
With \(2.5\) million matches it takes just around a minute to
run through them all, which is acceptable. But since I am to run faster
than that, I wanted to know how much faster I could go.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Compiling with HiPE gives 8\(\mu{}\)s. This is much better and
far more in the area where I would like to be. But perhaps we can do
better by switching the language.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ocaml Glicko2&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://github.com/jlouis/o-glicko2&#34;&gt;o-glicko2&lt;/a&gt; One of my favorite
languages when I need fast processing is OCaml. The language has a large
number of beneficial properties—static typing, a native code generator
producing fast executables, a good module system and a nice eco-system.
So naturally, transcribing the code from Erlang to OCaml has to be
tried.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The code is quite straightforward to change from Erlang into OCaml.
There are few places in the code base where we use anything but &lt;em&gt;float&lt;/em&gt;
types, so it is easy. The only slight problem was a missing parenthesis
group which made a subcomputation produce the wrong result. Luckily, I
have extensive tests so it was caught quickly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Note that the particular error is one of those which will not be caught
be a type system. In numerical code, everything is of type &lt;em&gt;float&lt;/em&gt;
anyway, so there is no way I can hope to catch this kind of error
straight away. Type systems help a lot with symbolic processing, but
this task is not one which has that property.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The OCaml code is written in idiomatic style. Functional, closures, and
so on. I could opt for a more imperative style—which Ocaml allows—but
for what purpose?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I use the &lt;strong&gt;Core_Bench&lt;/strong&gt; module from Janes St. to do my benchmarking. The
nice thing is that this tool predicts the batch size to use and also has
prediction that avoids making the wrong conclusions. The OCaml bytecode
interpreter clocks in at 28\(\mu{}\)s. This result somewhat
surprises me. I had expected the run to be faster than Erlang. But I
guess more time is spent optimizing the Erlang interpreter than the
OCaml bytecode interpreter and code generator.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Running native yields a time around 2\(\mu{}\)s. This number
is really good. If we are to process \(2.5\) million matches,
we can do so in \(2.5 \times 2\)\(\mu{}\)s (assuming
no cache hierarchy) or \(5\) seconds. Much better than the
minute it would require in Erlang.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Yet, the problem here is that the OCaml core is not parallel. I would
need to cut up the data set into pieces and then run an OCaml process
per core. There is no need to do that in Erlang. So even though the
results will clock in faster, the problem is that I will need more work
to fetch data in parallel later on. So parallelism might become a
problem going forward.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Go — Glocko2&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://github.com/jlouis/glocko2&#34;&gt;Glocko2&lt;/a&gt; Naturally, I had to try Golang
next. This language is interesting because it has nice semantics, fixing
most of the things I hate about C. It compiles to native code with a
standard slightly optimizing compiler. And it supports multiple cores in
its runtime, which is needed if I want to get parallelism inside a
single process later on.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Writing the code in Golang is a chore. Productivity is definitely slower
than in Ocaml since you have to type more and waste precious time
reframing the nice functional problem into imperative code. Even though
this was the last thing I implemented, it still took about twice as long
as the OCaml implementation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Do note: My imperative skillset is there, but I don’t write much
imperative code nowadays. This could be a factor in the slower writing
speed. However, writing last should be a help, rather than a
hinderance.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What is so nice about Golang is the tooling. I set up &lt;em&gt;go test&lt;/em&gt; early on
in my editor, so when I saved a file it would automatically compile and
run tests. See &lt;a href=&#34;http://github.com/eaburns/Watch&#34; class=&#34;bare&#34;&gt;http://github.com/eaburns/Watch&lt;/a&gt; for the tool I use in
Acme to do this. This meant I could start by writing down all the test
cases and then go work on the implementation afterwards. As more and
more of the code base began to work, I had fewer and fewer failing test
cases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Benchmarking can be done with the Go Testing tools as well. It also
computes a batch size and gives you predictive results, like in Ocaml.
But in this case, it is built into the default tooling. I cannot
&lt;em&gt;stress&lt;/em&gt; how important it is for a language to have nice access to
profiler tooling and so on inside the default language distribution. The
fact that the build tool does testing and benchmarking as well by
default is just awesome.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Being Go, the compile times are faster—but this doesn’t matter for this
problem as the compile times are ``not noticable&#39;&#39;. Go clocks in at
1\(\mu{}\)s. About twice as fast as the OCaml solution. This
is with the default compiler written by Ken Thompson initially and
improved by many other people.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Recap&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So we have:&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&#34;tableblock frame-all grid-all stretch&#34;&gt;
&lt;caption class=&#34;title&#34;&gt;Table 1. Breakdown of the different implementations running speed&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col style=&#34;width: 50%;&#34;&gt;
&lt;col style=&#34;width: 50%;&#34;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th class=&#34;tableblock halign-left valign-top&#34;&gt;Language&lt;/th&gt;
&lt;th class=&#34;tableblock halign-left valign-top&#34;&gt;Efficiency (\(\mu{}\)s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Ocaml bytecode&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;28&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Erlang bytecode&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;22&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Erlang HiPE&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;8&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Ocaml native&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;2&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Go&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There is no solution which totally aborts at this point. I already have
an Erlang implementation, and the numbers may change around when we add
the next layer—processing 2.5 million matches. Before I add that and
have the option to do profiling, I’d rather not try to hand-optimize
these results too much right now.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Tuning Tricks&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When you revisit the same algorithm in multiple languages, you see
possibilities for optimizations all over the place. There are some
subcomputations, the &lt;em&gt;g&lt;/em&gt; and &lt;em&gt;e&lt;/em&gt; functions, which I don’t know if it is
worth to compute once and then stash away in memory. I could probably
lower write memory pressure and GC by recomputing them when I need them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Also, all of Glicko2 runs on a scaling factor of &lt;em&gt;173.7178.&lt;/em&gt; This means
that before doing anything with the given R and RD values, you scale
them down by this factor. All computation are carried out on the
downscaled numbers. The final step is to upscale everything again. A
trick which I am seriously considering is to scale down everything
before starting my runs. This avoids a down scale and an upscale in each
loop and this would help a &lt;em&gt;lot&lt;/em&gt; for the larger computations where many
runs are needed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One of the major Glicko2 steps is to find a root of a function. I am
currently using a root-finder, called Ridder’s method. This finder is
quite fast, but it is also the major slowdown in the runs. When I first
implemented the OCaml variant, I picked a different root-finder by
mistake. This meant that it ran in 0.6\(\mu{}\)s, so
definitely this part of the code base is the contending one. It also
suggests that the Golang implementation is handling this part
differently than the OCaml code and there is definitely room for
improvement in the OCaml code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Parting words&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In the next phase, the code to read, parse and compute on 2.5 million
lines of code has to be written. I have no time frame for doing so, as I
am mostly doing this ``for fun and entertainment&#39;&#39;. I am pretty sure you
can optimize the code bases like mad, but there is little reason to do
so before the other parts have been implemented. The problem will
quickly be memory bound, so the interesting things in speeding it up
will be in-memory representation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;My initial ideas is to store data in a vector-like format. In Erlang I
use an ETS-table, but this incurs a hash-table lookup a large number of
times. My profiling shows I spend 50% time in &lt;em&gt;ets:lookup_element/3&lt;/em&gt; in
Erlang. So to go faster, I need to pack these data better in memory. It
might very well be that the numerical code is not the hottest path in
this program at all. So I hesitate to optimize it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This is also the reason why I considered BER MetaOCaml, but lost
interest in using it again before I know that I can get decent speed on
the other parts. There are ways to make this parallel even thought the
OCaml runtime is not. Perhaps I can work around that, but I will note
the extra cost in time to do so.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I also considered Haskell. Given Repa or Accelerate, you can probable
speed up the computation and move it to the GPU. It is an interesting
project, but it requires a completely different approach to the problem
at hand. One could also use the Erlang OpenCL bindings to achieve
something like this.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Finally, if you were a company, &lt;strong&gt;none&lt;/strong&gt; of this would have been needed. I
already had the Erlang code for tuning. I would just have had to lease
the next machine size in Amazon Web Services for 24 hours. I don’t need
to run tuning that often. Once a year or so is perfect. And I can run
weekly updates in a minute. If I cut the dataset into 10 pieces, and
load it from Postgres a little bit at a time, then I could definitely do
this inside a 3 minute window. This is hardly a problem. It is not worth
doing this from a Cost/Benefit perspective. And frankly, writing the
code in Erlang is probably faster than writing it in OCaml or Go for me.&lt;/p&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>On Logbooks</title>
       <link>https://jlouis.github.io/posts/on-logbooks/</link>
       <pubDate>Mon, 11 Nov 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/on-logbooks/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;My friend, Michael T. Richter, presented me with a nice concept from
engineering. The &lt;em&gt;logbook&lt;/em&gt;. The concept is extremely simple: you keep a
log of your work, so you can refer back to it later. Yet, there are
relatively few in Computer Science who does that, which is a sad state
of affairs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The odd thing is that most computer scientists do know the importance of
logging in an application. You see these elaborate logging frameworks
that can log at different log levels, can forward logs between machines
and so on. Yet—it looks like the CS people forgot that the same logging
could apply to your own work.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;My Log comprises two files. One for work and one for personal projects.
In each file, I keep track of dates. The file is pure text, though I use
utf-8 encoding, so I have access to full Unicode, which I exploit fully.
I have the following in the file in the acme(1) editor:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;literalblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre&gt;&amp;lt;date +%Y-%m-%d&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;which can be run to enter the current date at the cursor position. I
tend to jot down the projects that are &lt;em&gt;in progress&lt;/em&gt;. My log is not a
TODO list! I’d rather track stuff I have done than stuff I don’t have
time to do. Having a log gives me some immediate benefits:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I can run &lt;em&gt;grep&lt;/em&gt; on old entries. This is tremendously efficient. I
often write down shell-oneliners, R scripts, hostnames too volatile
for &lt;em&gt;.ssh/config&lt;/em&gt;, results from benchmarks, test failures, meeting
outcomes and so on. I can find old stuff as long as I remember that I
wrote it down at some point in time. I also keep links to papers, Issues
I am working on, source files and so on. My editor of choice, acme(1),
allows one to write &lt;em&gt;file:/REGEX&lt;/em&gt; to open a file and then perform a
search within that file based on the regular expression I give. In
effect, I have full history tracking.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I can answer the question ``What did you do two weeks ago?&#39;&#39; with
ease. It also means I can gather knowledge about what kind of work I am
currently doing and for what purpose.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The log acts as a tool for improving the process. By keeping track of
what is being done, I can look back and see what can be done better.
This allows me to run an iterative quality improvement process on my
development.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The log allows me to use the &amp;#8220;Hemmingway trick&amp;#8221;, which is leaving a
sentence before it is done and finished. It is then easier to go back
and pick up from where you left. By tracking what is currently in
progress, I have an easier time entering flow again on the piece of code
I am working on. Switching ``context&#39;&#39; is also way easier. Since I can
write down where I am currently on one part and then switch to another
part.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Since the log tracks stuff in progress, I can quickly figure out if I
am starting too many new projects and not finishing any of them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The log allows me to clear my brain once in a while since it has been
documented elsewhere.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It is way easier to have &lt;em&gt;focus&lt;/em&gt; with a log of what is being done,
vastly improving efficiency and output.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Personally, I think the most important part is that this has vastly
improved my process. Especially when hunting for bugs. I tend to write
down what I know and what hypothesis I have. Then I try to devise some
experiment that can cut through the hypothesis and cleave up the
possibilities. Bug finding becomes much faster when you approach it like
this.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Another part of the process which also has improved is the approach to
writing new code:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I try to document the purpose of the new piece of code. That way, I
make sure I know why it is important to implement this part—and I
document that for future reference.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I often write down how hard I think the code is to complete. This
gives me a benefit later when I can go back and see if I was right or
wrong with the estimate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we had multiple solutions, that is documented.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If a test comes up with a surprising result, that is documented.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As a consequence, you do less work and better quality. The concept of
the &lt;em&gt;logbook&lt;/em&gt; is hereby passed on to the reader.&lt;/p&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>Eventi</title>
       <link>https://jlouis.github.io/posts/eventi/</link>
       <pubDate>Wed, 30 Oct 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/eventi/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So, listening a bit to &amp;#8220;The Civil Wars&amp;#8221; this afternoon cooked up the
rest of eVenti. This blog post is brought to you by Maurice Ravel, and
Morcheeba however.&lt;sup class=&#34;footnote&#34;&gt;[&lt;a id=&#34;_footnoteref_1&#34; class=&#34;footnote&#34; href=&#34;#_footnotedef_1&#34; title=&#34;View footnote.&#34;&gt;1&lt;/a&gt;]&lt;/sup&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The eVenti system is a simple Erlang-implementation of the venti(8)
system famous from Plan9. The idea is very simple: We can store data in
Venti and the data becomes addressed by its SHA1 checksum.footenote:[I
should probably change this later, but for compatibility reasons we
stick to it…] This is called a Content Adressable Storage (CAS) because
Content is—you guessed it—addressed by the checksum of the content.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;div class=&#34;title&#34;&gt;Immediate effects are:&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Storing the same data twice has no effect, deduplication is automatic.
You can’t accidentally destroy data in a Venti-store, because writes are
idempotent and happens at most once.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Data storage is forever. And it is excellent for archival storage and
backups.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Security is peculiar. I can give almost everyone in the world read
access—and yet they will be unable to guess a key (called a &lt;em&gt;score&lt;/em&gt; in
venti-speak). This makes it possible to use the store as a dead-drop for
messages and have others retrieve them at a later stage. Write access is
more problematic. While nobody can destroy my data in venti, I can’t
protect against an enemy adversary filling up my store with junk. Yet,
the properties of implicit integrity is quite nice to have.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The Erlang implementation is very simple. First, we employ the &lt;em&gt;ranch&lt;/em&gt;
acceptor pool to handle many simultaneous TCP connections. The protocol
it binary, but we can use Erlangs ability to match on binary patterns to
handle that easily. To handle the backend storage, we employ &lt;em&gt;eleveldb&lt;/em&gt;
which is LevelDB bindings to Erlang.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Whenever a client connects, we spawn a process and loop over standard
request/reply patterns for that client. A single &lt;code&gt;gen_server&lt;/code&gt; instannce
runs the calls to and from the database. All code we wrote, including
source, empty lines and comments are 435 lines of code. Erlang tends to
be wonderfully succinct.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;An interesting notion is that all commands in the protocol have &lt;em&gt;tags&lt;/em&gt;
which identifies the message. A tag in a request is reflected in the
response. It is the same as correlation id’s in the AMQP protocol for
instance. And it allows for aggressive pipelining of requests. If only
more protocols had this nice construction built in.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What I &lt;em&gt;love&lt;/em&gt; about the model is that venti(8) is a very simple storage
endpoint—yet it plugs so well into other subsystems. There is a
unix-feeling to Plan9 tools, except they are one-level-up in the
distribution chain. The key insight is that with venti, you have a
self-contained system you can use to build other systems on top of. And
by picking a system that already exists, you leverage the advantage that
there are already tooling out there which can read and write from the
store.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There are some obvious extensions to eVenti. First, we can trivially
exchange leveldb for riak. This will provide proper secure backup of
data by running a cluster of machines and by copying data out to
multiple machines. Note that the fact that Riak is a AP store is no
problem to us: We store immutable data with idempotent writes. Conflict
resolution is simply &amp;#8220;pick one at random since they are equivalent by
construction&amp;#8221;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;My intention is to use eVenti as a building block. I have a weakness for
Merkle-tree constructions and immutability in general. Plugs to systems
like Datomic, Dropbox, and Bitcoin. Note that you can run an event-log
as a Merkle tree, in the same sense as a Bitcoin block-chain.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Suppose I and a friend run eVenti servers. If I have write access to his
server, I can make encrypted backups at his place, not entirely unlike
Colin Percivals tarsnap project. Co-incidentally, it will also provide a
nice foundation for a secure encrypted chat service with long-term
storage. It will be so simple to link attachments into the chat. Or
Chess games. If I know the SHA1 of our game, I can extend it with a move
and send the new SHA1 to you. Nobody else knows our game. But if I send
you a SHA1 of another game, you can walk the chain and get at all moves.
Over time the DAG in venti will form a nice opening book as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A system like venti is a necessary tool nowadays. The pendulum has swung
totally to the point where every service we use is centralized. Ten
years ago, we were running lots of P2P systems: Bittorrent for instance.
It is time we—the internet—push the pendulum in the other direction.
This means we need to be the arbiters of our own data again. Not push
the data to some irritating insane third party company who will like to
sell the data for money&lt;sup class=&#34;footnote&#34;&gt;[&lt;a id=&#34;_footnoteref_2&#34; class=&#34;footnote&#34; href=&#34;#_footnotedef_2&#34; title=&#34;View footnote.&#34;&gt;2&lt;/a&gt;]&lt;/sup&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;No company will build the decentralized structure, unless they have a
business plan for it. And it seems very few companies in this space have
any other business plan than to sell your data back to you for money.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Next, I want to see how I can leverage the Plan9 9p protocol and FUSE to
turn data into a filesystem I can mount. Imagine having a chat
conversation where you can cd into a directory in the filesystem and
automatically have access to all the attachments of that chat.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;But I do think I need more than 435 lines to do that. Perhaps 1000.
Embrace Erlang :)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;footnotes&#34;&gt;
&lt;hr&gt;
&lt;div class=&#34;footnote&#34; id=&#34;_footnotedef_1&#34;&gt;
&lt;a href=&#34;#_footnoteref_1&#34;&gt;1&lt;/a&gt;. I have a weakness for Gaspard de la nuit :)
&lt;/div&gt;
&lt;div class=&#34;footnote&#34; id=&#34;_footnotedef_2&#34;&gt;
&lt;a href=&#34;#_footnoteref_2&#34;&gt;2&lt;/a&gt;. Hello every company in existence.
&lt;/div&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>Glicko 2 Benchmarking</title>
       <link>https://jlouis.github.io/posts/glicko2-benchmarking-2/</link>
       <pubDate>Wed, 30 Oct 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/glicko2-benchmarking-2/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Glicko2 is a ranking system for duel games. I use it to rank Quake Live
duels. The idea is to find a value, the &lt;em&gt;strength&lt;/em&gt; of a player, called R
in the system. The higher the R value, the better the player.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;How does Glicko2 estimate R? It looks at historical data and uses
bayesian methods to estimate the current strength of a player. Like all
other systems, there are parameters we can tune for a set of players and
a set of duels:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;What initial R value should we pick for new players? We could pick
1500 as the base, but it may be that there are better initial values
than this.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What initial RD value should we pick for new players? The RD value
measures a &lt;em&gt;belief&lt;/em&gt; in a given R-value. A large RD means we have
relatively little information and hence can’t trust the R value as much
for rathing purposes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What about the initial Sigma-value? The Sigma-value is used to adjust
ratings for players which are consistently fooling the rating system. It
accounts for the situation where a player has been ``locked&#39;&#39; to a given
rating and then suddenly improves. In other rating systems, it would
take a long time to move that players R value to the correct position.
But Glicko2 will detect this and adjust the Sigma for the player,
allowing for greater R-strides.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What about the value of Tau? Tau is a global value which controls how
much power Sigma has. Games with high random variability needs a low Tau
around 0.2 to account for randomness in games. Games with lower
variability can run with higher Tau-values. Perhaps as high as 1.2 at
maximum. In game types with high Tau-scores, there is very little random
behaviour. Hence a win or a loss is more decisive and Sigma should
adjust with a greater factor.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The 4 different values spans a 4-dimensional space. We can try to tune
the values for the game type we are looking at. By doing so, we can hope
to find good values which optimize the ranking system to the game type.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_nelder_mead_numerical_optimization&#34;&gt;Nelder-Mead numerical optimization&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There are many optimization algorithms. The original algorithm when I
operated in pure Erlang was quite computationally intensive. I used the
concept of &lt;em&gt;Simulated Annealing&lt;/em&gt; as an optimization heuristic. This
algorithm works well, but requires many computations in order to find
good values.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I had experiments of Glicko2 computations in Erlang, Go &amp;amp; OCaml. Given
that the fastest Erlang code runs a round in 8us, OCaml in 2us and Go in
1us, I decided to focus on Go for the next round of work.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I want a more intelligent search for an optimum. One algorithm is
Nelder-Mead from 1965. This algorithm has some trouble in certain
situations. And it may converge to a wrong point. But it often works
well in practice. So I set out to implement the algorithm for Go. The
efforts are here, including tests and benchmarks:
&lt;a href=&#34;http://github.com/jlouis/nmoptim&#34; class=&#34;bare&#34;&gt;http://github.com/jlouis/nmoptim&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;NM is nice for our ranking work since it does not need numerical
derivatives of the function being computed. Rather, you start with a
&lt;em&gt;simplex&lt;/em&gt; which you then iteratively move around. You can imagine a
fishing net spanning the whole sea. NM proceeds by moving the fishing
net according to some rules in order to find the fish you are searching
for. In this case the minimum of the function at hand.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Nelder-Mead by itself is not easy to make parallel. But the ranking
function is trivially parallelizable. So I opted to do operations in
parallel and then speed up the ranking code. By using sync.WaitGroup in
Go, I immediately got to around 500% CPU usage on an 8 core machine. So
now I am blocked on speedup. Getting 5/8 of the cores to do meaningful
work and a factor of around 5 in speedup is nice. My ranking runs are
about 5 times faster in wall-clock as well. And that is disregarding
other possible optimizations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Furthermore, we find a good value in 22 iterations of Nelder-Mead with
45 function evaluations. I guess it was not that important to speed up
the computations after all since Erlang would have been able to run
this, albeit in hours rather than minutes. Go completes the run in in
about 3 minutes on my current Ivy Bridge Core-i7 laptop, which is a fine
speed for 2.5 million quake matches. It also ranks in around 925ns per
match which is around the numbers I got in my Glicko2 benchmarks for a
single test match.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_the_nextsteps&#34;&gt;The next steps&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I can now optimize in Go, but there are still more work to be done
before it is on par with the Erlang code:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We need to be able to rank pairs of \{Player, Map}. This is rather
easy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The prediction code only runs on the last round out of 99. It should
preferably run prediction on the last 4-5 rounds instead so the
predictions even out over a larger area. This will account for a single
round of matches becoming too crazy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ranking expected scores need some clamping which I am not doing
currently, but that should be easy to add as well.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>Why I use erlang.mk</title>
       <link>https://jlouis.github.io/posts/why-erlang-mk/</link>
       <pubDate>Mon, 28 Oct 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/why-erlang-mk/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Here is our typical Erlang project. And note we are on a pretty slow Mac
OSX filesystem and a 5400 RPM disk. Not the fastest in the world. If I
run a rebar-compile from cold, we get the following a timing of 26
seconds. Doing the same with erlang.mk is 24 seconds. Note that
erlang.mk only uses one thread, whereas rebar is parallelizing the build
and is using all 4 cores in the machine. But erlang.mk only spawns the
erlc compiler once per directory, and only if it needs to—no change
means no spawn.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;But if we have already compiled the code, the numbers are much
different. When compiling from warm, it takes rebar 9 seconds to figure
out that there is nothing to do in the project. erlang.mk does the same
thing in 0.2 seconds.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When developing, I don’t want to wait on the compile to finish all the
time. I want it to be proportional to the amount of change in my
repository, not on the complexity of the software project.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The other reason is that make(1) is the right tool for the job. Most of
these other tools are reinventions of the thing make(1) does. And it is
very hard to even contend with a tool that has survived so many years
and is so archaic.&lt;/p&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>An Evil Postgres Bug</title>
       <link>https://jlouis.github.io/posts/evil-postgres-bug/</link>
       <pubDate>Mon, 07 Oct 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/evil-postgres-bug/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So, I have this QLGlicko project. It consists of a web scraper which
takes in duel matches played in the game of Quake Live—and stores them
in a Postgres database. These duels are then analyzed and I run the
Glicko 2 (see &lt;a href=&#34;http://glicko.net/&#34; class=&#34;bare&#34;&gt;http://glicko.net/&lt;/a&gt;) ranking system on them to tell people
who are currently the best player on a given map.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The system works well, but I was tired of maintaining it on a Linux
machine for several reasons. One, Linux is hard to maintain and things
change underneath faster than I like. Two, I have much more experience
maintaining FreeBSD machines. Three, I can get proper built-in ZFS
support on FreeBSD. Hence I decided to move the database onto FreeBSD.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Most of the migration went well. I dumped the database, installed
FreeBSD, installed Postgres 9.3 (to avoid having to toy with SysV shared
memory). Tuned the database. And tried to import. First problem is that
Linux used the fake locale called &amp;#8220;en_dk.utf-8&amp;#8221;—so I had to fake it
and install that. Next problem was that I used the &amp;#8220;uuid-ossp&amp;#8221;
EXTENSION in Linux. This one has several problems on FreeBSD, mostly
related to PIC code and the fact that it will crash the database.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So I changed the code to &lt;em&gt;inject&lt;/em&gt; the UUID data rather than producing it
on the database side. And then I suddenly had duplicate key constraint
problems on an UNIQUE INDEX. Running SELECT queries showed no such
trouble with the index and there were no entries with more than a single
entry. This is to be expected due to the index being UNIQUE. But the
insertion or update code would soundly fail. I was wondering what went
wrong and began digging.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Here is what happened: the &amp;#8220;uuid-ossp&amp;#8221; code had managed to insert a
row into the database before it crashed. So this went under the radar of
the index and now we had trouble! There is an extra entry in the
database—violating the index—but it does not detect that.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Worse, when we query, the data can be served from the index alone, since
most data in the table are frozen. This means we begin getting really
evil and odd violations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Running a DROP on the index and then trying to recreate the index again
makes the error show up. And now I understood what went wrong.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The solution was pretty simple: Restore the database from a backup.
Remove any trace of &amp;#8220;uuid-ossp&amp;#8221; and then start the database again. Now
the index works as expected and the database doesn’t crash.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;TL;DR—Beware of extensions that doesn’t work on your platform of choice!&lt;/p&gt;
&lt;/div&gt;
</description>
     </item>
   
     <item>
       <title>An Initial Post</title>
       <link>https://jlouis.github.io/posts/an-initial-post/</link>
       <pubDate>Wed, 02 Oct 2013 00:00:00 +0000</pubDate>
       
       <guid>https://jlouis.github.io/posts/an-initial-post/</guid>
       <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I tend to stir up things over on blogger, mostly writing the blog
&lt;a href=&#34;http://jlouisramblings.blogspot.com/&#34; class=&#34;bare&#34;&gt;http://jlouisramblings.blogspot.com/&lt;/a&gt; —but I am considering writing and
using Medium instead to provide stuff, since the platform just seems
nicer. My Ramblings are mostly-technical and they tend to contain a lot
of code in them, but the way I tend to add new blog posts is somewhat
indirect. I write the post itself in my trusty Acme editor—as
markdown—and then I convert that into HTML which I then push in on top
of Blogger. I almost never use the editor in Blogger because I hate it.
So writing on Medium is an attempt. An attempt to see if the platform
would be a nicer way to write posts and if I would prefer it to writing
in the Editor.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Aside from 2018:&lt;/em&gt; In 2013, Medium was a quite nice platform. But over
the years, they destroyed the platform totally, making it a platform
where you have to pay in order to read posts and entries. It was free
originally.&lt;/p&gt;
&lt;/div&gt;
</description>
     </item>
   
 </channel>
</rss>
